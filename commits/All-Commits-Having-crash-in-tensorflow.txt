commit db445bbf91e9e020d0df4dbd08e9bc3ab074a4e8
Author: Sanjoy Das <sanjoy@google.com>
Date:   Fri Feb 19 01:45:43 2021 -0800

    Return a failed status (instead of crashing) when block count is too high
    
    PiperOrigin-RevId: 358360541
    Change-Id: Ia08a289c1368bfb2c8b726e707c8bb94a208d224

commit 252a113e7103790275790dca40298939de2672e4
Author: Richard Uhler <ruhler@google.com>
Date:   Wed Feb 17 16:16:32 2021 -0800

    Support dynamic-shaped operand in verification of BroadcastInDim.
    
    Verification of HLO_BroadcastInDimOp was previously failing or crashing if the
    operand had a dynamic shape or was unranked. Update the verification code to
    allow the operand to be unranked or have dynamic shape.
    
    PiperOrigin-RevId: 358056793
    Change-Id: Ia9305631cb7502bd5697ce484375169f534adbc4

commit 6129ab977cf6a56e203c04fd39fb2461152af551
Merge: b1c9e600e02 94ef2e05851
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Thu Feb 11 09:14:07 2021 -0800

    Merge pull request #46838 from around-star:fix-crashing-of-the-runtime-with-kernel-size-0
    
    PiperOrigin-RevId: 356987452
    Change-Id: I95790ccae67f77c63fd8825b08755ea721dd4924

commit 05756fcc81f6b5c2152d597b6285b350e7b05e36
Author: Doe Hyun Yoon <dyoon@google.com>
Date:   Wed Feb 10 17:26:46 2021 -0800

    Set default device info if device type is neither CPU nor GPU.
    
    OpLevelCostEstimator::GetDeviceInfo() returns GFLOPs/sec and GB/sec of
    the assumed machine, but currently it assumes the device type is either CPU
    or GPU. We didn't expect other device types would be passed during the Grappler
    optimization as transfer operations such as _Send and _Recv are added when
    a graph actually runs. In some occasions, we encountered the input graph
    includes _HostSend op (it is possible that the graph includes _Send or _Recv
    ops; that happened in some test cases).
    
    Device type not CPU / GPU currently causes crash; to avoid such a case, we
    assume unknown device type as transfer operations over PCIe; setting
    default PCIe x16 gen3 bandwidth to avoid crash.
    
    As the GetDeviceInfo() method is virtual, one may override this method
    if more precise device info is needed.
    
    PiperOrigin-RevId: 356865551
    Change-Id: Icf1f39e5da81f9c627aa01e479f437184a13eed3

commit 7edb8c9b83ad583616406af61e0de61393996a3e
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Sat Feb 6 20:24:54 2021 +0000

    Fix crash of tf.strings.substr when pos and len have different shapes
    
    This PR tries to address the issue raised in 46900 where
    tf.strings.substr will crash when pos and len have different shapes.
    According to the documentation of tf.strings.substr, ValueError
    should be raised instead when pos and len does not have the same shape.
    
    This PR add shape check in kernel to allows grace error throw (instead of crash).
    
    This PR fixes 46900.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit e84e4b3c841b0e81191f6d564bb61cfb9e1c33db
Author: Adrian Kuegel <akuegel@google.com>
Date:   Fri Feb 5 07:33:54 2021 -0800

    Revert PR #46886: [ROCm] Workaround for a LLVM crash when doing codegen for MLIR generated Cast kernel
    
    The workaround is not needed anymore, there is a LLVM fix available now.
    
    PiperOrigin-RevId: 355847125
    Change-Id: Iee1bf2b86621e51d872a0079b1a4b2ac29c02160

commit 41e8c71efb7efdb55fe83eab1bfde55b3a46bad4
Author: Deven Desai <deven.desai.amd@gmail.com>
Date:   Sun Jan 31 01:52:09 2021 +0000

    [ROCm] Workaround for a LLVM crash when doing codegen for MLIR generated Cast kernel
    
    When you enable (uncomment) the `gen_kernel_library` rule for `cast` in `tensorflow/core/kernels/mlir_generated/BUILD`, the build would fail on the ROCm platform with the following error
    
    ```
    LLVM ERROR: Cannot select: 0x56134e3c5b10: i1 = fp_to_sint 0x56134d1f53d8
      0x56134d1f53d8: f16 = bitcast 0x56134e3c58a0
        0x56134e3c58a0: i16,ch = load<(load 2 from %ir.lsr.iv)> 0x56134eaa3788, 0x56134e3c5698, undef:i64
          0x56134e3c5698: i64,ch = CopyFromReg 0x56134eaa3788, Register:i64 %16
            0x56134d41d620: i64 = Register %16
          0x56134d1f5850: i64 = undef
    In function: Cast_f16_i1_kernel
    TensorFlow crashed, please file a bug on https://github.com/tensorflow/tensorflow/issues with the trace below.
    Stack dump:
    0.      Program arguments: bazel-out/host/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel --unroll_factors=4 --tile_sizes=256 --arch=gfx803,gfx900,gfx906,gfx908 --input=bazel-out/k8-opt/bin/tensorflow/core/kernels/mlir_generated/cast_f16_i1.mlir --output=bazel-out/k8-opt/bin/tensorflow/core/kernels/mlir_generated/cast_f16_i1_kernel_generator_kernel.o --enable_ftz=False
    1.      2.      Running pass 'CallGraph Pass Manager' on module 'acme'.
    3.      Running pass 'AMDGPU DAG->DAG Pattern Instruction Selection' on function '@Cast_f16_i1_kernel'
    ...
    ...
    ```
    
    Jack (@whchung) identified the root cause of this crash as lack of support for FPTOSI (fp16 to i1) instruction in the AMDGPU LLVM backend. The correct fix for this bug, is to add support for the same in the AMDGPU LLVM backend. Jack is in the process of upstreaming that fix to the LLVM repo.
    
    In the meantime (i.e. until the TF LLVM commit pointer is updated to point to a commit that includes Jack's fix), we need to workaround this on the TF side, by adding a pass that converts the `fptosi f16 to i1` op to `fptosi f16 to i16` + `trunci i16 to i1`, which is what this commit does.

commit bd14bb7cf4dffbf9be2041361855372aa48d5977
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Feb 2 22:06:41 2021 -0800

    Avoid crashing in LocalDeviceState::ReturnStreamToPool and BorrowStreamFromPool when stream fails with "ABORTED: Bad connection".
    
    PiperOrigin-RevId: 355324168
    Change-Id: Id5c99a418733ad394af4f5a99aaca398615e986b

commit b70b22739cc41c004e9ff6a0ad6b599b308d47dd
Author: Yi Situ <yisitu@google.com>
Date:   Tue Feb 2 18:48:04 2021 -0800

    Make profiler C APIs portable by serializing opaque protobufs into a user provided buffer.
    
    WHAT
    * Make profiler APIs in libtpu portable.
    * CollectData() takes in a user sized buffer that is big enough to contain a serialized XSpace from the TPU driver.
    
    WHY
    * Minimize number of APIs to maintain.
    * Minimize number of serialize and deserializations of XSpace.
    * Eliminate incompatibilities and crashes as a result of passing protobufs at shared library boundaries.
    * Untangle ownership and lifetime of resources; buffer for serializing is used and owned by the client, collected XSpace is owned by driver until after serialization.
    
    Misc clean ups:
    * Fix mismatch of TpuProfiler_Free definition vs declaration.
    * Fixed a leak in TpuProfiler_Create() on error conditions.
    
    Note: TPU driver refers to libtpu.
    PiperOrigin-RevId: 355299692
    Change-Id: Ie37c295c20c29bb511e9e969d785de57fe1446fd

commit 2ea2347dff126bff95ab51329e944e6fce9b28c5
Author: Hiran Sarkar <hiransarkar.cse2019@nsec.ac.in>
Date:   Tue Feb 2 02:10:29 2021 +0530

    Update nn_ops.py
    
    Fix #46798
    On having kernel size as 0 , the code crashes on execution. This pull request will raise a FloatingPointError upon getting a value of 0 for the ksize argument in nn_ops.

commit 727311cd6e1f363901f294bc98e5573afc062c01
Author: Roman Dzhabarov <rdzhabarov@google.com>
Date:   Fri Jan 29 10:30:39 2021 -0800

    [mlir] Crash in case two passes are registered with the same priority in MlirOptimizationPassRegistry
    
    PiperOrigin-RevId: 354560669
    Change-Id: I462e3979666ca71919e756d2d860a09c9d047419

commit 3f735b281c9ef21214b3ef74dd2c3d61276ad258
Author: Laura Pak <lpak@google.com>
Date:   Wed Jan 27 16:20:35 2021 -0800

    Create a fuzzer for `ParseAttrValue` to fuzz for crashes only.
    
    PiperOrigin-RevId: 354197044
    Change-Id: I4f4ac3d54da8cca1f1d686de6f25aecfcb71c7dd

commit 8acf52169fd910d4939ab4c8a3aa88b395be41af
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Wed Jan 27 21:19:33 2021 +0000

    Fix crash when tf.sequence_mask takes a non-integer lengths
    
    This PR tries to address the issue raised in 46698 where
    tf.sequence_mask will crash abruptly if lengths is not passed
    with an integer tensor.
    
    This PR applies a dtype check and throw out ValueError to avoid
    program crash.
    
    This PR fixes 46698.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 5f457f704022b08c5592481bf79d03adcf6450db
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Wed Jan 27 20:25:08 2021 +0000

    Fix crash when invalid keepdims value is being passed to tf.math.reduce_prod
    
    This PR tries to address the issue raised in 46700 where
    tf.math.reduce_prod will crash if keepdims is being passed
    with a non-boolean value (e.g. numpy value)
    
    The issue was that keepdims is passed through pywrap
    which can not interprete numpy values, thus crashes.
    
    A way to detect the type mismatch before being passed
    to pywrap is to use `bool(keepdims)` to give python a chance
    to convert to bool (and throw out error when appropriate).
    
    This PR also fixes all reduce_ ops.
    
    This PR fixes 46700.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 4db28856db1f9e8c0a062beea5fa5f8774c21663
Author: Smit Hinsu <hinsu@google.com>
Date:   Fri Jan 15 13:39:01 2021 -0800

    Explicitly reject ops with symbol ref attributes in the fallback legalization pass
    
    We don't attempt legalization for ops with symbol reference attribute even if they are in allow-list. Xla op kernels for these ops compile the function to HLO on-demand which won't work in our case as it may contain unsupported ops in the fallback nor we provide XlaCompiler to the kernel. Also, these patterns are used from a function pass.
    
    This is just an extra check which might be useful if we switch to deny list instead of allow list or avoid crashing if an op with symbol ref is added to the allow list.
    
    PiperOrigin-RevId: 352074881
    Change-Id: Ided5dc736b61aa25bd5b3960059ee4949086f54b

commit b7d254ae619d9f7fabdada186fcb65deddf160b9
Author: Mark Sandler <sandler@google.com>
Date:   Fri Jan 15 10:14:52 2021 -0800

    Makes experimental_implements work correctly with GradientTape.  Before it would erroneously keep experimental_implements attribute in forward/backward of eager versions of the tf.function, which would cause a runtime crash.
    
    This change unifies that code path being used for both eager and non eager functions.
    
    PiperOrigin-RevId: 352033823
    Change-Id: I98ae4d07420826482faf9e0ace3f53193964a816

commit b30f3f3a36609bf314aeb551bbce590f7145c830
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Mon Jan 11 17:46:17 2021 -0800

    Log error before failing
    
    Report the error before crashing. It is unfortunate that the internal helper function can be used safely, while the external accessor cannot. But this avoids at least dropping the error message.
    
    PiperOrigin-RevId: 351272683
    Change-Id: I34ceda0b59b61aec6351c5efc8cb34e1e7291a9f

commit 287ab9046604c277908969e20b7b4c0febe8b4ab
Author: David Majnemer <majnemer@google.com>
Date:   Sun Jan 10 16:26:32 2021 -0800

    Return an error instead of crashing
    
    The function returns a Status so we can just propagate the stream error.
    
    PiperOrigin-RevId: 351055448
    Change-Id: Id7234429e063b2c6a590ac4ec36acd07a6992cea

commit d5a1371029481eaefe303d576754e3ac8ceba154
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Tue Jan 5 14:17:34 2021 -0800

    Add `FooWithStatus` methods for all `Foo` methods with `CHECK` fails.
    
    This is part of eliminating CHECK fails from `tensor_shape.cc`.
    
    The goal is to provide options for the callers to either test the `CHECK` conditions before calling the `Foo` methods or to call the `FooWithStatus` methods and receive a `Status` to act on instead of just crashing.
    
    PiperOrigin-RevId: 350218073
    Change-Id: I4238ba3a2eff16a224e61bafb58b6553d706bb4b

commit 5a1d7415893a2e27ee6084809820cc18d2183225
Author: Qiao Zhang <zhangqiaorjc@google.com>
Date:   Tue Jan 5 13:13:21 2021 -0800

    BufferFromHostBuffer in CopyToDevice in implementation should take ownership of the intermediate literal.
    
    It doesn't crash today because we cache the literal internally. But we plan on removing the caching behavior. It's better to remove this fragile dependency.
    
    PiperOrigin-RevId: 350204506
    Change-Id: Iaa2d88e484ed1668aaf1b4eb6789e5d861bb3fb4

commit 0ccf4bfab53d0af5e684e379b4520a789633ab27
Author: Sanjoy Das <sanjoy@google.com>
Date:   Wed Dec 30 14:19:00 2020 -0800

    Crash if XLA flags are to be read from a file but we could not open the file
    
    PiperOrigin-RevId: 349601577
    Change-Id: Id094dabb1ccb03e633d472bbee9bc1f48604c0ba

commit 92ed1d37d8a1814b9f92a7745bf0d3dc6d003aef
Author: Yi Situ <yisitu@google.com>
Date:   Wed Dec 23 11:09:10 2020 -0800

    Fixed an OOB crash that may happen when pairs of tokens were consumed in an odd length vector.
    
    * Added test cases for various odd and even length lists.
    
    xplane_to_kernel_stats_db.cc
    * Refactor for Debug (RFD): split out compound expressions into separate lines so that stack traces can pinpoint the sub-expression that is crashing.
    
    PiperOrigin-RevId: 348820545
    Change-Id: I5934f568e5e7fe870ae14b1a871716aaa145d770

commit 0666d8bb711b41c9f03dec238d7d165bc946fc70
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Mon Dec 14 23:11:16 2020 +0000

    Prevent crash of tensorflow if shape is too large for tf.sparse.reorder
    
    This PR tries to address the issue raised in 45392 where
    tensorflow crashes if shape of sparse tensor is too large for
    tf.sparse.reorder
    
    This PR adds additional checks and exit gracefully if the shape
    is too large.
    
    This PR fixes 45392.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 2f7251d79b9562aeb5f8cab30a5848fd03120637
Author: Prakalp Srivastava <prakalps@google.com>
Date:   Wed Dec 9 01:37:55 2020 -0800

    Handle empty callee during export from `mhlo` to HLO.
    
    Some tests crash during export to MLIR as they have empty functions being called into. This change fixes that.
    
    PiperOrigin-RevId: 346502515
    Change-Id: I95c331e3bf33bb87ed0e1061d68a499df5e01576

commit 53fb98858ffc8efa937197d05535f7ccb774749d
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit c7748eb5130526bd0b66fce410af7c74d24f6385
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit 07d2f0766c81fa25fa41e5959d77a0a68c24b9ce
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit 54461b130dff8ad05740179d7c47abd6b782667d
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit 35fbc5ce82b56553ec7fda36456ae4414346ed96
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit 6f788c5d3ee689460528796ec02e08c8538bcddf
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit 2d753e6a210bc337cc559e06007b2e383aeef6f8
Author: Terry Heo <terryheo@google.com>
Date:   Tue Dec 8 18:15:36 2020 -0800

    Fix a crashing issue of Android logging
    
    Avoid using std::cerr.
    This patch resolves GitHub issue #38025.
    
    PiperOrigin-RevId: 346452855
    Change-Id: Ife2504476b265909814c09c900cbb5090a55fcc5

commit 8fcb4cea3592c8ee9fcebe301eaa686bf295bbd5
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit faf7af8ef8aacfa0e3d20ae61fe302ab13203f55
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit 211469d43feae91e122e098d49666c879382b7b9
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit 0b289c33bed2e9338d42378ffffeb71552c3caeb
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit eccdffd4ba5604fd53bcc48a9b20490dd7b732b4
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit ffea0239373512240bb17101b5a5992de26aa5a4
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit ebc70b7a592420d3d2f359e4b1694c236b82c7ae
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Dec 7 11:15:21 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 346135579
    Change-Id: I1c76392382c89ad8f072d5bc93d70669851eb404

commit c1e1fc899ad5f8c725dcbb6470069890b5060bc7
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 17:06:23 2020 -0800

    Mark `MemmappedTensorAllocator` as returning opaque handle.
    
    This allocator is used for `ImmutableConstantOp` and it returns a handle to the contents of a memory mapped file which is supposed to represent a tensor.
    
    For tensors of complex types (resources, variables and strings), allocators which are not marked as returning opaque handles will call placement new to initialize each element. This means writing to the buffer. However, in our case, the buffer is immutable and already contains the tensor data. Hence, writing to it is both destructive and causes a crash.
    
    PiperOrigin-RevId: 345786451
    Change-Id: I46369c50fa60b3431709ffe068a728d3061f49c4

commit 6a16b086c14621979c3b364e1c9c52673d8cd325
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Dec 4 16:23:02 2020 -0800

    Validate that `DataFormat*` attributes form a permutation.
    
    The `src_format` and `dst_format` attributes for the `DataFormatDimMap` and `DataFormatVecPermute` raw ops are supposed to determine a permutation. However, this was not validated and could result in unitialized memory accesses as well as writes outside of bounds and potential crashes.
    
    While here, we also test that the format attributes have the needed length, add tests for all validation failure cases, remove unnecessary calls to `strings::StrCat`, and fix a few grammar errors.
    
    This will be cherry-picked on the supported release branches.
    
    PiperOrigin-RevId: 345779199
    Change-Id: I333bd02520e78e586b9e418d4700154a142181f1

commit 3e40e27e454cd8d8d27f757f4942b0bb43da4b03
Author: Tim Shen <timshen@google.com>
Date:   Fri Dec 4 00:29:29 2020 -0800

    [XLA/GPU] Fix debug mode crash.
    
    PiperOrigin-RevId: 345622289
    Change-Id: I7aa15eabf8df9ed3072f32e87a921c6494e94df2

commit bb2e09ad7207c504296962192fa5f1b7ec53a659
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Thu Dec 3 10:49:20 2020 -0800

    Do not crash if Model.summary called on subclassed model with unused layer.
    
    Fixes https://github.com/tensorflow/tensorflow/issues/36198. Before, the error was in the form:
    
      ValueError: You tried to call `count_params` on concatenate, but the layer isn't built. You can build it manually via: `concatenate.build(batch_input_shape)`.
    
    PiperOrigin-RevId: 345486596
    Change-Id: I334994d3b31e53af40be7c33261f4e3af5d799b2

commit 9b898e62d3ce614a1fb9f7db8795a69d8f7ef189
Author: Smit Hinsu <hinsu@google.com>
Date:   Thu Nov 19 13:41:42 2020 -0800

    Fix Unpack lowering to not crash for unranked inputs and generate valid reshape ops
    
    Use TF::SqueezeOp instead of mhlo::ReshapeOp to drop axis dimension and Re-enable Unpack lowering tests disabled because of invalid HLO reshape op
    
    PiperOrigin-RevId: 343360430
    Change-Id: I95c3eb05adc0959ba543707e63898ccf4336f57e

commit 6674647c205921cbe9e2bdbb160051aa7ba4054b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Nov 16 11:57:25 2020 -0800

    Reduce the risk of crash by checking hook interface in ApiCallback.
    
    PiperOrigin-RevId: 342687482
    Change-Id: I3cd9cfde81638977cda61d357e8ead4f89f5ad9f

commit 2dac0812a52cc72661a55487d2bc9ed84fd7b268
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Nov 16 10:46:52 2020 -0800

    Fix `base64_fuzz` crash due to non-zero-terminated strings.
    
    If the fuzzing data is not a null terminated string, `std::string(data)` will cause a crash. This is because `std::string(char*)` calls `strlen` on the `char*` argument to know the size of the string. So, if `data` does not contain any `\0` this results in a heap overflow.
    
    PiperOrigin-RevId: 342670802
    Change-Id: I1c85836d58f7204ed8562babe1911c14dcbb0ae0

commit ce25634e3ec6c79c89645e4c52b004eabb869cb8
Author: Benjamin Kramer <kramerb@google.com>
Date:   Mon Nov 16 09:31:55 2020 -0800

    Fix iterator invalidation when pushing a self-reference on a SmallVector
    
    This crashes with https://github.com/llvm/llvm-project/commit/2c196bbc6bd897b3dcc1d87a3baac28e1e88df41
    
    PiperOrigin-RevId: 342653532
    Change-Id: I26b32e9674a03a1dfeb74c7760916a9e43a080fc

commit 4c7aeb0a0c3ffd4ec547efb37719c62a09137031
Author: Jaesung Chung <jaesung@google.com>
Date:   Wed Nov 11 22:32:56 2020 -0800

    Fix crashing on unknown rank tensors at creating protobuf for converter backend
    
    PiperOrigin-RevId: 341981639
    Change-Id: I50b229d622beefca1abcfe6db6d9e77f0591902d

commit bec7b3dae423fde74bf57bce037acd075c9f43d3
Author: Ruoxin Sang <rxsang@google.com>
Date:   Wed Nov 11 00:29:04 2020 -0800

    Make sure TPUPartitionedInput shape inference doesn't crash if input handle shapes and types are not available.
    
    PiperOrigin-RevId: 341777572
    Change-Id: Iad741580d81a51de3d92861f8c999047bd4b163d

commit 855db1ba86e22a6f3911cf5ff3f15b2b5bcf9678
Author: Andrew Audibert <aaudibert@google.com>
Date:   Thu Nov 5 11:25:11 2020 -0800

    [tf.data service] Perform journaling for SplitProvider progress.
    
    This allows us to recover SplitProvider progress on dispatcher restart, instead of needing to start SplitProviders from the beginning. As a result, the "distributed_epoch" processing mode now guarantees that no splits will be processed multiple times. Splits may still be lost if workers crash after receiving splits from the dispatcher.
    
    PiperOrigin-RevId: 340892436
    Change-Id: I7d64d768eff55fa4bc58d940b2ca21c19e9fc92d

commit 60ac36f504ccef5aa50261ee2d496a8b3590e78f
Author: Hongmin Fan <fanhongmin@google.com>
Date:   Fri Oct 30 13:17:43 2020 -0700

    Fix a batch task creation bug in TFRT batch fallback kernel. Without the fix,
    TFRT batch fallback kernel to crash in high QPS load. The bug makes it only
    create an object of base class BatchTask even when splitting a task of the
    derived class FallbackBatchTask (used only in TFRT), and put it into a batch
    with other FallbackBatchTask objects. When this batch of mixed types of tasks is
    processed, it crashes.
    
    PiperOrigin-RevId: 339927837
    Change-Id: Ie52bd11c61c9ddbe6ab803cd90208419d4b2dba6

commit 10f777a05ba92e4d1775911181536a09ec2ff4d9
Author: Terry Heo <terryheo@google.com>
Date:   Tue Oct 27 21:59:07 2020 -0700

    Fix a crashing issue of Android logging
    
    Avoid using std::cerr.
    
    Tested with //tensorflow/lite/tools/benchmark:benchmark_model_plus_flex
    
    PiperOrigin-RevId: 339394158
    Change-Id: I1a035ebb258a6fb8515b8daa8261ef5f29519343

commit 7bd42cf6ba061ba7c06c072c9d962abe331461eb
Author: Rohan Jain <rohanj@google.com>
Date:   Mon Oct 26 17:12:19 2020 -0700

    Addressing large number of outputs in a consistent way across our various C
    APIs (Eager fastpath, Eager slowpath, graph).
    
    Previously in graph mode, we would error out for somewhat the wrong reason but
    the error message was decent. This CL makes it more precise.
    
    In fastpath eager mode, we tried parsing an int64 attr to an int32, failed and
    unnecesarily hit the slow path.
    In the slowpath, we used to just try and allocate a huge output number of
    handles causing a crash.
    
    This CL just checks whether the output size is greater than int32 and errors
    out before trying to do any allocation.
    
    Fixes https://github.com/tensorflow/tensorflow/issues/42281
    
    PiperOrigin-RevId: 339150482
    Change-Id: I6d9d1541ccfa9881f92a06348567562f79b0a963

commit fec830a3c84480870bbb6e63a5532ffb6c41f747
Author: Tiezhen WANG <wangtz@google.com>
Date:   Wed Oct 21 08:07:49 2020 -0700

    TFLM: Fix hard crash on Arduino.
    
    Long debug log caused the program to crash.
    
    Also this debug log is not much in use anyway.
    
    PiperOrigin-RevId: 338264544
    Change-Id: I940208380074e74a40e21cf22960fdc8f1c00c4d

commit e5942a87436e7e12957627fa53c510c6a9b6ab2c
Author: Aleksey Vitebskiy <aleksey.vitebskiy@maxar.com>
Date:   Tue Oct 20 12:11:44 2020 -0400

    Don't ignore sink == nullptr, let it crash instead.

commit 1e2389b4bad3f6f3705114388951b6d608f49e9b
Author: Mehdi Amini <aminim@google.com>
Date:   Mon Oct 19 19:17:10 2020 -0700

    Print a message refering to the Kernel CodeGen tool on crashes
    
    PiperOrigin-RevId: 337980841
    Change-Id: I5ffc42032fa7cf44768b6d806af5317774f040f1

commit eccb7ec454e6617738554a255d77f08e60ee0808
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Mon Oct 19 17:56:36 2020 -0700

    Prevent segfault in `quantize_and_dequantize`
    
    Fixes #42105.
    
    If `tf.quantization.quantize_and_dequantize` is called with `axis` argument pointing to outside of the input tensor, we obtain a `CHECK` fail which then aborts the application/interpreter. This change adds a condition check and returns a `Status` instead of crashing.
    
    PiperOrigin-RevId: 337972243
    Change-Id: I71ec32c00a87266e364fb017f0ad5dfd3e23542f

commit bc7dcb1a5af6f0765320ed2fdfa8aef364e787df
Author: Ran Chen <crccw@google.com>
Date:   Thu Oct 15 18:55:33 2020 -0700

    Put group_size, group_key and instance_device in host memory
    
    Otherwise they're will be copied to GPU, and the kernel will crash when accessing them.
    
    This change also adds GPU tests to kernel_tests/collective_ops_test.py, so that we can verify this.
    
    PiperOrigin-RevId: 337426822
    Change-Id: If085447afb2c7d55230a3aeb2b373f9d1eb22f6e

commit 35f478825b56218768220a46bb49b9645271f6cf
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu Oct 15 13:09:37 2020 -0700

    [XLA:Python] Validate shapes in Python bindings to avoid crashes.
    
    [JAX] Perform LAPACK workspace calculations in int64 to avoid overflows, clamp the values passed to lapack to int32.
    
    Will fix https://github.com/google/jax/issues/4358 when incorporated into a jaxlib.
    
    PiperOrigin-RevId: 337367394
    Change-Id: I3b8c116c7bfb764751448ab33ee7ae2a1ebe5ab6

commit dd934175ecaa6d52d8a297144215acfa650360ac
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Oct 6 17:11:45 2020 -0700

    Avoid compiler crash on aggregate initialization of flexible array member
    
    PiperOrigin-RevId: 335754239
    Change-Id: Ibc812c55e7e64739a030a6f03976c9c73d799ad2

commit 3db7b6d07b8bf4cb763963552d877ad06a79906d
Author: Rohan Jain <rohanj@google.com>
Date:   Wed Sep 30 07:58:58 2020 -0700

    Fixing a crash in tf.fingerprint([]). We now just return []
    
    PiperOrigin-RevId: 334598888
    Change-Id: I77423c797f003bf32a50687a0dd389c19f5fa27d

commit df4033fc955f4d872941b392ff3002e4323099b7
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Tue Sep 29 14:45:40 2020 -0700

    Remove `CHECK` in `TensorShapeBase::end()`.
    
    Since we use `kUnknownRank` to mark partial shapes with no rank information, without this `CHECK` or this code change the following program would result in accesses out ouf bounds
    
    ```cc
    PartialTensorShape s;
    for (auto d : s) {
      std::cout << d << "\n";
    }
    ```
    
    With the `CHECK`, the above program results in an abort. Without the `CHECK` and without the rest of the changes, `TensorShapeBase::dim_size` will be called with arguments from 0 to 255 (`kUnknownRank`) which would result in reading outside of bounds of the `ShapeRep` buffer (`dim_size` has `DCHECK`s). With the fixes in this change, the `for` loop will not iterate at all, but there won't be a program crash.
    
    PiperOrigin-RevId: 334466121
    Change-Id: I96252933b67cb64a27c1648157f87ccff3a5561a

commit 9427f6f2cfc21aac7fcd25710cc354bcd8c195ad
Author: Tres Popp <tpopp@google.com>
Date:   Tue Sep 29 03:51:26 2020 -0700

    Remove use of unserializable FuncOp pass parameter.
    
    propagate-tf-abi-knowledge used a FuncOp as an argument. This could not be serialized and thus not used for crash reproduction through textual .mlir files. This removes the function and instead finds it inside of the pass.
    
    PiperOrigin-RevId: 334345658
    Change-Id: If917b22bc6eba6065233d91faaecd531e1c78659

commit 8d6c46237c483dc1133a1a9da7523049a696f82d
Author: Mehdi Amini <aminim@google.com>
Date:   Mon Sep 28 15:52:12 2020 -0700

    Print a TensorFlow URL instead of LLVM on crashes
    
    PiperOrigin-RevId: 334255040
    Change-Id: I2481458998fe6bf64fbfb09a744814e3441e5f00

commit e093e9667e275f4bad447f5be5898c5ef6fba82c
Author: Thomas Joerg <tjoerg@google.com>
Date:   Fri Sep 25 02:42:00 2020 -0700

    Revert: Implement horizontal input fusion.
    
    This change causes SIGSEGV crashes in XLA.
    
    PiperOrigin-RevId: 333696643
    Change-Id: I32b578bd46d504bc6826b681a1c8fd166bded707

commit 5861e0dc3c6f02ab4a55bfaa37e75386f8c1a482
Author: Mehdi Amini <aminim@google.com>
Date:   Thu Sep 24 17:46:05 2020 -0700

    Disable crash reproducer in kernel codegen tool
    
    This is blocked on having a complete textual serialization for the pass pipeline, which
    isn't possible because of PropagateTensorFlowABIKnowledgePass uses of a
    "FuncType" pass option.
    
    PiperOrigin-RevId: 333636608
    Change-Id: I1fb53b2842f70c92ddb933ee208fe418bb192940

commit c519ec6b8a54c05c97e45ef16f33eab80e341a5b
Author: Richard Uhler <ruhler@google.com>
Date:   Tue Sep 22 14:26:05 2020 -0700

    Don't crash when legalizing reduction ops with quantized int types.
    
    Only attempt legalization of tf.Min, tf.Max, tf.Prod, and other reduction ops
    for int, float, and complex element types, to avoid crashing in the case of
    unsupported types such as quantized integer types.
    
    PiperOrigin-RevId: 333159797
    Change-Id: I48f58c7f7e3dab196d2a2a1e728531a65fbf5872

commit c53e6e7f492dd9c1dd10e84a6ddb57fd07a3c0b6
Author: Mehdi Amini <aminim@google.com>
Date:   Mon Sep 21 18:01:00 2020 -0700

    Add a header for table-gen generated pass for MHLO and use it in SinkConstantsToControlFlowPass
    
    A non globally registered pass should define `getName()` in order to generate correct crash reproducers.
    This is something we get "for free" when using the TableGen generated base class.
    We should also migrate the other passes to the same mechanism and remove the static
    global registration.
    
    PiperOrigin-RevId: 332976907
    Change-Id: I85071e97259cf2ce34f1542e443465b50c473261

commit e90dd8abe71a5075027eea79241714dcea545389
Author: Mehdi Amini <aminim@google.com>
Date:   Mon Sep 21 17:09:53 2020 -0700

    Setup the crash reproducer on the MLIR pass manager
    
    PiperOrigin-RevId: 332969417
    Change-Id: I71dd28699631fc2ffc34add4df7afc7a2a5c75f2

commit 35f6596114d79a5371e2a1feea8d343fc5ac5521
Author: Mehdi Amini <aminim@google.com>
Date:   Sun Sep 20 17:08:53 2020 -0700

    Fix crash in tf.Size folder when the output is originally unranked
    
    We can't change the output type when folding, and we can't create and unranked
    attribute: disable folding and rely on the shape propagation to fix it up
    first.
    PiperOrigin-RevId: 332755797
    Change-Id: I39c020781835021a9abe9f01eee6de903bcc609f

commit 5cbcf59ba2875ab27ca755cbe106ee24950bbe20
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Sep 15 14:17:48 2020 -0700

    Propagate test error to avoid crashes.
    
    PiperOrigin-RevId: 331853257
    Change-Id: Idea8c0a4855b0c404f6ff6bd042ce950e2904767

commit 7fe9c5b4692bffd9576660c0d2416a9c4d2870b1
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Sep 1 07:36:57 2020 -0700

    Fix mhlo::SliceOp::fold to not crash on unknown shapes
    
    PiperOrigin-RevId: 329504383
    Change-Id: I0039c7a69d3af9611156b2eb01afa921cdc9e774

commit 7ceb77b914ec92ecc472a18e10ebb0e51430d9a1
Author: Doe Hyun Yoon <dyoon@google.com>
Date:   Mon Aug 24 13:39:47 2020 -0700

    Return Zero Costs if any of dim in Conv input is zero.
    
    It's reported that op_level_cost_estimator crashes when input depth or output depth
    is zero.
    
    This CL checks any zero value in dim and just returns zero Costs.
    
    PiperOrigin-RevId: 328201526
    Change-Id: I52c085d3e4b9f549a3e1d2a46c5d6b34bb696540

commit 35c2a97ddca6da7d5a21d5ee3e2869eec68299f9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Aug 21 11:55:02 2020 -0700

    Adding explicit boolean conversion to `expand_composites` arg.
    
    Fixes #42331
    
    Currently on violation it results in crashing, this explicit conversion helps to raise ValueError from python.
    
    PiperOrigin-RevId: 327848244
    Change-Id: Id872a95f5d64bd2f694885ace0350b44b70eb558

commit 313edafd6fad2cf36d43b7eb18de093787ddf27c
Merge: 78635aa3581 70a041db8aa
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Wed Aug 19 17:46:17 2020 -0700

    Merge pull request #42397 from yongtang:42329-tf.nest.assert_same_structure-crash
    
    PiperOrigin-RevId: 327541695
    Change-Id: I29ed66c2a161b10e4aa44772bc2b167b74a73cd5

commit 03867516a901c826e03dfaeb8438f0307df26139
Author: yair_ehrenwald <yair.ehrenwald@ceva-dsp.com>
Date:   Tue Aug 18 17:52:12 2020 +0300

    Fix flexible members crash in clang 7.1

commit 560d393f88c09fa9f658c0e3701271eb8e989bee
Author: John Poole <john@primatelabs.com>
Date:   Tue Aug 18 10:41:34 2020 -0400

    Initialize external_command_encoder_ to nil
    
    The uninitialized value can cause other functions (e.g., Invoke()) to
    behave as if the user has set an external command encoder.  Since the
    value is an invalid pointer, this causes the process to crash.

commit 3affef88ea6ae2348147e51025d72235c1c758a0
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Aug 18 01:19:31 2020 -0700

    Fix crash in IsTailOfShape inside TFL Optimize
    
    Previously we assumed all ShapedType have a known rank but that isn't
    always the case as UnrankedType is also a ShapedType so we have to call
    hasRank() before calling getRank().
    
    PiperOrigin-RevId: 327184195
    Change-Id: I80bad59e56fa920828935f71e4b69984680fb70b

commit a2aace76dc7b199573595e92864fa3ab1a417471
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Aug 17 13:30:24 2020 -0700

    Fix crash on TfLiteEvalTensor with null dims
    
    PiperOrigin-RevId: 327087234
    Change-Id: Id03adabcb128d94e214b9b6011e45779656fe46d

commit 9f86089e45e038d2df834608e950f0058e5890fb
Merge: 131a9225ed2 f6944b7c599
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Wed Aug 12 09:12:48 2020 -0700

    Merge pull request #42240 from Intel-tensorflow:yimei/fix_mkl_conv2d_bf16_eager_crash
    
    PiperOrigin-RevId: 326244105
    Change-Id: Ic3f6777dc8750c7fc1787ec817da79c66d006e88

commit 19806267f85275a395e7a9cd80d5be23d0c70a74
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Aug 6 10:09:15 2020 -0700

    Set name of layer to node name when converting activation and FusedBatchNorm ops
    Also fix a potential crash if creating the layer fails.
    
    PiperOrigin-RevId: 325254289
    Change-Id: I8d38bf11880b8eb4fe92512977ebc304ed202acc

commit 0c2b2a3063dc4334b62eade3dace0e8c171df539
Author: Advait Jain <advaitjain@google.com>
Date:   Wed Aug 5 16:37:13 2020 -0700

    Remove logic that is no longer needed and make GetTensor availability strict.
    
     * Most kernels have been ported over to use the new EvalTensor API. The
             exceptions are kernels in arc_mli, ethos-u, xtensa_hifi and
       xtensa_hifimini_staging.
    
     * The kernel tests were previously changed to where they would fail unless they
       used EvalTensors
    
     * This change enforces the fact that kernels should no longer be using full
             TfLiteTensors in the Eval functions. Calling GetTensor from a kernel's Eval
       will now crash due to dereferencing a nullptr.
    
    PiperOrigin-RevId: 325126736
    Change-Id: I1a1c9af7dcca5765461794a60ef626387fa82638

commit 4a64fa3df8455d06a81c126a28262f64db60d15b
Author: Benjamin Kramer <kramerb@google.com>
Date:   Wed Aug 5 04:20:39 2020 -0700

    [XLA:CPU] Fix a crash in topk emission by canonicalizing pointers
    
    If there are multiple topk of different shapes in the same module, the
    signature of our runtime function will contain the shapes of the first
    instance. Subsequent instances clash with that signature. Canonicalize the
    types so all signatures become identical.
    
    PiperOrigin-RevId: 324992669
    Change-Id: Ibbbfdd671dedfcdfdb85706e3cffdf8d64859da6

commit e27d1f5d492eaf9d2f8e57a734aa15e0b6a36cbc
Author: Smit Hinsu <hinsu@google.com>
Date:   Thu Jul 30 18:13:15 2020 -0700

    Avoid crash while exporting HLO ops that are not isolated from above
    
    Abort and emit an error if one of the operand is Value to XlaOp in the current scope.
    
    PiperOrigin-RevId: 324124204
    Change-Id: Iad5825fbc015a9d75cd292b39216732848774062

commit d6066885d7547332df957f7bdb50cf26a090e2ac
Author: Tomer Kaftan <kaftan@google.com>
Date:   Wed Jul 29 13:50:05 2020 -0700

    Put a size limit on the int32 tensors KerasTensors will try to infer values for. This is needed because there is a maximum rank limit (of 254) for Tensors, so int32 tensors with more than 254 elements cannot represent shapes. (Which before this cl would cause KerasTensor shape inference to crash)
    
    PiperOrigin-RevId: 323860520
    Change-Id: Icbf10b8220739c5a9474f6f588174606402b9ca8

commit 8d3585924325f572c71b790a70439db1bce73ff5
Author: Mangpo Phothilimthana <mangpo@google.com>
Date:   Mon Jul 27 22:07:35 2020 -0700

    Make MemoryUsageTracker::EndInstruction() return error status instead of crashing due to CHECK fails. This crashes the layout autotuner.
    
    PiperOrigin-RevId: 323507724
    Change-Id: I5eafc0dbbb527164a9246131f1ad7f7d71ddcb44

commit f413da875ce3e599cd299379dc4d7ad282e03dcc
Author: Ran Chen <crccw@google.com>
Date:   Mon Jul 27 12:50:29 2020 -0700

    Abort collectives immediately after timeout
    
    instead of waiting for a second. This is to avoid crashes in two corner cases:
    - We now aborts the ParamResolver, which is not owned by BaseCollectiveExecutor, but the CollectiveExecutorMgr which is owned by EagerContext/Session. It's possible that it's gone when the abortion happens.
    - If the collective finishes before the aborting happens, i.e. within one second after the timeout, some callbacks in the stack will be called with OK and may access OP related data structures. Those structures are already gone after the timeout.
    
    PiperOrigin-RevId: 323420766
    Change-Id: I8e10dc5a30d22dc0d88268bd28751e93e9108dd1

commit 07b58e0820cdd23ef147c1233b750764df1b182a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Jul 21 16:42:01 2020 -0700

    Generate unique node names in AddEmptyNode by appending a suffix instead of crashing.
    
    PiperOrigin-RevId: 322469383
    Change-Id: I8062711c8d2bfb6e8c1afec44b28e7d3625a54cb

commit f29ace3cc878b96becc9ab18808273a541e7384d
Author: Benjamin Kramer <kramerb@google.com>
Date:   Wed Jul 15 12:13:26 2020 -0700

    [XLA:CPU] Register collective-permute IR
    
    Otherwise any use of collective-permute as an argument to another operation crashes.
    
    PiperOrigin-RevId: 321411964
    Change-Id: I5375762204a83536451f6ec472ae91712722fee2

commit ef4db27b3176f41613d159c8da9782abdaef2e90
Author: Tomer Kaftan <kaftan@google.com>
Date:   Tue Jul 14 11:02:34 2020 -0700

    Explicitly raise a (clearer) error message when models end up in invalid states due to interleaving graph and eager.
    
    In rare cases code may have run w/o crashing when in these invalid states, but it's safer to error with an explanation rather than risk silent failures/fragile behavior.
    
    PiperOrigin-RevId: 321192744
    Change-Id: I9e97ac3b7cea27c9b389e5202de9f1c09a4aa2b8

commit e9516a8b0e980b1b2478a683bd233d5ac2c9f2e9
Author: Sanjoy Das <sanjoy@google.com>
Date:   Tue Jul 14 11:30:37 2020 -0700

    Fix size computation logic in TransposeSimple
    
    Use the right type when computing `num_bytes`.  This caused the crash observed
    in the bug, but I could not reproduce in a unit test (even with cuda_asan) since
    the `InlinedVector` always uses stack storage.
    
    PiperOrigin-RevId: 321199018
    Change-Id: I339307a2d2d098d4ad73b363b5f96c19ed65ea52

commit 000b17d9a19643b206c29accb3abbfd7de70ce9c
Author: Tomer Kaftan <kaftan@google.com>
Date:   Tue Jul 14 11:02:34 2020 -0700

    Explicitly raise a (clearer) error message when models end up in invalid states due to interleaving graph and eager.
    
    In rare cases code may have run w/o crashing when in these invalid states, but it's safer to error with an explanation rather than risk silent failures/fragile behavior.
    
    PiperOrigin-RevId: 321192744
    Change-Id: I9e97ac3b7cea27c9b389e5202de9f1c09a4aa2b8

commit 909c073034e9b185149717c22b83d52dbd7396c3
Author: Prakalp Srivastava <prakalps@google.com>
Date:   Mon Jul 13 09:53:43 2020 -0700

    Return error instead of crashing when resource does not alias input.
    
    PiperOrigin-RevId: 320975373
    Change-Id: If40b04f88bc189ae5a9ec04690b66cf8389b528f

commit f1ee6a406c3ee63371c3ebb0072f8ea06614a8aa
Author: Robert David <lrdx@google.com>
Date:   Mon Jul 13 09:36:06 2020 -0700

    Fix GetNumberOfRuntimeInputsForNode crashing on optional input tensors.
    
    Also use NumInputs/GetOptionalInputTensor from kernel_util.h instead of directly accessing TfLiteNode members.
    
    PiperOrigin-RevId: 320971976
    Change-Id: Ieb7073dbfe644ad1f87289738ae6ff0d24e5ffad

commit 23873d4d6518a6f169600a076001dc2d7a661dd0
Author: Terry Heo <terryheo@google.com>
Date:   Mon Jul 6 01:28:38 2020 -0700

    Fix a crash on BenchmarkTfLiteModel with delegate
    
    When a delegate is used, it should be destoried after the interpreter object
    since the interpreter doesn't own the delegate object.
    
    PiperOrigin-RevId: 319736644
    Change-Id: I90879b83d5de98dd6b09b00927fae79ec61b1e8f

commit 4f370285e0501a54c059ed9aa763433cc51bbac4
Author: Ran Chen <crccw@google.com>
Date:   Tue Jun 30 17:41:03 2020 -0700

    Fix the crash when the collective param resolution finishes after timesout
    
    We need to check set the is_callback_called when timeout fires as well, since
    the timeout could be caused by a slow worker. The worker may catch up after the
    timeout fires.
    
    PiperOrigin-RevId: 319133791
    Change-Id: I9fdd9fe1ba942c2ef07a0ea14c860c7759d91ef9

commit bbfb45c6ad7ca875bf2ff45db69bb9630895bbbe
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jun 29 10:31:39 2020 -0700

    [XLA:Python] Fix crash in outfeed_receiver.
    
    PiperOrigin-RevId: 318842645
    Change-Id: I4cbfe777acb6ebf23fc206014c0db007a1cf2476

commit 68f26867e7fd30d46e079e3febb9f90ee735db74
Author: David Majnemer <majnemer@google.com>
Date:   Thu Jun 25 16:56:23 2020 -0700

    [XLA] Don't crash in the verifier if an operand's parent is null
    
    PiperOrigin-RevId: 318376207
    Change-Id: I32350514d0c65afb16915c7e80624bead1faaea9

commit aac1dd5788000f05f19f247e3bacacd81810d72b
Author: Tomer Kaftan <kaftan@google.com>
Date:   Mon Jun 22 12:24:15 2020 -0700

    Updates Keras layer `__call__` to always set `training`, with the following priority order:
        # Training mode for `Layer.__call__` is set via (in order of priority):
        # (1) The `training` argument passed to this `Layer.__call__`, if it is not None
        # (2) The training mode of an outer `Layer.__call__`.
        # (3) The default mode set by `tf.keras.backed.set_learning_phase` (if set).
        # (4) Any non-None default value for `training` specified in the `call`
        #  signature
        # (5) False (treating the layer as if it's in inference)
    
    Previously (4) and (5) were missing, leading to crashes for layers that do not provide a default argument for `training`.
    
    Note that (4) is fragile to reflection issues, and may get confused by decorators.
    
    PiperOrigin-RevId: 317709904
    Change-Id: I58039a4d9e5106bcb27f4cfbf65e6762f1b40807

commit e0780ef031fc27f4f2a71d745004d859a711c90a
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Fri Jun 19 10:21:14 2020 -0700

    Fix fp16 FusedBatchNorm CPU crash if batch dimension is 1.
    
    The GPU kernel outputs NaNs for the variance in this case, which is also incorrect, but better than crashing.
    
    PiperOrigin-RevId: 317331280
    Change-Id: Iea4e5a3337625796c50244e51d7ccb4b89f4c3e4

commit 3dd8cb721adf5505f8760fa48875a151d700b749
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Jun 12 13:16:03 2020 -0700

    Add GPU compatibility list entries based on crash reports
    
    PiperOrigin-RevId: 316164283
    Change-Id: I13910c527e531a2aa3bff596c963bee8168a4bc6

commit 255df2c8d876a15a76217a7ccb161aa4f3fc2fa3
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Fri Jun 12 13:11:08 2020 -0700

    Add fuzzer for `Status`.
    
    This should allow us to test fuzzing infrastructure with minimal dependencies.
    
    Since `Status` is used almost everywhere, we need to ensure that the common functionality is safe. We don't expect many crashes from this fuzzer since we only create a status and then look at the error message from it but this is a good test of the fuzzing infrastructure, with minimal dependencies (thus, it is a good test to weed out linker bloat and other linker issues).
    
    PiperOrigin-RevId: 316163409
    Change-Id: I62d192348b5f90209ce9188039e4962fe34872a8

commit 41de1e90a3f1ec879f5b1708df2b00a299f87526
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 11 02:28:15 2020 -0700

    Fix a bug in lift_to_graph.py.
    
    For example, if a source tensor is SOME_OP:0, the SOME_OP will be added to source_ops in line 325, and also be added to op_map in line 203. However if SOME_OP has another output SOME_OP:1, it will skip the _copy_non_source(), so SOME_OP:1 won't be added to op_map. As the result, in line 349 if mutation.old_graph_tensor is SOME_OP:1, it will crash.
    
    With this cl, all tensors including SOME_OP:1 will be added to op_map.
    
    PiperOrigin-RevId: 315861055
    Change-Id: I7aec62416051d90c37dec11a7a883452d1960c23

commit 46f963256a477487696716d8936b44f000a9d09b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 11 01:33:38 2020 -0700

    Fix a bug in lift_to_graph.py.
    
    For example, if a source tensor is SOME_OP:0, the SOME_OP will be added to source_ops in line 325, and also be added to op_map in line 203. However if SOME_OP has another output SOME_OP:1, it will skip the _copy_non_source(), so SOME_OP:1 won't be added to op_map. As the result, in line 349 if mutation.old_graph_tensor is SOME_OP:1, it will crash.
    
    With this cl, all tensors including SOME_OP:1 will be added to op_map.
    
    PiperOrigin-RevId: 315855946
    Change-Id: I86a5bc76557b89aecddfeec83c14b61408c195e3

commit 4acad672b7c77c8444366ba150da876f0855d411
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Jun 10 11:11:14 2020 -0700

    Fix a crash when SparseTensor::Slice receives start/size larger than input tensor.
    SparseTensor::Slice already reduces the size of the result if the selection is not fully contained in the input; this fix ensures that the same treatment applies when the start is already beyond the input boundary.
    
    PiperOrigin-RevId: 315727283
    Change-Id: I65acc099dd37932c32994e8026beb2be59d1c824

commit f672ee2564c95f037be869355bd78eeafd7e4998
Author: Christian Sigg <csigg@google.com>
Date:   Wed Jun 3 13:26:09 2020 -0700

    Avoid crash in C API and log error.
    
    PiperOrigin-RevId: 314592831
    Change-Id: I182a27286b9f31a9c53cf80d4ccfa83849faa205

commit 6e5cdea8492452ede1e3942eef54da95b8a2d2d7
Author: Stefano Galarraga <galarragas@google.com>
Date:   Tue Jun 2 16:30:20 2020 -0700

    Accounts added dequantization operations into NNAPI model size
    
    Before this CL application would crash when using NNAPI with target accelerator specified with model containing Conv2d or FullyConnected or LSTM nodes with quantized weights.
    The NNAPI models generated by the NNAPI Delegate could contain extra Dequantize operations.  The crash is caused by the buffer passed to ANeuralNetworksModel_getSupportedOperationsForDevices being too small since those extra Dequantize operations were not accounted.
    
    PiperOrigin-RevId: 314427031
    Change-Id: Ie8bce2b63b3b6129942644f79c661ad0b01351ee

commit 80768cb23a3a4314c52af0b48a6bcf23ca541e19
Author: Stefano Galarraga <galarragas@google.com>
Date:   Mon Jun 1 03:28:31 2020 -0700

    Accounts added dequantization operations into NNAPI model size
    
    Before this CL application would crash when using NNAPI with target accelerator specified with model containing Conv2d or FullyConnected or LSTM nodes with quantized weights.
    The NNAPI models generated by the NNAPI Delegate could contain extra Dequantize operations.  The crash is caused by the buffer passed to ANeuralNetworksModel_getSupportedOperationsForDevices being too small since those extra Dequantize operations were not accounted.
    
    PiperOrigin-RevId: 314104459
    Change-Id: I4784e62780c4bc44800f7c1bb3a1bb18b961d212

commit b100b185eecacef9990525e9a712b5547fa20689
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue May 26 17:28:20 2020 -0700

    Don't crash in 3D pooling ops with empty batch size on GPU.
    
    PiperOrigin-RevId: 313299099
    Change-Id: I40ce8f57efc386ae820460a325cfebee1be14d77

commit dd7849ed4c4c304ce15f6a95ff4d95c9f4af97bb
Author: Francois Chollet <fchollet@google.com>
Date:   Tue May 26 11:50:13 2020 -0700

    Fix issue where calling plot_model on Functional model that uses add_loss would crash due to model._layers containing DictWrapper objects.
    
    PiperOrigin-RevId: 313237777
    Change-Id: I1e9685242f3c5d887340fbcfed6f4709681c7cb7

commit 3d9ec6298a5d167c93e260605d3d2957d294fcb2
Author: Smit Hinsu <hinsu@google.com>
Date:   Thu May 21 09:53:22 2020 -0700

    Limit FillOp custom folder to int and float types to avoid crash
    
    DenseElementsAttr::getValue doesn't work for complex and string types and denseelementsAttr::get with Attribute only works for int and float types.
    
    It is possible to handle complex types in the custom folder but not doing that now as complex types are less common and it would be easier to handle those once we have an attribute type for complex types.
    
    PiperOrigin-RevId: 312687907
    Change-Id: I4596e82d7b7e1d353bfb045b39b451785a7474e7

commit 869920697b243622073317ddc533bdff41684c41
Author: Jared Duke <jdduke@google.com>
Date:   Mon May 18 13:27:55 2020 -0700

    [tf.lite] Use in-process conversion when the new converter is used
    
    Out-of-process conversion was a workaround for the legacy converter,
    which would generally crash the process when conversion failed. However,
    out-of-process conversion also adds a good deal of complexity, so avoid
    it when using the new conversion backend.
    
    PiperOrigin-RevId: 312142994
    Change-Id: I7ddc83df99ccf24be6e15f46d6a116dce8321933

commit cf35170ceaebd332683582eb08b4315708b55f76
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 15 14:47:11 2020 -0700

    Fixes linkage error on pre-18 Android where GLESv3 is not available
    
    With this CL gpu delegate is linkable for Android Apps supporting pre-18 API level.
    This solution works because tflite gpu delegate only weak-imports OpenGL ES 3+ symbols. However, it may results in a runtime crash if gpu delegate tries to use
    GLES3 symbols on those devices. A reasonable solution for pre-18 API is refusing
    to delegate?
    
    Two symbols were behaving as strong symbols ("glUnmapBuffer", "glMapBufferRange") because they were defined in a template only class, which would get preprocessed before #define that redefines GLES symbols into weak symbols.
    
    PiperOrigin-RevId: 311805477
    Change-Id: Ia217ebe64a975092a43869ece7d42f64c33bf795

commit 2540d202b5b798c7cea953b60247b834bef3ca07
Author: Yuanzhong Xu <yuanzx@google.com>
Date:   Fri May 15 10:19:17 2020 -0700

    Fix TF2XLA's InitGraph for unused feeds.
    
    If a feed is not used, previously it would prune the placeholders and cause crashes.
    
    PiperOrigin-RevId: 311754319
    Change-Id: Ie1ad67c21ffb83ba88aeabea94c416473df099a0

commit 1c74b32aa27dc0d40a9ce1f883ea632d399a7b9a
Author: Haoyu Zhang <haoyuzhang@google.com>
Date:   Tue May 12 21:23:08 2020 -0700

    Validate remote resource devices before safe access of resources.
    
    Cluster updates (due to recreated distribution strategies, remote worker failures, etc.) can lead to crashing failures with segfaults when accessing resources created before the update. Some common patterns are:
    * Accessing datasets created on old remote workers;
    * Accessing variables created on failed workers;
    * Garbage collecting datasets/iterators created on old remote workers;
    
    This CL validate the remote devices to make sure the access is safe before executing the ops by looking up the device in a set of device pointers and checking its incarnation ID. Remote workers on restarted devices will have different incarnation IDs, and accessing resources on those devices will fail gracefully.
    
    PiperOrigin-RevId: 311261000
    Change-Id: Ifc07862229b06301e0275fe80975565d9df28152

commit 28f2af10ecdde4ab8e24247a728032ea1891d730
Author: Jens Elofsson <jens.elofsson@arm.com>
Date:   Tue May 12 17:41:28 2020 +0200

    Realign AllocationInfo struct.
    
    After adding offline_offset, sizeof(AllocationInfo) = 40, which caused
    hello_world_test to crash. After realigning it's back to its original
    size (32).

commit 40835281112e42fd34af2aea4d3788d15b8e795a
Author: Derek Murray <mrry@google.com>
Date:   Fri May 8 16:08:20 2020 -0700

    [Executor] Fix segfault when using verbose logging in the executor module.
    
    Selective vlog-enabling for the executor module would trigger a crash in `SimplePropagatorState::DumpState()` (called when the executor executes a kernel that produces an error status). Because `SimplePropagatorState` is in a separate module, and selective vlogging might not be enabled for that module as well, the necessary state was not created, leading to a null pointer dereference.
    
    The fix is to share the executor's vlog setting with the propagators, so that if vlogging is enabled for the executor, `SimplePropagatorState` will create the necessary debugging structures (i.e. the `SimplePropgagatorState::active_` vector).
    
    PiperOrigin-RevId: 310646985
    Change-Id: Ic4220bfdb7e0800e1ad8a5eb6d468db5886367ad

commit dd7df2f89f5f9d23c23cd0d7e0d60df67ddda2c6
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed May 6 10:56:53 2020 -0700

    Improve TensorFlow arithmatic op folders
    
    * Fix crash for non fp32 types by creating identity attribute of the appropriate type.
    * Handle integer types
    * Handle identity value as lhs for symmetric ops
    * Utilize isSplat and getSplatValue helpers.
    
    PiperOrigin-RevId: 310185631
    Change-Id: I10c1db84595034470c6dbc64a0e7c1959b81741e

commit 5bb727ee34eb4f49977e91c2b102677e694f13c7
Author: Smit Hinsu <hinsu@google.com>
Date:   Wed May 6 09:04:48 2020 -0700

    Improve TensorFlow arithmatic op folders
    
    * Fix crash for non fp32 types by creating identity attribute of the appropriate type.
    * Handle integer types
    * Handle identity value as lhs for symmetric ops
    * Utilize isSplat and getSplatValue helpers.
    
    PiperOrigin-RevId: 310162612
    Change-Id: I863a5bf5cb64c832dd938e22c7694d34236dcfc3

commit 7f631f41f27e0fbd6ce2995dd8b0ccc582b55670
Author: Smit Hinsu <hinsu@google.com>
Date:   Mon May 4 11:36:41 2020 -0700

    Fix crash on OpaqueElementsAttr in CreateLiteralFromAttr helper
    
    PiperOrigin-RevId: 309786811
    Change-Id: I3086efacfdd4c97747fb47516afc7985fd9608b0

commit f5cd5c6a781b89a57097437ac04b52329e31ba16
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Sun May 3 16:31:57 2020 +0000

    Add test case for Huber Loss crashes when data type mismatch
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit edf5029353c452a5599dd02e95adee5657cd5599
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Sun May 3 16:28:29 2020 +0000

    Fix Huber Loss crashes due to data type mismatch
    
    This PR tries to address the issue raised in 39004 where
    setting keras backend to 'float64' causes Huber Loss crash:
    ```
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1440 huber
            math_ops.multiply(delta, linear)),
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:180 wrapper
            return target(*args, **kwargs)
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:490 multiply
            return gen_math_ops.mul(x, y, name)
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:6153 mul
            "Mul", x=x, y=y, name=name)
        /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper
            inferred_from[input_arg.type_attr]))
    
        TypeError: Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'.
    
    ```
    
    This PR fixes the crash by casting delta the same way as y_pred and y_true accordingly.
    
    This PR fixes 39004
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 57320e5a8cc4c75ac9dd8f50e6f6aabb6d4417c1
Author: Bixia Zheng <bixia@google.com>
Date:   Fri May 1 15:24:54 2020 -0700

    [TF:TRT] Check batch size consistency during segmentation for implicit batch
    mode.
    
    When forming segments for implicit batch mode, the inputs of the operations in a
    segment need to have a rank of not less than 2 and the implicit batch size of
    the operations need to be consistent. Previously, we do not perform such
    checking during segmentation. We may reject to build a TRTEngineOp for a
    segment that doesn't meet such a requirement. We may even crash when executing
    a TRTEngineOp built for a segment that doesn't meet such a requirement as shown
    in the bug here.
    
    Add test cases.
    
    PiperOrigin-RevId: 309484466
    Change-Id: I715817e9359d41075300911ca44aacb410e63ea0

commit 4d4cfa046fe2f287f5bdffc7b360a974fb7d8268
Author: Sean Silva <silvasean@google.com>
Date:   Wed Apr 29 12:39:30 2020 -0700

    Don't crash for unranked tensor types.
    
    ShapedType::getShape will abort for unranked types. Bail out for unranked early, and just use RankedTensorType directly.
    
    No test. I don't want to set a precedent of every elementwise op / other op needing individual test cases for every operand that might be ranked.
    
    PiperOrigin-RevId: 309076134
    Change-Id: Ibb15856bb29a1feac0a7054d2629f29b320ee8f8

commit 0de3c20c624c774d70b92f5ca38f05b351676f7d
Author: Derek Murray <mrry@google.com>
Date:   Wed Apr 22 09:24:01 2020 -0700

    Rolling forward "[tf.unique] Optimize the hash table implementation in `UniqueOp::Compute()`."
    
    The previous version was rolled back because it caused crashes with the previously valid input of `tf.unique([float('nan')])`. This was due to an assertion in `absl::flat_hash_map` that a constructed key is equal to itself. To work around this problem, this change retains the use of `std::unordered_map<>` for float and double arguments, and adds a test for this case to codify the previous behavior.
    
    PiperOrigin-RevId: 307831760
    Change-Id: I0c3f3f748a4876e19689e9031ce88d0815d9119b

commit 7a5797929c882505ed69cd45708dcf9e6ab92db4
Author: Bixia Zheng <bixia@google.com>
Date:   Mon Apr 20 09:25:58 2020 -0700

    Avoid crashing the TRTEngineOp execution when the inputs do not have consistent
    batch sizes.
    
    Instead, emit a warning and execute the native segment.
    
    PiperOrigin-RevId: 307414100
    Change-Id: I72c82414240a796756f8cf20fb2a0858e60e7c84

commit 2730e4b0bcba80799ddc10f52081927848540f30
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Wed Apr 15 13:38:36 2020 -0700

    Fix crash if set_visible_devices() used with tf.keras.mixed_precision, part 2.
    
    I thought I fixed this in https://github.com/tensorflow/tensorflow/commit/10e5748ddfcf0c60e5ef0a90bb72a34bc55190ec, but didn't, since I still called list_local_devices().
    
    Fixes https://github.com/tensorflow/tensorflow/issues/38516.
    
    PiperOrigin-RevId: 306711358
    Change-Id: Ic07ff827c42bae925bd20fc360d51bbc94f457c5

commit aad947401ee94ed81303c31a6f0f76c3a58c7267
Author: Smit Hinsu <hinsu@google.com>
Date:   Mon Apr 13 12:57:09 2020 -0700

    Fix unranked type handling crash in xla-legalize-tf-with-tf2xla pass
    
    PiperOrigin-RevId: 306291478
    Change-Id: Iffb01b19add6bb1d3727e46fc68d1f50d03b7ac0

commit 75dddeda5cf9c7887ceb8cd9a8ee44a37423406e
Merge: a853452aab8 85f156915b9
Author: Goldie Gadde <ggadde@google.com>
Date:   Thu Apr 9 23:51:42 2020 -0700

    Merge pull request #38417 from qiuminxu/cherrypicks_FNV99
    
    r2.2-rc3 cherry-pick request: Fix a bug that profile XLA gpu crashes OOM.

commit f530df457a55cd367ba6405323bf5e70cbec4dc1
Author: Cesar Crusius <ccrusius@google.com>
Date:   Thu Apr 2 14:47:34 2020 -0700

    Avoid crashing in TensorHandle::TensorValue when in a custom device.
    
    PiperOrigin-RevId: 304481949
    Change-Id: Id5396f5463f1402b1b5f891e930d97986f5aeec4

commit 9771765f4189fa36e8987160fbd6d880114c33fb
Author: George Karpenkov <cheshire@google.com>
Date:   Wed Apr 1 11:31:31 2020 -0700

    [TF/XLA] Force all tensors which need to be constant during the XLA compilation to be located on the host
    
    Otherwise, this leads to strange crashes during the compilation.
    
    PiperOrigin-RevId: 304226917
    Change-Id: Ia2f1e77b13a25c7e15f009787af81f93b90e8bca

commit 229326ce9c379a7a7d9c08d5975becc069103121
Author: Frederic Bastien <fbastien@nvidia.com>
Date:   Mon Mar 16 10:26:19 2020 -0700

    Crash fix. We where not returning the right reduction tile size.

commit 01e84d7cc214dbf5a7a21bc418ad43afb5694fbc
Author: Scott Zhu <scottzhu@google.com>
Date:   Tue Mar 31 09:27:33 2020 -0700

    Update error message for data_adapter with validation split.
    
    Remove the user provided value in the error string in case it contains large amount of data. Dump large input data to log might crash on user side.
    
    https://github.com/tensorflow/tensorflow/issues/37840
    
    PiperOrigin-RevId: 303980671
    Change-Id: I1e2a6d3091c98bad0fcdd0e59c0eb88cd1d36956

commit e6e5d6df2ab26620548f35bf2e652b19f6d06652
Merge: f4b139e5f59 ce7990b1661
Author: Goldie Gadde <ggadde@google.com>
Date:   Thu Mar 26 15:19:19 2020 -0700

    Merge pull request #37919 from reedwm/none_grad_fix
    
    2.2-rc2 cherry-pick request: Fix crash in Model.fit() if a gradient is None

commit 6e920629c520f69a92dc5730260d4039356c4cc4
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Thu Mar 26 13:09:07 2020 -0700

    Fix crash when trying to look through blockarg
    
    PiperOrigin-RevId: 303178864
    Change-Id: I1eb1560c3e236e5b566c5b69be98ebf74582c549

commit 54ed7b661ec37578fcb758ccf03d26cb215594b3
Merge: 006d57e623f 10e5748ddfc
Author: Goldie Gadde <ggadde@google.com>
Date:   Thu Mar 26 11:52:01 2020 -0700

    Merge pull request #37918 from reedwm/mp_vis_dev
    
    2.2-rc2 cherry-pick request: Fix crash if set_visible_devices() is used with tf.keras.mixed_precision.

commit 908cb44d13b7ea24e20f1c39e90c14928b1018fc
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Fri Mar 20 15:10:05 2020 -0700

    Fix crash in Model.fit() if a gradient is None, attempt 2.
    
    I first submitted this in 3931d39379b9feb44d4f8edba0906e96629d6884 but was rolled back since Nones were filtered out from the gradients, but not the variables. I now add Nones back to the gradients so they properly match up.
    
    PiperOrigin-RevId: 302107549
    Change-Id: I81b7fb71c9cdaa458475d83f784366ce8405fb74

commit 10e5748ddfcf0c60e5ef0a90bb72a34bc55190ec
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon Mar 23 18:08:14 2020 -0700

    Fix crash if set_visible_devices() is used with tf.keras.mixed_precision.
    
    Unfortunately, this required disabling the warning that would appear if mixed precision was used on a GPU that didn't fully support it. A warning will still appear if there is no GPU, but no log will appear if the user does have a GPU, because in that case we cannot tell if the GPU is support or not. I will try to get the warning back by 2.3.
    
    PiperOrigin-RevId: 302561652
    Change-Id: Ic73d06a4531a052009e83080de7af257042f33e1

commit e1afcc5feb844cbd576ecc8712a6ed8e96886cef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Mar 24 09:36:35 2020 -0700

    Fix a crash when combining step databases among multiple GPU hosts.
    
    PiperOrigin-RevId: 302683087
    Change-Id: I3807b55b85efcc216ede6f7c2b439543a64b3b51

commit f748283ee01059be52da5dada6e2157d9f6732ba
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon Mar 23 18:08:14 2020 -0700

    Fix crash if set_visible_devices() is used with tf.keras.mixed_precision.
    
    Unfortunately, this required disabling the warning that would appear if mixed precision was used on a GPU that didn't fully support it. A warning will still appear if there is no GPU, but no log will appear if the user does have a GPU, because in that case we cannot tell if the GPU is support or not. I will try to get the warning back by 2.3.
    
    PiperOrigin-RevId: 302561652
    Change-Id: Ic73d06a4531a052009e83080de7af257042f33e1

commit ce3ba1058f055d3c924dd0a8e71ef343ef649630
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Fri Mar 20 15:10:05 2020 -0700

    Fix crash in Model.fit() if a gradient is None, attempt 2.
    
    I first submitted this in 3931d39379b9feb44d4f8edba0906e96629d6884 but was rolled back since Nones were filtered out from the gradients, but not the variables. I now add Nones back to the gradients so they properly match up.
    
    PiperOrigin-RevId: 302107549
    Change-Id: I81b7fb71c9cdaa458475d83f784366ce8405fb74

commit 308835c96a6488e8c7ec95fbb309e09072cd8799
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Mar 19 21:44:19 2020 -0700

    Fix crash in Model.fit() if a gradient is None.
    
    The crash would occur with distributed strategy if multiple devices were used.
    
    PiperOrigin-RevId: 301958941
    Change-Id: I92081f22b66f62e7749525e2c292d45262ab9ae7

commit 3931d39379b9feb44d4f8edba0906e96629d6884
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Thu Mar 19 20:34:36 2020 -0700

    Fix crash in Model.fit() if a gradient is None.
    
    The crash would occur with distributed strategy if multiple devices were used.
    
    PiperOrigin-RevId: 301951658
    Change-Id: I2e596599bec19f1caa7cf41bd70771a7e6f7541d

commit 68ab2e4c4a6c3cc68788633b2b89f3cee1019028
Author: Frederic Bastien <fbastien@nvidia.com>
Date:   Mon Mar 16 10:26:19 2020 -0700

    Crash fix. We where not returning the right reduction tile size.

commit 6e2afa622bba0f15aa68e2291a7c5b63ac9e3e70
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Thu Mar 12 19:13:39 2020 -0700

    Use dyn_cast_or_null to avoid isa on null pointer
    
    * Avoids crashing with unset values;
    * Also don't fail extracing version if no minimum of bad version specified (as
      there may be no mimimum or bad verion), but do require producer.
    
    PiperOrigin-RevId: 300672607
    Change-Id: I82a4c2b1042553bebbc2d2377a2efbd75f3bf917

commit 97e1e8091a9f61b7079de9bbaf4aaacdc6ef51bd
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Mar 9 15:58:02 2020 -0700

    Using unaligned_flat() instead of flat() for Expectors.
    
    Otherwise, the Expectors may crash on unaligned Tensors such as what's returned by Tensor::Slice().
    
    PiperOrigin-RevId: 299956868
    Change-Id: I2fd7f7db2f03c4d536b6923eb2f876df931e9b09

commit de9444744b5be870823673583df048712a70d2d1
Author: Peng Wang <wangpeng@google.com>
Date:   Fri Mar 6 16:27:34 2020 -0800

    Fixed a crash when calling tf.searchsorted with zero-sized `values`.
    
    PiperOrigin-RevId: 299461014
    Change-Id: I013fae9606f56a8ebefec6f15eabd14e381b5b15

commit e82714b529db1da849148ab784959aa3a9682224
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Mar 2 11:35:59 2020 -0800

    make sure we capture up to 1 million trace events to avoid crashing the trace viewer. add an unit-test
    
    PiperOrigin-RevId: 298403826
    Change-Id: Idfcbf9501e9d2a626828c83501b2c548b8df48dd

commit 07be61a93210f1b9590683f1de7edabe2e29075b
Author: Ben Barsdell <bbarsdell@nvidia.com>
Date:   Fri Feb 28 20:06:35 2020 +1100

    Address auto_mixed_precision PR 37101 review comments
    
    - Make constant op sets `static`.
    - Simplify logic for blacklisting clusters of Tensor List ops.
    - Change `/*D*/ CHECK` to `CHECK // Crash OK`.
    - Remove old comment.
    - Add TODO for more Python tests.
    - Add comments regarding assumptions made and other info.

commit a7e7d41d567ee5993cf8f7dcb0d9fa05fbc0cb85
Author: Sanjoy Das <sanjoy@google.com>
Date:   Mon Feb 24 16:45:08 2020 -0800

    Do not crash if we failed to write the PTX file in CompileGpuAsm
    
    PiperOrigin-RevId: 297001867
    Change-Id: Ib3599555912a2257e6d88b812cb3c00ba2f907d8

commit 71389a324ac07fc068bb0aaa4c336dd25707fde0
Author: Edward Loper <edloper@google.com>
Date:   Mon Feb 24 12:01:01 2020 -0800

    Bug fixes for tf.sparse.cross (avoid crashes on bad inputs)
    
    * Updated ValidateInput & CreateOutputTensors to return a Status, rather than calling OP_REQUIRES_OK.  (Calling OP_REQUIRES_OK in a helper function will register the error, but won't stop execution -- this means that execution continues until we reach a fatal error, causing TF to have a hard crash).
    
    * Updated the order of some tests to avoid crashes.
    
    PiperOrigin-RevId: 296943120
    Change-Id: Ia4e471eeae6a9b1d5e8dd9929ebf59bf20992479

commit d9444a76c0db31d205f6f8ff12997ad7fc777aa9
Author: Terry Heo <terryheo@google.com>
Date:   Thu Feb 20 19:07:48 2020 -0800

    Fix crashing on GPU elementwise ops
    
    Pass ElementwiseAttributes para as a pointer to check if it's valid or not.
    
    PiperOrigin-RevId: 296348071
    Change-Id: Ia0a4149605d5fbff5f6a08176ea7eb004bb23315

commit 4249696badf668410832a3444712a730dcebde7e
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Thu Feb 20 17:22:15 2020 -0800

    Do not crash if losses have different dtypes.
    
    Also change mixed precision tests to no longer cast losses to float32, as this is no longer necessary, even when regularizers are used (which always are float32)
    
    PiperOrigin-RevId: 296333364
    Change-Id: I2f026815b6b71a701ad3975654cef1fe26ea0728

commit a165c7fa08502e19ae822d0238bac45c40af3c76
Merge: 2c1f7ac1a32 cf8d3b17aef
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Thu Feb 20 10:59:58 2020 -0800

    Merge pull request #36856 from wwwind:crash_conv_dilation
    
    PiperOrigin-RevId: 296249506
    Change-Id: Ic6401824fab91257354e8ae3dfbbdba505304f3c

commit e4381fd70b46b0a860e9970dd18f427fe94c1291
Author: Mehdi Amini <aminim@google.com>
Date:   Tue Feb 18 11:24:05 2020 -0800

    Change BreakupIslands pass from an Operation pass into a Function pass
    
    This is fixing a crash when there are external functions in the module.
    The subtle difference between:
    
      OperationPass<BreakUpIslands, FuncOp>
    
    and:
    
      FunctionPass<BreakUpIslands>
    
    is that the latter will skip over external functions (functions without a body)
    but not the former.
    
    PiperOrigin-RevId: 295780488
    Change-Id: I032e806bbc7d8e80375fa776bdc8873f850d7c58

commit 00302ef2856b7965b0057f1f601bd8bfade9becf
Author: Brian Atkinson <bca@google.com>
Date:   Mon Feb 10 11:39:10 2020 -0800

    CreateTestFile doesn't need to crash on failure.
    
    An expectation should, for all existing cases, work fine. This may result in later assertions also failing, but it should be fairly benign.
    
    PiperOrigin-RevId: 294267513
    Change-Id: I2ad3e31d9151306a6bc29ef78199739c6d1583ee

commit e45c9f22722df4d967bf81467f1691cc6b8e864b
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Thu Feb 6 17:48:10 2020 -0800

    Fix crash when unfused layer normalization used with mixed precision.
    
    For numeric safety, I do the unfused layer normalization in fp32, as parts of the fused version are internally done in fp32. I'm not sure if doing the layer normalization in fp32 over fp16 makes a difference in practice.
    
    PiperOrigin-RevId: 293717765
    Change-Id: Ie91ed55d73b02b93530a72f917243c39a37e7430

commit 959d49e2d3f77332e5dce4fadbffe2612949b91c
Author: Yunxing Dai <yunxing@google.com>
Date:   Thu Jan 30 21:50:35 2020 -0800

    Be defensive when parsing first operand of send/recv-done that is not channel.
    
    Calling channel_id() on a non-channel instruction would lead to a hard
    crash instead of parser failure.
    
    PiperOrigin-RevId: 292484404
    Change-Id: I2dd39bc8db6f71b5079cfda59efa8316fc3f0e40

commit f9e899854cc96db28564fa65f22d32a647268fc1
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon Jan 27 16:23:55 2020 -0800

    Fix crash when float64 or mixed precision used in certain layers.
    
    Also add many more tests to layer_corectness_test.py, so that most Keras layers are tested.
    
    Also do not test distribution strategy without mixed precision in layer_corectness_test.py. This previuosly was only tested for ease of debugging if a test failed. But the distribution strategy tests take a very long time, so it's not worth testing with distribution strategy without mixed precision.
    
    I made the test a py_test instead of a cuda_py_test to save a bit of GPU resources.
    
    Fixes #35817 and fixes #35883.
    
    PiperOrigin-RevId: 291825015
    Change-Id: I8ece6de5b9d549f0de06b643774686f56775781e

commit 93fbba3529493c7d4bf436bb96e7c7cba045a639
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Wed Jan 22 13:07:39 2020 -0800

    Fix crash if tf.transpose used with tf.LossScaleGradientTape.
    
    Thank you @benbarsdell for finding and debugging this issue
    
    PiperOrigin-RevId: 291014436
    Change-Id: I8f82a5e35f0818c799332b29c3abcb35b5484b3d

commit 34b72b3120e94224fe81dfa134fe7d99fc0fa29e
Author: Dan Moldovan <mdan@google.com>
Date:   Thu Jan 16 05:48:11 2020 -0800

    Fix bug causing tf.sparse.expand_dims to crash for arguments of dynamic dense rank.
    
    PiperOrigin-RevId: 290049840
    Change-Id: I0a99bbf41e21f75511edefb75c49994a3323f963

commit 5521416058f85c044c96aa8d5b5c6105472e7093
Author: Andrew Selle <aselle@google.com>
Date:   Thu Jan 9 14:34:45 2020 -0800

    Avoid crashing if allocate_tensors hasn't been called on tflite python bindings
    
    - Check for nullptr on tensor before executing set_tensor()
    - Provide helpful suggestion
    
    Fixes #35675
    
    PiperOrigin-RevId: 288974466
    Change-Id: If5fcf722e31e9b1c9b563728b88c71699d11d195

commit c6c81bc1732c1a8255f2ac8850cedcaab1c0ddea
Author: Benoit Jacob <benoitjacob@google.com>
Date:   Mon Jan 6 11:27:49 2020 -0800

    Keep only the simple auxv method for detecting dotprod instructions.
    It's available on Linux >= 4.15 in general; on Android, at least Linux 4.14.111 thanks to a late backport. This was backported just before the Android 10 release, so this is leaving out pre-release Android 10 builds as well as earlier Android versions.
    
    Part of the rationale for submitting this now is an understanding that most devices with new hardware supporting dotprod instructions either shipped with Android 10 in the first place (Pixel4) or have received an Android 10 update already (LG G8, Samsung Galaxy S10, Note 10). We are probably leaving some devices unsupported, but conversely the signal-handler detection method that this is removing was reported to cause crashes on other devices, so this is a compromise. At least now we won't crash anywhere, at worst some devices won't get the speedup from dotprod instructions.
    
    PiperOrigin-RevId: 288340160
    Change-Id: I9f1b934f4e3996456af0489b780d567596f6db92

commit 08e24370367fb96d1bf050a39560cce488ea7f7e
Author: Alexandre Passos <apassos@google.com>
Date:   Thu Jan 2 12:32:30 2020 -0800

    Filters concrete functions which closure capture graph tensors from savedmodels.
    
    It doesn't make sense to serialize those functions as their own endpoints
    or to allow calling them directly from the loaded module but they should
    still be in the metagraph's function library as otherwise calling the root
    functions will crash.
    
    PiperOrigin-RevId: 287876746
    Change-Id: I3401f65f7beb21cdda13cdf7bda9fc0f0cfa4156

commit d393d5d7528ff4b7a5ff602aadb2c144d7c7ac58
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Thu Jan 2 11:48:05 2020 -0800

    Fix various bugs in LossScaleGradientTape.
    
    The following bugs are fixed:
    1. Crash when gradients were taken w.r.t. distributed variables.
    2. Crash when targets or sources were not float32.
    3. Crash when some gradients were None.
    4. Bogus gradients returned when loss scale was 1.
    
    Several error messages were also greatly improved, such as when the jacobian is taken.
    
    Changed tests to take gradients w.r.t. variables instead of tensors, as this is the more common case.
    
    In the future, we may simply the code by having each replica have an independent loss scale. This means we do not have to synchronize the loss scales, which would greatly simplify the LossScaleGradientTape implementation, and probably improve performance as well. The downside is that not having a single loss scale may be more confusing to users. For now, I kept a single loss scale, as we have not yet decided if we want to go with this approach.
    
    PiperOrigin-RevId: 287869750
    Change-Id: Ie60aa3f9721f78ab3fe857d4fdb0d1f70fa84faf

commit 2135def33887704d93301cdcb8fef5abf8cbf275
Author: Frederic Bastien <fbastien@nvidia.com>
Date:   Thu Dec 19 14:29:10 2019 -0800

    Fix compilation crash. ParseFromStringPiece isn't defined.

commit f6319c0d48b2850276416aa1a2cb7e19688eaa18
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Dec 17 12:08:24 2019 -0800

    Don't crash on empty inputs to AvgPoolOp{Grad}.
    
    PiperOrigin-RevId: 286030391
    Change-Id: I9c3a6f6104b23929b36078c4eca36da79eb245ce

commit fcff4705cbe7e9513251d1f4d8010e61d9175261
Author: Thai Nguyen <thaink@google.com>
Date:   Thu Dec 12 21:08:34 2019 -0800

    Fix GPU delegate crash with C++17
    
    PiperOrigin-RevId: 285331240
    Change-Id: I57d96c99828282181d4054db15db4e0efb10fcd7

commit 688c9d1d9434045f2b89fe19fd2e51a41e5560fa
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Wed Dec 11 14:15:13 2019 -0800

    Unexpose LossScaleGradientTape.
    
    It doesn't support DistributionStrategy. It will be reexposed when it does. I tried to fix this in #34974, but only made the issue worse. The issue is that when taking gradients with respect to variables (which occurs almost every time), it would crash with a very long error message when DistributionStrategy is used. The unit tests only tested taking gradients w.r.t. constants, as it was assumed there would be no functional difference between taking gradients w.r.t. variables and constants.
    
    PiperOrigin-RevId: 285059221
    Change-Id: I9ffc5d68f092f9ff3ea634b9523b67ff2bbc4bd7

commit c373e83e340f75a3de32bb4ea66728a064efbfe5
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Wed Dec 11 14:15:13 2019 -0800

    Unexpose LossScaleGradientTape.
    
    It doesn't support DistributionStrategy. It will be reexposed when it does. I tried to fix this in #34974, but only made the issue worse. The issue is that when taking gradients with respect to variables (which occurs almost every time), it would crash with a very long error message when DistributionStrategy is used. The unit tests only tested taking gradients w.r.t. constants, as it was assumed there would be no functional difference between taking gradients w.r.t. variables and constants.
    
    PiperOrigin-RevId: 285059221
    Change-Id: I9ffc5d68f092f9ff3ea634b9523b67ff2bbc4bd7

commit e33e506430f3c55871cc5a2ef0fc38be56471e41
Author: Benjamin Kramer <kramerb@google.com>
Date:   Wed Dec 11 06:05:14 2019 -0800

    [XLA:CPU] Make call rewriting resilient about non-call uses
    
    The optimizer is free to do whatever it wants with a function, so there can be
    references around that we can't inline.
    
    LLVM head triggers this by sometimes adding vectorized functions to
    llvm.compiler.used. This is unneccessary and should be fixed upstream, but XLA
    shouldn't crash when that happens.
    
    PiperOrigin-RevId: 284970424
    Change-Id: If9a2dad425db4da86c199dd5add4bc21a7b0eafc

commit bd045624683452a3100a98cf1c061a787cf444bb
Author: Peter Ma <pcma@google.com>
Date:   Fri Dec 6 15:15:31 2019 -0800

    Added a guard to prevent from crashing for certain cases.
    
    PiperOrigin-RevId: 284272480
    Change-Id: Idb6e566037d83406921e5d318aaa4d35a336edfa

commit 4198b1c7315aef7b86b2c07c8b29d5c42791aaf1
Author: Sean Silva <silvasean@google.com>
Date:   Thu Dec 5 15:18:26 2019 -0800

    Produce better error message on SavedModel import failure
    
    This will now produce a useful error message like this instead of crashing:
    ```
    Invalid argument: While importing SavedModel function 'terminal.consume': in input signature: Unhandled structured value kind 12 at index path: <value>.1
    This likely means that you have @tf.function on an exported function instead of @tf.function(input_signature=[...]). Consider narrowing your set of exported names.
    ```
    
    PiperOrigin-RevId: 284065012
    Change-Id: I0cdcfc95b9d4d5f2950f79e5124bcc2fae84e75c

commit 7f458cfe95e5a8423e3fd53b66135ecc2ea85210
Author: River Riddle <riverriddle@google.com>
Date:   Thu Dec 5 09:59:52 2019 -0800

    Add a flag to dump the current stack trace when emitting a diagnostic.
    
    It is often desirable to know where within the program that a diagnostic was emitted, without reverting to assert/unreachable which crash the program. This change adds a flag `mlir-print-stacktrace-on-diagnostic` that attaches the current stack trace as a note to every diagnostic that gets emitted.
    
    PiperOrigin-RevId: 283996373
    Change-Id: I51392e0a93e8a687d9069afa64d048cb7110242a

commit 48e88283dbed3fb9129d69b867dfb2ae1f7fec2d
Author: River Riddle <riverriddle@google.com>
Date:   Wed Dec 4 15:49:09 2019 -0800

    Add emitOptional(Error|Warning|Remark) functions to simplify emission with an optional location.
    
    In some situations a diagnostic may optionally be emitted by the presence of a location, e.g. attribute and type verification. These situations currently require extra 'if(loc) emitError(...); return failure()' wrappers that make verification clunky. These new overloads take an optional location and a list of arguments to the diagnostic, and return a LogicalResult. We take the arguments directly and return LogicalResult instead of returning InFlightDiagnostic because we cannot create a valid diagnostic with a null location. This creates an awkward situation where a user may try to treat the, potentially null, diagnostic as a valid one and encounter crashes when attaching notes/etc. Below is an example of how these methods simplify some existing usages:
    
    Before:
    
      if (loc)
        emitError(*loc, "this is my diagnostic with argument: ") << 5;
      return failure();
    
    After:
    
      return emitOptionalError(loc, "this is my diagnostic with argument: ", 5);
    
    PiperOrigin-RevId: 283853599
    Change-Id: Icc28f0257f7a4ffa96e14e61e57c5340c868f17d

commit d2e9dc16d1418b81f9d0d59eac7886fe65798ebd
Author: Sean Silva <silvasean@google.com>
Date:   Wed Dec 4 10:19:20 2019 -0800

    Print out large elementsattr's such that they are parseable.
    
    I found that when running crash reproducers, the elided elementsattr's
    would prevent parsing the IR repro. I found myself manually going and
    replacing the "..." with some valid IR.
    
    With this change, we now print elided attrs as `opaque<"", "0xDEADBEEF">`
    to clearly delineate them as being elided while still being parseable.
    
    PiperOrigin-RevId: 283781806
    Change-Id: I44aef05323e5577f64078a084a7271b3b2c2caa1

commit 8f467074608f328f8e5becc754ab271847aa2941
Author: Sean Silva <silvasean@google.com>
Date:   Tue Dec 3 14:00:36 2019 -0800

    Make diagnostic a bit clearer.
    
    This prints out in case of any pass failure. Not just a crash.
    
    PiperOrigin-RevId: 283616719
    Change-Id: I31ee68cd17dcc3867f7a5e6a1bf21ca336cecc63

commit d393702997fcf9beb9048778413d387ed30e296c
Author: Benjamin Kramer <kramerb@google.com>
Date:   Thu Nov 28 06:24:54 2019 -0800

    [XLA:CPU] Register replica-id IR
    
    Otherwise any use of replica-id as an argument to another operation crashes.
    
    PiperOrigin-RevId: 282934610
    Change-Id: Iab3957f85910fd1f453c6d1b9043c9d220ece633

commit d79ffabd36a04402a9dfa2089ff3d980fd6fee10
Author: Tim Shen <timshen@google.com>
Date:   Wed Nov 20 16:30:14 2019 -0800

    Correctly parse empty affine maps.
    
    Previously the test case crashes / produces an error.
    
    PiperOrigin-RevId: 281630540
    Change-Id: Ide40094fdffb48d86b116e2916880b84ff2ed869

commit f68bd0e9ac5693d09ab99d95c5254114995d56ec
Author: Lei Zhang <antiagainst@google.com>
Date:   Thu Nov 14 11:02:52 2019 -0800

    [ODS] Fix operation argument population to avoid crash
    
    The `Operator` class keeps an `arguments` field, which contains pointers
    to `operands` and `attributes` elements. Thus it must be populated after
    `operands` and `attributes` are finalized so to have stable pointers.
    SmallVector may re-allocate when still having new elements added, which
    will invalidate pointers.
    
    PiperOrigin-RevId: 280466896
    Change-Id: I8cfeb990e249810a215930f2d2ed33db9e93f45d

commit 64ec59096a3afd5ed89f3c5c8876afddb49347ff
Author: Lei Zhang <antiagainst@google.com>
Date:   Thu Nov 14 11:02:52 2019 -0800

    [ODS] Fix operation argument population to avoid crash
    
    The `Operator` class keeps an `arguments` field, which contains pointers
    to `operands` and `attributes` elements. Thus it must be populated after
    `operands` and `attributes` are finalized so to have stable pointers.
    SmallVector may re-allocate when still having new elements added, which
    will invalidate pointers.
    
    PiperOrigin-RevId: 280466896

commit b6cbff89d15c237745c7d6a16ee37ccb2bd3f09d
Author: Allen Lavoie <allenl@google.com>
Date:   Wed Nov 13 13:49:19 2019 -0800

    Make empty tensors of resource handles less crashy
    
    PiperOrigin-RevId: 280271103
    Change-Id: Ibc39a41117114e17358bf9c15e59fc1c7f086914

commit a895bdaf05f49117634c510ebfa20e47cbc9a679
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Nov 11 15:47:31 2019 -0800

    Return if an error status was set in LinearAlgebraOp::AnalyzeInput() or LinearAlgebraOp::PrepareOutputs(), instead of potentially crashing.
    
    PiperOrigin-RevId: 279834647
    Change-Id: Iaef1b3598eaee212c75e397f4ffafce0ebfdf8b8

commit 2e6d84b216cc36a7f8d39abf756d270c1bf5e2ba
Author: Guangda Lai <laigd@google.com>
Date:   Mon Nov 11 01:06:33 2019 -0800

    Lazily load the wrap_py_utils module so that python binaries that doesn't have
    access to the wrapped dso won't crash at startup.
    
    PiperOrigin-RevId: 279687622
    Change-Id: Ie79cd36f259976347821f991ac3397500465e4a4

commit 755aec33ef4bb52ea69669d8287c85b0a08b5cdd
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Nov 8 17:32:50 2019 -0800

    Don't crash on empty RHS in matrix_triangular_solve on GPU.
    
    PiperOrigin-RevId: 279424548
    Change-Id: I59b10866bd99f9e92e8714fc1b1a05674b301ce8

commit a94a7a4bfb7b7da365a28c24a7d2131afd55bb59
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Nov 1 12:00:31 2019 -0700

    Properly increment none refcount when returning from status caster.
    
    Otherwise this will lead to crashes when the refcount of none drops to 0.
    
    PiperOrigin-RevId: 277973520
    Change-Id: I8abf8450bec0dcf07c915189f2ab75ca9a787e1b

commit 0f08466d733a81db6c3e9504563bcde56ee944f6
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Oct 30 19:40:49 2019 -0700

    [XLA:Python] Fix crash using bfloat16 arrays.
    
    PiperOrigin-RevId: 277635061
    Change-Id: I2cf46e802644f5dd74af0ba5d670789aefb84d21

commit 83569dfad98f7137dcf38593722fd16674ae632e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Oct 28 14:50:47 2019 -0700

    Removes two Keras fallbacks to older v1 code:
    1. when calling predict without compiling first.
    2. when using a tf.compat.v1.optimizers.Optimizer (these work eagerly & should work in the v2 loops)
    
    This revealed some missing coverage in the tests & a few bugs.
    
    The fixes to these issues are are:
    1. Int sample weights used with masks now work correctly (w/o type crashes)
    2. Keras in TF2 explicitly disallows using sparse scipy matrices as inputs to dense functional model inputs. A meaningful error is now raised whereas before this crashed w/ unclear messages. In v1 the scipy matrices were silently cast to dense arrays, but this causes ambiguity for subclass models & can't be done w/o too much extra complexity for the data adapters.
    3. This cl needs to mark a few tests that depend on v2 dtype behavior as run_v2_only, and changes a few tests to v1_deprecated
    
    PiperOrigin-RevId: 277148078
    Change-Id: Ic794104d85f999f0b449cc606df85f1e4cc5b8ed

commit c6b2a2a87b05406a75d29641e625fd0eaa92a781
Author: Brian Atkinson <bca@google.com>
Date:   Mon Oct 28 14:37:58 2019 -0700

    `{` was left unescaped.
    
    Building genrules in debug mode (asserts turned on) results in this crashing:
    
    ERROR: tensorflow/compiler/mlir/lite/BUILD:401:1: Couldn't build file tensorflow/compiler/mlir/lite/operator_converters.inc: Executing genrule //tensorflow/compiler/mlir/lite:operator_converter_inc failed (Aborted): bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)
    operator-converter-gen: external/llvm/lib/Support/FormatVariadic.cpp:117: static std::pair<llvm::ReplacementItem, llvm::StringRef> llvm::formatv_object_base::splitLiteralAndReplacement(llvm::StringRef): Assertion `false && "Unterminated brace sequence.  Escape with {{ for a literal brace."' failed.                                                                                                                                                                                   Stack dump:
    0.      Program arguments: bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen -I external/local_config_mlir/include -I external/org_tensorflow tensorflow/compiler/mlir/lite/ir/tfl_ops.td -o bazel-out/host/bin/tensorflo
    w/compiler/mlir/lite/operator_converters.inc                                                                                                                                                                                                   bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xe6bc4)[0x56141b511bc4]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xe6c57)[0x56141b511c57]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xe4a73)[0x56141b50fa73]                                                                                                                                              bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xe656f)[0x56141b51156f]
    /lib/x86_64-linux-gnu/libpthread.so.0(+0x123a0)[0x7ff68d5733a0]                                                                                                                                                                                /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x10b)[0x7ff68d1d8cfb]                                                                                                                                                                                 /lib/x86_64-linux-gnu/libc.so.6(abort+0x129)[0x7ff68d1c38ad]
    /lib/x86_64-linux-gnu/libc.so.6(+0x2177f)[0x7ff68d1c377f]                                                                                                                                                                                      /lib/x86_64-linux-gnu/libc.so.6(+0x2f542)[0x7ff68d1d1542]                                                                                                                                                                                      bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xa992d)[0x56141b4d492d]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0xa9b7b)[0x56141b4d4b7b]                                                                                                                                              bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x1abc6)[0x56141b445bc6]                                                                                                                                              bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x1d36d)[0x56141b44836d]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x1c009)[0x56141b447009]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x198e3)[0x56141b4448e3]                                                                                                                                              bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x19de6)[0x56141b444de6]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x2bd57)[0x56141b456d57]                                                                                                                                              bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x19ea7)[0x56141b444ea7]                                                                                                                                              /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xeb)[0x7ff68d1c552b]
    bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen(+0x1827a)[0x56141b44327a]                                                                                                                                              /bin/bash: line 1: 155940 Aborted                 bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator-converter-gen -I external/local_config_mlir/include -I external/org_tensorflow tensorflow/compiler/mlir/lite/ir/tfl_ops.td -o bazel-out/host/bin/tensorflow/compiler/mlir/lite/operator_converters.inc
    PiperOrigin-RevId: 277145188
    Change-Id: Ib3a6ad2ff79092ccd9f7a02ec901254c8b9b87ee

commit 5bd540913203d28454d8389194a21b1dd9c8442e
Author: Abdlhamit Yilmaz <mr.yilmaz@gmx.de>
Date:   Mon Oct 28 15:18:59 2019 +0100

    Fix Crash When input_size Is an int

commit 268229dfedd5ee95ddb8028625a3b27ae5361a50
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Oct 23 17:45:23 2019 -0700

    Removes two Keras fallbacks to older v1 code:
    1. when calling predict without compiling first.
    2. when using a tf.compat.v1.optimizers.Optimizer (these work eagerly & should work in the v2 loops)
    
    This revealed some missing coverage in the tests & a few bugs.
    
    The fixes to these issues are are:
    1. Int sample weights used with masks now work correctly (w/o type crashes)
    2. Keras in TF2 explicitly disallows using sparse scipy matrices as inputs to dense functional model inputs. A meaningful error is now raised whereas before this crashed w/ unclear messages. In v1 the scipy matrices were silently cast to dense arrays, but this causes ambiguity for subclass models & can't be done w/o too much extra complexity for the data adapters.
    3. This cl needs to mark a few tests that depend on v2 dtype behavior as run_v2_only, and changes a few tests to v1_deprecated
    
    PiperOrigin-RevId: 276388163
    Change-Id: I0c31e4e6aa16793f119f6f0184a93b294db3d030

commit cc5404eb642094885a75993806e6a8fd86ceee74
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Oct 23 04:04:28 2019 -0700

    Don't crash if failed to dump execution options
    
    Instead of using TF_CHECK_OK we should just log an error and continue
    the same way we do for the case when dumping the HLO module failed.
    
    PiperOrigin-RevId: 276247364
    Change-Id: I61171165910e5829d0f9271f3fc8197d462cfcb9

commit 2133490bf22be577928ad9d3ebdd56ac2260f8d5
Author: George Karpenkov <cheshire@google.com>
Date:   Fri Oct 18 07:54:57 2019 -0700

    Crash on @tf.function(experimental_compile=True) in non-eager mode
    
    experimental_compile=True is only propagated in eager mode, it is better to
    crash explicitly.
    PiperOrigin-RevId: 275470969
    Change-Id: Icae827695335e1d68a0fed0cd9db8978458ed846

commit f476212772d1b51b7fd6bfa01b092c7dea50eebf
Author: Lei Zhang <antiagainst@google.com>
Date:   Thu Oct 17 07:25:50 2019 -0700

    Add LLVM_DEBUG in RewritersGen.cpp and Pattern.cpp
    
    It's usually hard to understand what went wrong if mlir-tblgen
    crashes on some input. This CL adds a few useful LLVM_DEBUG
    statements so that we can use mlir-tblegn -debug to figure
    out the culprit for a crash.
    
    PiperOrigin-RevId: 275253532
    Change-Id: Ic008da3ffb3bff321df65ce516499fdf01dab438

commit 2ec5e386f19ecf3614fb32a6d7bee275509843a4
Author: Lei Zhang <antiagainst@google.com>
Date:   Thu Oct 17 07:25:50 2019 -0700

    Add LLVM_DEBUG in RewritersGen.cpp and Pattern.cpp
    
    It's usually hard to understand what went wrong if mlir-tblgen
    crashes on some input. This CL adds a few useful LLVM_DEBUG
    statements so that we can use mlir-tblegn -debug to figure
    out the culprit for a crash.
    
    PiperOrigin-RevId: 275253532

commit 88a10e78f7c0c8cecc588bc606e66e52cc229806
Author: River Riddle <riverriddle@google.com>
Date:   Thu Oct 10 21:57:24 2019 -0700

    NFC: Print the generic op form after pass failure.
    
    On failure, the IR is likely to be in an invalid state, meaning the custom printer for some operations may now crash. Using the generic op form prevents this from happening.
    
    PiperOrigin-RevId: 274104146

commit e8fc11fb63571447a9d4745f52c2d4d5c3494d61
Author: River Riddle <riverriddle@google.com>
Date:   Thu Oct 10 19:19:11 2019 -0700

    Add support for generating reproducers on pass crash and failure.
    
    This cl adds support for generating a .mlir file containing a reproducer for crashes and failures that happen during pass execution. The reproducer contains a comment detailing the configuration of the pass manager(e.g. the textual description of the pass pipeline that the pass manager was executing), along with the original input module.
    
    Example Output:
    
    // configuration: -pass-pipeline='func(cse, canonicalize), inline'
    // note: verifyPasses=false
    
    module {
      ...
    }
    
    PiperOrigin-RevId: 274088134

commit 85ce9db5eb43fb36dbaf0b724dd3fd7ac59df8a7
Author: River Riddle <riverriddle@google.com>
Date:   Thu Oct 10 21:57:24 2019 -0700

    NFC: Print the generic op form after pass failure.
    
    On failure, the IR is likely to be in an invalid state, meaning the custom printer for some operations may now crash. Using the generic op form prevents this from happening.
    
    PiperOrigin-RevId: 274104146

commit 3233929344cb17564369670aa3a37eb05f7abceb
Author: River Riddle <riverriddle@google.com>
Date:   Thu Oct 10 19:19:11 2019 -0700

    Add support for generating reproducers on pass crash and failure.
    
    This cl adds support for generating a .mlir file containing a reproducer for crashes and failures that happen during pass execution. The reproducer contains a comment detailing the configuration of the pass manager(e.g. the textual description of the pass pipeline that the pass manager was executing), along with the original input module.
    
    Example Output:
    
    // configuration: -pass-pipeline='func(cse, canonicalize), inline'
    // note: verifyPasses=false
    
    module {
      ...
    }
    
    PiperOrigin-RevId: 274088134

commit f21df3d1548794a320b0f944c83465c9827bd7d3
Author: Prakalp Srivastava <prakalps@google.com>
Date:   Wed Oct 9 08:24:38 2019 -0700

    Return error instead of failing on assert.
    
    The number of input arguments are expected to be of same as the length of _input_shapes attribute (if present) in a function def. Instead of crashing on this assert, return a failed status.
    
    PiperOrigin-RevId: 273750115

commit cea968877b68b0bca7d7e40cbae2e6cac741aec4
Author: Lei Zhang <antiagainst@google.com>
Date:   Mon Oct 7 14:40:18 2019 -0700

    [spirv] Disable a crashing spv.loop test
    
    PiperOrigin-RevId: 273379318

commit c5c69cd6a871751b12d11a7d24b9d5e9681f08bf
Author: Lei Zhang <antiagainst@google.com>
Date:   Fri Oct 4 20:08:05 2019 -0700

    [spirv] Allow return ops to be in control flow ops
    
    Use `getParentOfType<FunctionOp>()` instead of `cast<FuncOp>(getParentOp())`
    to avoid crash when return ops are used inside spv.selection/spv.loop.
    
    PiperOrigin-RevId: 273006041

commit 9ecd7371859bda4e5f161f410fa585bfecac4a06
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Fri Oct 4 15:47:30 2019 -0700

    Disable cudnn RNN on GRU V2 with distribution strategy or mixed precision.
    
    Before, it would crash or give completely incorrect output with distribution strategy or mixed precision.
    
    PiperOrigin-RevId: 272973619

commit bfbf171b5304f6a4f51ced0da5c6f29cdf734b31
Author: Lei Zhang <antiagainst@google.com>
Date:   Fri Oct 4 20:08:05 2019 -0700

    [spirv] Allow return ops to be in control flow ops
    
    Use `getParentOfType<FunctionOp>()` instead of `cast<FuncOp>(getParentOp())`
    to avoid crash when return ops are used inside spv.selection/spv.loop.
    
    PiperOrigin-RevId: 273006041

commit d7d83ef6a6289a95994e8ce58ccbbbe002d32ef5
Author: Nicolas Vasilache <ntv@google.com>
Date:   Fri Oct 4 08:07:12 2019 -0700

    Add missing Linalg lowerings to allow roundtrip.mlir to lower to LLVM
    
    Certain lowering patterns were reported as [missing](https://groups.google.com/a/tensorflow.org/forum/#!topic/mlir/dkdmHa77sSQ).
    
    This CL adds them and allows Linalg/roundtrip.mlir and Linalg/loops.mlir to lower to LLVM directly. Those 2 tests are updated to additionally check that the direct lowering to LLVM does not crash.
    
    The following points, left as TODOs still need to be addressed for correct end-to-end execution:
    1. the lowering for ConvOp needs to pass attributes such as strides and dilations; the external library call needs to support it.
    2. the lowering for GenericOp needs to support lowering to loops as a DialectConversion pattern. This is blocked on the DialectConversion infrastructure accepting an OperationFolder.
    
    PiperOrigin-RevId: 272878131

commit c9da96b3c24f09282965cee88d1ba942f8972a95
Author: Nicolas Vasilache <ntv@google.com>
Date:   Fri Oct 4 08:07:12 2019 -0700

    Add missing Linalg lowerings to allow roundtrip.mlir to lower to LLVM
    
    Certain lowering patterns were reported as [missing](https://groups.google.com/a/tensorflow.org/forum/#!topic/mlir/dkdmHa77sSQ).
    
    This CL adds them and allows Linalg/roundtrip.mlir and Linalg/loops.mlir to lower to LLVM directly. Those 2 tests are updated to additionally check that the direct lowering to LLVM does not crash.
    
    The following points, left as TODOs still need to be addressed for correct end-to-end execution:
    1. the lowering for ConvOp needs to pass attributes such as strides and dilations; the external library call needs to support it.
    2. the lowering for GenericOp needs to support lowering to loops as a DialectConversion pattern. This is blocked on the DialectConversion infrastructure accepting an OperationFolder.
    
    PiperOrigin-RevId: 272878131

commit ff650ad4c46ad7d7cf47b335f3698f66fee13edc
Author: Xiao Yu <fishx@google.com>
Date:   Wed Oct 2 18:28:56 2019 -0700

    Improve TF 2.0 error message:
    1. Avoid appending "Encountered when executing an operation..." at the end of each error.
    2. Avoid redundant "W 0916 11:48:32.515855  41375 eager_client_thread destroy_tensor_handle_node.h:48] Ignoring an error encountered when deleting..." when client is crashed.
    
    PiperOrigin-RevId: 272565152

commit 5a3841aacf07cba0ed3893819c55f1b3e4837954
Author: Revan Sopher <rsopher@google.com>
Date:   Wed Oct 2 15:43:32 2019 -0700

    Fix async checkpoint test on Cloud TPU.
    
    - Use gfile glob rather than stdlib glob.
    - Expose model_dir flag rather than loading from envvar.
    - Set model_dir in RunConfig (otherwise checkpoints are temporarily stored locally, causing crash).
    
    PiperOrigin-RevId: 272536005

commit cebed8b575b93629e884a6cf8cd45666e289fc2e
Author: Uday Bondhugula <udayb@iisc.ac.in>
Date:   Wed Sep 18 11:25:33 2019 -0700

    Support symbolic operands for memref replacement; fix memrefNormalize
    
    - allow symbols in index remapping provided for memref replacement
    - fix memref normalize crash on cases with layout maps with symbols
    
    Signed-off-by: Uday Bondhugula <uday@polymagelabs.com>
    Reported by: Alex Zinenko
    
    Closes #139
    
    COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/mlir/pull/139 from bondhugula:memref-rep-symbols 2f48c1fdb5d4c58915bbddbd9f07b18541819233
    PiperOrigin-RevId: 269851182

commit 331c663bd2735699267abcc850897aeaea8433eb
Author: Uday Bondhugula <udayb@iisc.ac.in>
Date:   Wed Sep 18 11:25:33 2019 -0700

    Support symbolic operands for memref replacement; fix memrefNormalize
    
    - allow symbols in index remapping provided for memref replacement
    - fix memref normalize crash on cases with layout maps with symbols
    
    Signed-off-by: Uday Bondhugula <uday@polymagelabs.com>
    Reported by: Alex Zinenko
    
    Closes #139
    
    COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/mlir/pull/139 from bondhugula:memref-rep-symbols 2f48c1fdb5d4c58915bbddbd9f07b18541819233
    PiperOrigin-RevId: 269851182

commit cb26f0cfc0988b44305ab6f94c47cea60a9349c2
Author: Haoyu Zhang <haoyuzhang@google.com>
Date:   Tue Sep 17 16:17:29 2019 -0700

    Hold remote task instead of eager client in `RemoteTensorHandleData`.
    
    The EagerContext and the cluster connections have to be mutable to survive worker failures and preemptions. When cluster changes, it's hard to update the saved `eager_client`s in all remote tensor handles. This CL changes remote tensor handle data to only hold a remote task name instead of the actual eager client. At the time when the tensor handle should be destroyed, it can easily lookup the corresponding client by task name, and prevent client program crashes if the eager clients are changed in the context.
    
    PiperOrigin-RevId: 269678594

commit ef85cdca6e0d0ea83ab734c527b146825fc51a4c
Author: Renjie Liu <renjieliu@google.com>
Date:   Tue Sep 10 21:34:24 2019 -0700

    add evaluation to failure type for model not crashed in the test but missed accuracy.
    
    PiperOrigin-RevId: 268378425

commit 1ec2677a9c0780615a7f0732e2a4e6353c8a09d9
Author: Eugene Brevdo <ebrevdo@google.com>
Date:   Mon Sep 9 20:41:34 2019 -0700

    Enable GPU tests for bucketize op and fix a hard crash on empty input tensors.
    
    PiperOrigin-RevId: 268139518

commit 6b346a7b3fdb4d7db504f46e7b045694edee68a8
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon Sep 9 19:39:34 2019 -0700

    Fix dist strat crash when Optimizer given empty list.
    
    This fixes an "IndexError: list index out of range" error when OptimizerV2.minimize or OptimizerV2.apply_gradients is called with an empty list of variables under a DistributionStrategy.
    
    PiperOrigin-RevId: 268132700

commit 2ff39d00faf8f7e433ddcae0aa278f6e573b0c55
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon Sep 9 14:37:13 2019 -0700

    ProgbarLogger: Do not crash if on_begin_batch is not called.
    
    on_begin_batch is not called if an exception is thrown by DistributionStrategy when distributing the dataset. Before this change, the exception would be replaced by a ProgbarLogger exception.
    
    PiperOrigin-RevId: 268079829

commit 912db4a625e6e84ec1fd4123b0d2da23537dce7f
Author: Benjamin Kramer <kramerb@google.com>
Date:   Thu Aug 29 08:04:53 2019 -0700

    Blacklist CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM for NHWC
    
    This algorithm is only specified for INT8 in the convolution and causes spurious
    cuda errors during autotuning when run on floats with cuda 10.
    
    This might be a bit too big of a hammer, but shouldn't regress performance
    anywhere and fixes the crashes we're seeing now.
    
    PiperOrigin-RevId: 266142522

commit c2107162034ff1f0c894895eb8799a91d284101f
Author: Tong Shen <endlessroad@google.com>
Date:   Tue Aug 27 21:16:01 2019 -0700

    Make sure we return proper error message when there is Placeholder node in TPU computation (instead of crashing).
    
    PiperOrigin-RevId: 265831005

commit c377c9e292b989030b0c700b47be9c61a8c4d0d0
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 14 11:58:21 2019 -0700

    This change allows benchmarker to be used in an external library without crashing on fatal failures.
    
    PiperOrigin-RevId: 263398273

commit c92022d3c73ac1fdd334729b7caecaf2da9d29c7
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Aug 13 19:49:06 2019 -0700

    Update TensorFLow to use nsync version 1.22.0
    
    Changes include:
    - slightly faster condition variables on the Mac
      https://github.com/google/nsync/releases/tag/1.21.0
    
    - a fix for crashes in a C++11 thread_local desructor if nsync happens to be
      pulled into the address space nultiple times (perhaps in multiple shared
      libraries)
      https://github.com/google/nsync/releases/tag/1.22.0
      #31301
    
    PiperOrigin-RevId: 263267561

commit 39e9aa1985e182a20cafcaa6bc548ec6662d1cda
Author: Derek Murray <mrry@google.com>
Date:   Fri Aug 9 14:49:30 2019 -0700

    In UpdateTFE_ContextWithServerDef(), call GrpcServer::Start() after all other initialization.
    
    Currently, GrpcServer does not support clean shutdown and destruction after GrpcServer::Start() is called, and logs a FATAL error in this case. In UpdateTFE_ContextWithServerDef(), there are several cases where a method can fail (e.g. due to invalid user input), and we attempt to destroy the created GrpcServer before returning. By deferring the call to GrpcServer::Start(), we can return an error to the client without crashing their process.
    
    PiperOrigin-RevId: 262638388

commit 3f5348e84fc74f9e426ee1122ea45fd5cc3ab0e8
Author: Jing Pu <jingpu@google.com>
Date:   Fri Aug 9 11:27:02 2019 -0700

    Check "cond" and "body" are defined in tf.While verifier.
    
    This also fix a crash in `condFn.getType()` if the lookupSymbol fails.
    
    PiperOrigin-RevId: 262599229

commit d30a41fcb05e87d597052213f74ad629e8d39933
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Aug 8 09:14:24 2019 -0700

    Parser: treat implicit top-level module as an SSA name scope
    
    Now that modules are also operations, nothing prevents one from defining SSA
    values in the module.  Doing so in an implicit top-level module, i.e. outside
    of a `module` operation, was leading to a crash because the implicit module was
    not associated with an SSA name scope.  Create a name scope before parsing the
    top-level module to fix this.
    
    PiperOrigin-RevId: 262366891

commit 45b303b5fc3d712c394d8dad73765f1f2514c331
Author: Alex Zinenko <zinenko@google.com>
Date:   Thu Aug 8 09:14:24 2019 -0700

    Parser: treat implicit top-level module as an SSA name scope
    
    Now that modules are also operations, nothing prevents one from defining SSA
    values in the module.  Doing so in an implicit top-level module, i.e. outside
    of a `module` operation, was leading to a crash because the implicit module was
    not associated with an SSA name scope.  Create a name scope before parsing the
    top-level module to fix this.
    
    PiperOrigin-RevId: 262366891

commit bc3185633ed4c6fd77e2c491794c62e3323c4ea4
Author: Mihai Maruseac <mihaimaruseac@google.com>
Date:   Tue Aug 6 09:35:40 2019 -0700

    Add one include file so that compile would succeed.
    
    Without
    
    ```c
    ```
    
    compilation will crash with
    
    ```
    ERROR: /tmpfs/src/github/tensorflow/tensorflow/core/kernels/data/experimental/BUILD:360:1: C++ compilation of rule '//tensorflow/core/kernels/data/experimental:take_while_dataset_op' failed (Exit 1)
    tensorflow/core/kernels/data/experimental/take_while_dataset_op.cc:203:36: error: expected constructor, destructor, or type conversion before '(' token
     REGISTER_INPUT_COLOCATION_EXEMPTION("TakeWhileDataset");
                                        ^
    tensorflow/core/kernels/data/experimental/take_while_dataset_op.cc:204:36: error: expected constructor, destructor, or type conversion before '(' token
     REGISTER_INPUT_COLOCATION_EXEMPTION("ExperimentalTakeWhileDataset");
                                        ^
    Target //tensorflow/tools/pip_package:build_pip_package failed to build
    Use --verbose_failures to see the command lines of failed build steps.
    INFO: Elapsed time: 1158.013s, Critical Path: 245.65s
    INFO: 8464 processes: 8464 local.
    FAILED: Build did NOT complete successfully
    FAILED: Build did NOT complete successfully
    ```

commit df79f0859564dbc4ea7dea78aaebb5336c1a582f
Author: Smit Hinsu <hinsu@google.com>
Date:   Sun Aug 4 18:43:16 2019 -0700

    Return an error if the output index is invalid while importing GraphDef to MLIR
    
    Currently, it crashes in such cases.
    
    PiperOrigin-RevId: 261603894

commit 5ee4f63f8d9ef2d01ce5a752888b41e5c73151a6
Author: Nicolas Vasilache <ntv@google.com>
Date:   Fri Aug 2 09:53:08 2019 -0700

    Add a generic Linalg op
    
    This CL introduces a linalg.generic op to represent generic tensor contraction operations on views.
    
    A linalg.generic operation requires a numbers of attributes that are sufficient to emit the computation in scalar form as well as compute the appropriate subviews to enable tiling and fusion.
    
    These attributes are very similar to the attributes for existing operations such as linalg.matmul etc and existing operations can be implemented with the generic form.
    
    In the future, most existing operations can be implemented using the generic form.
    
    This CL starts by splitting out most of the functionality of the linalg::NInputsAndOutputs trait into a ViewTrait that queries the per-instance properties of the op. This allows using the attribute informations.
    
    This exposes an ordering of verifiers issue where ViewTrait::verify uses attributes but the verifiers for those attributes have not been run. The desired behavior would be for the verifiers of the attributes specified in the builder to execute first but it is not the case atm. As a consequence, to emit proper error messages and avoid crashing, some of the
    linalg.generic methods are defensive as such:
    ```
        unsigned getNumInputs() {
          // This is redundant with the `n_views` attribute verifier but ordering of verifiers
          // may exhibit cases where we crash instead of emitting an error message.
          if (!getAttr("n_views") || n_views().getValue().size() != 2)
            return 0;
    ```
    
    In pretty-printed form, the specific attributes required for linalg.generic are factored out in an independent dictionary named "_". When parsing its content is flattened and the "_name" is dropped. This allows using aliasing for reducing boilerplate at each linalg.generic invocation while benefiting from the Tablegen'd verifier form for each named attribute in the dictionary.
    
    For instance, implementing linalg.matmul in terms of linalg.generic resembles:
    
    ```
    func @mac(%a: f32, %b: f32, %c: f32) -> f32 {
      %d = mulf %a, %b: f32
      %e = addf %c, %d: f32
      return %e: f32
    }
    #matmul_accesses = [
      (m, n, k) -> (m, k),
      (m, n, k) -> (k, n),
      (m, n, k) -> (m, n)
    ]
    #matmul_trait = {
      doc = "C(m, n) += A(m, k) * B(k, n)",
      fun = @mac,
      indexing_maps = #matmul_accesses,
      library_call = "linalg_matmul",
      n_views = [2, 1],
      n_loop_types = [2, 1, 0]
    }
    ```
    
    And can be used in multiple places as:
    ```
      linalg.generic #matmul_trait %A, %B, %C [other-attributes] :
        !linalg.view<?x?xf32>, !linalg.view<?x?xf32>, !linalg.view<?x?xf32>
    ```
    
    In the future it would be great to have a mechanism to alias / register a new
    linalg.op as a pair of linalg.generic, #trait.
    
    Also, note that with one could theoretically only specify the `doc` string and parse all the attributes from it.
    
    PiperOrigin-RevId: 261338740

commit 10d0c61266696c4af211ee09669c3242ed3beea4
Author: Nicolas Vasilache <ntv@google.com>
Date:   Fri Aug 2 09:53:08 2019 -0700

    Add a generic Linalg op
    
    This CL introduces a linalg.generic op to represent generic tensor contraction operations on views.
    
    A linalg.generic operation requires a numbers of attributes that are sufficient to emit the computation in scalar form as well as compute the appropriate subviews to enable tiling and fusion.
    
    These attributes are very similar to the attributes for existing operations such as linalg.matmul etc and existing operations can be implemented with the generic form.
    
    In the future, most existing operations can be implemented using the generic form.
    
    This CL starts by splitting out most of the functionality of the linalg::NInputsAndOutputs trait into a ViewTrait that queries the per-instance properties of the op. This allows using the attribute informations.
    
    This exposes an ordering of verifiers issue where ViewTrait::verify uses attributes but the verifiers for those attributes have not been run. The desired behavior would be for the verifiers of the attributes specified in the builder to execute first but it is not the case atm. As a consequence, to emit proper error messages and avoid crashing, some of the
    linalg.generic methods are defensive as such:
    ```
        unsigned getNumInputs() {
          // This is redundant with the `n_views` attribute verifier but ordering of verifiers
          // may exhibit cases where we crash instead of emitting an error message.
          if (!getAttr("n_views") || n_views().getValue().size() != 2)
            return 0;
    ```
    
    In pretty-printed form, the specific attributes required for linalg.generic are factored out in an independent dictionary named "_". When parsing its content is flattened and the "_name" is dropped. This allows using aliasing for reducing boilerplate at each linalg.generic invocation while benefiting from the Tablegen'd verifier form for each named attribute in the dictionary.
    
    For instance, implementing linalg.matmul in terms of linalg.generic resembles:
    
    ```
    func @mac(%a: f32, %b: f32, %c: f32) -> f32 {
      %d = mulf %a, %b: f32
      %e = addf %c, %d: f32
      return %e: f32
    }
    #matmul_accesses = [
      (m, n, k) -> (m, k),
      (m, n, k) -> (k, n),
      (m, n, k) -> (m, n)
    ]
    #matmul_trait = {
      doc = "C(m, n) += A(m, k) * B(k, n)",
      fun = @mac,
      indexing_maps = #matmul_accesses,
      library_call = "linalg_matmul",
      n_views = [2, 1],
      n_loop_types = [2, 1, 0]
    }
    ```
    
    And can be used in multiple places as:
    ```
      linalg.generic #matmul_trait %A, %B, %C [other-attributes] :
        !linalg.view<?x?xf32>, !linalg.view<?x?xf32>, !linalg.view<?x?xf32>
    ```
    
    In the future it would be great to have a mechanism to alias / register a new
    linalg.op as a pair of linalg.generic, #trait.
    
    Also, note that with one could theoretically only specify the `doc` string and parse all the attributes from it.
    
    PiperOrigin-RevId: 261338740

commit fecc7c2823edf4e71b96e492d4590c727b1c4eae
Author: Bixia Zheng <bixia@google.com>
Date:   Tue Jul 30 17:53:04 2019 -0700

    [XLA:GPU] Handle the case when the first parameter is too large for tiling.
    
    Previously, when tiling the first parameter requires too much share memory, we
    call the tiled transpose emitter without any parameter being tiled and crash the
    compiler. The fix is to fall back to the codegen path without tiling.
    
    Add a test.
    
    PiperOrigin-RevId: 260834244

commit 9d4e18361b1c45d5e7d6591123f8115895a64fef
Merge: 5ff60ad52a1 64f954a9a3b
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Mon Jul 29 13:43:30 2019 -0700

    Merge pull request #31090 from Intel-tensorflow:weiwang/fix_maxpool3d_crash
    
    PiperOrigin-RevId: 260563022

commit 00ff0d77a91d4498ac9bbec9d169010ebbc1630d
Author: Wei Wang <wei.v.wang@intel.com>
Date:   Fri Jul 26 14:25:35 2019 -0700

    [Intel MKL] Fix "Missing 1-th output from" Crash caused by MKL MaxPool node having an extra workspace tensor as auxiliary output. Such output should never be left unallocated (0x0) even for cases that the output tensors are empty. If not, code will fail at this check in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/executor.cc#L2034-L2042 (i.e. the if (val.tensor == nullptr) check ). In addition, only MKL MaxPool has such a workspace tensor. AvgPool does not and Quantized MaxPool does not.

commit 65cd482a273d3e31d560a5b0aba8a6a65222a3ae
Author: Sanjoy Das <sanjoy@google.com>
Date:   Fri Jul 26 11:29:32 2019 -0700

    Teach the HLO bisect utility to run a script when testing for a bug
    
    We also remove the Crash BugKind: it was unimplemented and can be trivially
    implemented using the script BugKind.
    
    I also made some minor adjustments:
    
     - Add two CHECKs to ensure that we do not "lose" the bug in
       TrimComputationByOutputs and TrimComputationByInstructions.
    
     - Fix a typo.
    
    PiperOrigin-RevId: 260181098

commit a7ecc1b1a03ea02cd140d88146b741a4672dba4d
Author: Bixia Zheng <bixia@google.com>
Date:   Wed Jul 10 12:11:17 2019 -0700

    [XLA] Fix CreateFromProto to return an error status for illegal reshape
    instructions.
    
    Previously, CreateFromProto would crash when handling a reshape instruction with
    non-array shapes. Fix it to return an error status instead, so that the fuzzer
    can ignore the input module.
    
    PiperOrigin-RevId: 257455123

commit 7360531c13113a19120d798278cd20bec2e5e0c3
Author: Xiao Yu <fishx@google.com>
Date:   Wed Jul 3 12:00:38 2019 -0700

    Add support of local soft device placement for eager op. This change includes:
    1. "with tf.device" only set the requested device name of the eager operation. TF will place the op on device in EagerLocalExecute. As a result, TF won't crash immediately when user passes in an unknown device.
    2. When soft_placement is on and cannot find a proper device for the given device name, 'soften' device type and device index to find an alternative device to execute the op.
    
    This change fixes #29342.
    
    Soft placement on a remote op will be supported in a future change.
    
    PiperOrigin-RevId: 256411850

commit 06e136fec15782a64dc2683eee6c76eaf3aa7219
Author: Bixia Zheng <bixia@google.com>
Date:   Tue Jul 2 08:33:37 2019 -0700

    [XLA] Fix ScatterExpander to handle operands with no layout shapes.
    
    Previously, scatter expander would crash when expanding an operation that
    contains operands with no layout shapes. Since scatter expander runs before
    layout assignment, it should properly handle shapes without layouts. This
    CL uses a default layout for such a shape.
    
    Add a test case for scatter expander.
    
    PiperOrigin-RevId: 256170096

commit 2b9e5198036ae63ddde5e8d83b9675b7d3355de2
Author: Haoliang Zhang <haoliang@google.com>
Date:   Thu Jun 27 19:38:09 2019 -0700

    Return error status rather than hard crash when control flow conditions are not met.
    
    PiperOrigin-RevId: 255526709

commit d8d426ab9425f71a743ed9a2360f6caa05e289f2
Author: Cao Zongyan <zongyan.cao@alibaba-inc.com>
Date:   Mon Apr 29 17:45:06 2019 +0800

    Refine permuation const device placement for LayoutOptimizer.
    
    In layout optimizer of Grappler, two permutation const nodes would be
    added into the graph by default. The nodes should be placed to a default
    device assigned by a Virtual Placer, which was constructed from the
    cluster infomation. However, the Virtual Placer could not distinguish
    remote devices from local ones in distributed runtime, which causes that
    a remote device might be the default device. Thus unnecessary dependency
    between workers would be implicitly built, unexpected crashed would
    occur in asynchronous distributed graph running.
    
    This fix only refines the behaviour of LayoutOptimizer. Permutation
    const nodes would be lazy created when necessary and would be colocated
    with the connected nodes if the device was already done. Each device
    would keep one pair and at most one pair of permutation consts, so that
    these consts would not bring cross-device send-recv in ideal cases.

commit ea7964f8aee0c0d5630fa552d639ecccb0dcfda4
Author: Benjamin Kramer <kramerb@google.com>
Date:   Fri Jun 14 05:58:02 2019 -0700

    [XLA:CPU] Strip one-dimensions for dot by default
    
    This is a roll-forward with a crash fix.
    
    This switches the canonical representation away from having one dimensions, allowing
    further optimization and bringing CPU in line with the other backends.
    
    dot->reduce simplification is still disabled when strength reduction is enabled as we
    don't have a fast implementation of this on CPU yet.
    
    Sadly the assumption that vector-matrix multiplication is matrix-matrix multiplication withextra 1-dimensions is baked into many places. I think I managed to fix them all
    and adjusted the tests.
    
    Crash fix: The concat transform assumes that the inputs are 2D, and crashes if
    they're not.  I think this currently can only happen on CPU, on other backends
    the dot is transformed into a reduce+multiply and this code path never
    triggers.
    
    PiperOrigin-RevId: 253214157

commit 117d113a37c2af1f136678cefbf1219a378de87d
Author: Benjamin Kramer <kramerb@google.com>
Date:   Thu Jun 13 05:26:48 2019 -0700

    [XLA:CPU] Fix a crash when emitting an elemental (loop-fused) dot with scalar output
    
    PiperOrigin-RevId: 253009497

commit 7689e205079f00955b4d5f91d4edc0c99fd23d92
Author: Pete Warden <petewarden@google.com>
Date:   Wed Jun 12 12:51:17 2019 -0700

    Fix for Micro crash when quantization scale and zero point parameters aren't specified for inputs
    
    PiperOrigin-RevId: 252880624

commit 3cf07fc44b9e7122ce21e818d87d15d936a7dba9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Jun 11 19:56:58 2019 -0700

    Fixes a crash by preventing an unterminated string from being passed to NewStringUTF in ReadMultiDimensionalStringArray.
    
    Adds test for supplementary Unicode characters to NativeInterpreterWrapperTest, and updates the test suite to use try-with-resources.
    
    PiperOrigin-RevId: 252748620

commit e02a51cec6f438edacf0a7ae7252a92f2fea87b9
Author: River Riddle <riverriddle@google.com>
Date:   Wed Jun 5 10:08:47 2019 -0700

    Always remap results when replacing an operation. This prevents a crash when lowering identity(passthrough) operations to the same resultant type as the original operation.
    
    PiperOrigin-RevId: 251665492

commit d7d0fe4713960aa83d0d780271208585ff7b7fb4
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Jun 7 11:24:42 2019 -0700

    Ubind and destroy EGL context before draw/read surfaces are destroyed. (Fixes crash which happens on some devices right after EglEnvironment is destroyed.)
    
    PiperOrigin-RevId: 252085668

commit 9366340689fef873ddd269ca9059cfcb950be3bf
Author: Mehdi Amini <aminim@google.com>
Date:   Wed May 22 12:22:51 2019 -0700

        Return nullptr on Region::getContainingOperation()/getContainingFunction() instead of asserting
    
        This avoids crashing when trying to dump an operation nested in a region that isn't yet attached to an operation, which is quite useful when debugging.
    
        This alone won't be enough to print an unlink Operation, it'll display `<<UNLINKED INSTRUCTION>>`.
    
    --
    
    PiperOrigin-RevId: 249496388

commit 0e431759214b7911f843f799b968298e3458bab1
Author: Benoit Jacob <benoitjacob@google.com>
Date:   Thu May 30 12:33:32 2019 -0700

    Don't access CpuBackendContext concurrently from multiple threads.
    This fixes a race condition that caused crashes with 'illegal instruction'
    as the dot-product detection went wrong.
    
    When implementing dotprod detection in depthwiseconv code based on CpuBackendContext, I forgot to mention that CpuBackendContext should
    not be used concurrently from multiple threads (a limitation it inherits
    from the underlying gemmlowp / ruy contexts).
    
    To avoid that, the dotprod detection is moved to the top-level op kernel
    function called on the main thread, before the thread dispatch.
    
    A new data structure was needed to hold the results of the dotprod detection
    in a way that could be shared with threads: that's CpuFlags. Put it in
    the existing cpu_check.h. It can't share code with the existing code here
    because what it does is not currently supported by the OS features that
    this existing code uses.
    
    PiperOrigin-RevId: 250739702

commit 24673e4d606bd89e45e27e8d1503c88208d0adc4
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed May 29 14:30:52 2019 -0700

    Avoid crash from out of bounds error in quantize_nodes.cc.
    
    PiperOrigin-RevId: 250567603

commit 79e0f378dec9937d86d69a6d9998f255cf994d96
Author: George Karpenkov <cheshire@google.com>
Date:   Wed May 29 07:58:37 2019 -0700

    [XLA] Use default configuration protobuf instead of starting an empty one
    
    Using the default configuration protobuf has the advantage that devices
    are already configured properly, and we don't hit a crash caused by the fact
    that the list of default devices according to TF is different from the list
    of default devices according to XLA.
    
    Fixes //tensorflow/compiler/tests:eager_test_gpu on a multi-GPU machine.
    
    PiperOrigin-RevId: 250491056

commit b35d0e712c7dc6ab73554020766ea8df3cc7a19e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 24 18:45:21 2019 -0700

    major changes:
       1. fix crash when using run/test with -c opt.
    
    PiperOrigin-RevId: 249932872

commit 310a4a4419809bed7b8d62d60da7ebaae9da05f8
Author: Tim Shen <timshen@google.com>
Date:   Thu May 23 15:16:04 2019 -0700

    Adjust logging in the algorithm picker. Print more information under VLOG(1) instead of relying on the crasher flag, because they are indepdent intentions.
    
    PiperOrigin-RevId: 249725221

commit 9cb6dadcfd5ebfd908244eb791fd0eaa13ad50dd
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu May 23 07:46:06 2019 -0700

    [XLA:Python] Fix crash on process termination on CPU platform.
    
    We must wait for all scheduled activity to stop before terminating, but SynchronizeAllActivity() is a dummy on the Host platform.
    Work around the problem by also blocking on the compute stream.
    
    PiperOrigin-RevId: 249640832

commit e987cbce438ee2d41ca0e501755eedf01fc94fa3
Author: Peter Hawkins <phawkins@google.com>
Date:   Mon May 20 13:00:24 2019 -0700

    [XLA:Python] Make PyLocalBuffers stateful objects and clarify their ownership and threading semantics.
    
    Change PyLocalBuffers to be non-copyable, non-moveable, and passed via std::unique_ptr<PyLocalBuffer>. Lock the mutable parts of PyLocalBuffer to make it thread-safe. Check for buffer validity in functions that consume PyLocalBuffers.
    
    This change should make it safe for clients to call Delete(), whereas previously Delete() had unclear semantics and could lead to crashes.
    
    Change should help implement a JAX-level deletion API for https://github.com/google/jax/issues/725 and also lays groundwork for donating buffers to XLA computations.
    
    PiperOrigin-RevId: 249108908

commit c0f2b5b42019bbac0fcd0bb4a89c56a41e2a9fcf
Author: George Karpenkov <cheshire@google.com>
Date:   Fri May 17 09:31:12 2019 -0700

    Fix a memory leak in StreamExecutorMemoryAllocator in a multi-GPU case
    
    The previous commit
    (https://github.com/tensorflow/tensorflow/commit/21f1d8056a5ef913742d80b69de0ffe36f6297b2)
    has introduced a new constructor for StreamExecutorMemoryAllocator, which only
    accepted a single object.  That created a leak in a multi-GPU case, when the
    index of a stored stream executor within the allocator did not correspond to
    it's device_ordinal, and all deallocations were silently (only with a logging
    message) failing.
    
    This commit changes vector to a map, and ensures that indexes correspond
    properly.
    Proper testing remains an open concern: since we can't return a status from
    a destructor, the only option is to crash, which might be too intrusive.
    
    PiperOrigin-RevId: 248734288

commit 6918721471b28bb5ded60393e9ac4de95b418ec1
Author: Tim Shen <timshen@google.com>
Date:   Wed May 15 13:27:23 2019 -0700

    Print more information to local logs when `crash_on_checking_failure` flag is on.
    
    PiperOrigin-RevId: 248393395

commit 1751a9f117baebdaadd04cfaa90393964055ae05
Author: Justin Lebar <jlebar@google.com>
Date:   Thu May 9 15:28:44 2019 -0700

    [XLA] Use .at() instead of operator[] in InversePermutation and ComposePermutations.
    
    .at() has the property that it will crash on out-of-bounds accesses.
    
    This catches a bug in AlgebraicSimplifier, which suggests to me it's
    worthwhile.  Anyway the permutations we're dealing with are usually small.
    
    No functional change.
    
    PiperOrigin-RevId: 247507797

commit d6489471dd77abbd56ca24d2c1be556a85fd24bc
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Sat May 4 11:29:01 2019 -0700

    Don't crash in matrix_solve on empty matrices.
    
    PiperOrigin-RevId: 246662273

commit c14f7d33bb6b40d04f5a1bcd9674640dee090145
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Tue Apr 30 15:56:38 2019 -0700

    Support explicit padding in _FusedConv2D.
    
    This prevents a crash when a graph rewrite changes a Conv2D with explicit padding to _FusedConv2D.
    
    Also change a DCHECK to a CHECK. If the DCHECK failed but did not trigger, the program would crash with a very cryptic error.
    
    PiperOrigin-RevId: 246039310

commit c1025cd28d6472df0b484b9d0c48874dd36d07c2
Author: Dominik Schlsser <dsc@dosc.net>
Date:   Sat Apr 27 10:26:12 2019 +0200

    fix crash caused by unicode chars in ldconfig output

commit b307e692a11273d4fa9fcc789e022b90a3abeb1e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 23 09:58:01 2019 -0700

    Exclude device_tracer for CPU build
    
    cl/243861265 introduced a dependency on tensorflow/core/platform/default/device_tracer.cc, however this file is actually empty during the CPU build because GOOGLE_CUDA is not defined. So the cc library for device_tracer is empty, and when force linking (/WHOLEARCHIVE is used for linking shared library) an empty cc library with MSVC, we hit this compiler bug:
    https://support.microsoft.com/en-hk/help/4020481/fix-link-exe-crashes-with-a-fatal-lnk1000-error-when-you-use-wholearch
    
    This is the root cause of b/130835153 and b/130748329
    
    Since device tracer is only for GPU build, the solution is to exclude it from CPU build.
    
    PiperOrigin-RevId: 244872492

commit 67ed86c6878058d50292d0d71550de39afacded9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 23 09:58:01 2019 -0700

    Exclude device_tracer for CPU build
    
    cl/243861265 introduced a dependency on tensorflow/core/platform/default/device_tracer.cc, however this file is actually empty during the CPU build because GOOGLE_CUDA is not defined. So the cc library for device_tracer is empty, and when force linking (/WHOLEARCHIVE is used for linking shared library) an empty cc library with MSVC, we hit this compiler bug:
    https://support.microsoft.com/en-hk/help/4020481/fix-link-exe-crashes-with-a-fatal-lnk1000-error-when-you-use-wholearch
    
    This is the root cause of b/130835153 and b/130748329
    
    Since device tracer is only for GPU build, the solution is to exclude it from CPU build.
    
    PiperOrigin-RevId: 244872492

commit 021cf2a36710f052ef6da8ebce87dd9638e27ce6
Author: Justin DuJardin <justin@dujardinconsulting.com>
Date:   Mon Apr 22 16:42:40 2019 -0700

    chore: simplify test based on feedback
    
     - verify it passes running locally with bazel
     - remove call methods since we're just measuring the output_shape and making sure the wrapper in TimeDistributed doesn't crash like it did before.

commit 01d0542ed6b3e8450846b4b91ac0743f394537b5
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Apr 18 14:22:52 2019 -0700

    Set RNN state size to 1 to avoid transient array allocation crash issue.
    
    PiperOrigin-RevId: 244257545

commit 4c55f908d43f965645e9b29839e542c906e92827
Author: Xiao Yu <fishx@google.com>
Date:   Mon Apr 15 17:05:29 2019 -0700

    Avoid crashing the whole program when creating metric with the same name.
    
    PiperOrigin-RevId: 243716599

commit 9d6ef94f7aa26790e7f6bab29e9fabbc4efa1c86
Author: Lei Zhang <antiagainst@google.com>
Date:   Mon Apr 8 15:14:59 2019 -0700

        [TableGen] Make sure op in pattern has the same number of arguments as definition
    
        When an op in the source pattern specifies more arguments than its definition, we
        will have out-of-bound query for op arguments from the definition. That will cause
        crashes. This change fixes it.
    
    --
    
    PiperOrigin-RevId: 242548415

commit 34fd2a5e9bcdb40957ece90fec46a37e6e9248b2
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 8 04:54:48 2019 -0700

    Fix crash when forget_layer_norm_coefficients tensor has no value
    
    PiperOrigin-RevId: 242442133

commit 3af1404a10faecf1fb40959f9322d3d549ffbf86
Author: Penporn Koanantakool <penporn@google.com>
Date:   Mon Apr 1 10:50:30 2019 -0700

    Re-enabling MKL-DNN contraction kernel. Prevent _lstm_ops.so and _gru_ops.so from using MKL-DNN contraction kernel to avoid having duplicate MKL-DNN thread-local symbols in both files which can cause a crash due to linking issues.
    
    PiperOrigin-RevId: 241355936

commit dff4c1ae622eb2df1268137cf1a6d2e3d261f224
Author: River Riddle <riverriddle@google.com>
Date:   Fri Mar 29 08:52:06 2019 -0700

    [PassManager] Add a utility class, PrettyStackTraceParallelDiagnosticEntry, to emit any queued up diagnostics in the event of a crash when multi-threading.
    
    PiperOrigin-RevId: 240986566

commit 16326e77995ff5971b4b299549703957d101ee09
Author: Lei Zhang <antiagainst@google.com>
Date:   Sat Feb 9 17:38:24 2019 -0800

    [TFLite] Add rewrite pattern to fuse conv ops with Relu6 op
    
    * Fixed tfl.conv_2d and tfl.depthwise_conv_2d to have fused activation
      function attribute
    * Fixed RewriterGen crash: trying to get attribute match template when
      the matcher is unspecified (UnsetInit)
    
    PiperOrigin-RevId: 233241755

commit dc6d69e241df5a642486fba4e2def37ba1a5ccfa
Author: Nicolas Vasilache <ntv@google.com>
Date:   Mon Jan 28 14:32:00 2019 -0800

    Add a C API for EDSCs in other languages + python
    
    This CL adds support for calling EDSCs from other languages than C++.
    Following the LLVM convention this CL:
    1. declares simple opaque types and a C API in mlir-c/Core.h;
    2. defines the implementation directly in lib/EDSC/Types.cpp and
    lib/EDSC/MLIREmitter.cpp.
    
    Unlike LLVM however the nomenclature for these types and API functions is not
    well-defined, naming suggestions are most welcome.
    
    To avoid the need for conversion functions, Types.h and MLIREmitter.h include
    mlir-c/Core.h and provide constructors and conversion operators between the
    mlir::edsc type and the corresponding C type.
    
    In this first commit, mlir-c/Core.h only contains the types for the C API
    to allow EDSCs to work from Python. This includes both a minimal set of core
    MLIR
    types (mlir_context_t, mlir_type_t, mlir_func_t) as well as the EDSC types
    (edsc_mlir_emitter_t, edsc_expr_t, edsc_stmt_t, edsc_indexed_t). This can be
    restructured in the future as concrete needs arise.
    
    For now, the API only supports:
    1. scalar types;
    2. memrefs of scalar types with static or symbolic shapes;
    3. functions with input and output of these types.
    
    The C API is not complete wrt ownership semantics. This is in large part due
    to the fact that python bindings are written with Pybind11 which allows very
    idiomatic C++ bindings. An effort is made to write a large chunk of these
    bindings using the C API but some C++isms are used where the design benefits
    from this simplication. A fully isolated C API will make more sense once we
    also integrate with another language like Swift and have enough use cases to
    drive the design.
    
    Lastly, this CL also fixes a bug in mlir::ExecutionEngine were the order of
    declaration of llvmContext and the JIT result in an improper order of
    destructors (which used to crash before the fix).
    
    PiperOrigin-RevId: 231290250

commit 23464b395e2849975cdcb66742ad0f29f0c20caf
Author: River Riddle <riverriddle@google.com>
Date:   Tue Jan 15 09:30:39 2019 -0800

    When parsing Select/Cmpi standard operations, emit an error if the type does not have a valid i1 shape instead of crashing.
    
    PiperOrigin-RevId: 229384794

commit 031f2829b448e69076f005c4a964cf9286739594
Author: River Riddle <riverriddle@google.com>
Date:   Mon Jan 14 13:18:34 2019 -0800

    Emit unsupported error when parsing a DenseElementAttr with an integer type of greater than 64 bits.
    
    DenseElementAttr currently does not support value bitwidths of > 64. This can result in asan failures and crashes when trying to invoke DenseElementsAttr::writeBits/DenseElementsAttr::readBits.
    
    PiperOrigin-RevId: 229241125

commit fc860783f1cccb24b071eba0f4e6e52bd5a40c07
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Fri Jan 11 09:03:34 2019 -0800

    Verify string type token before attempting to get string value.
    
    Add repro that would have resulted in crash previously.
    
    PiperOrigin-RevId: 228890749

commit 5c4fb6712e90d7b43a7ef3ecd3c2e25bcbedf7e2
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Mon Jan 7 18:07:28 2019 -0800

    Fix 0-d memref corner case for getMemRefRegion()
    
    - fix crash on test/Transforms/canonicalize.mlir with
      -memref-bound-check
    
    PiperOrigin-RevId: 228268486

commit 19a78cb55097dee1dd2260ce16dd3272177a1117
Author: Nicolas Vasilache <ntv@google.com>
Date:   Thu Jan 3 15:30:45 2019 -0800

    [MLIR] Handle corner case in MaterializeVectors
    
    This corner was found when stress testing with a functional end-to-end CPU
    path. In the case where the hardware vector size is 1x...x1 the `keep` vector
    is empty and would result a crash.
    
    While there is no reason to expect a 1x...x1 HW vector in practice, this case
    can just gracefully degrade to scalar, which is what this CL allows.
    
    PiperOrigin-RevId: 227761097

commit a435e6fbab0ef00251dcd63708696241392afcbf
Author: Chris Lattner <clattner@google.com>
Date:   Sun Dec 30 22:00:45 2018 -0800

    Simplify the remapFunctionAttrs logic, merging CFG/ML function handling.
    Remove an unnecessary restriction in forward substitution.  Slightly
    simplify LLVM IR lowering, which previously would crash if given an ML
    function, it should now produce a clean error if given a function with an
    if/for instruction in it, just like it does any other unsupported op.
    
    This is step 27/n towards merging instructions and statements.
    
    PiperOrigin-RevId: 227324542

commit 38c365d1254eee217254d051271c821b1d721c65
Author: Chris Lattner <clattner@google.com>
Date:   Sun Dec 30 16:22:50 2018 -0800

    Greatly simplify the ConvertToCFG pass, converting it from a module pass to a
    function pass, and eliminating the need to copy over code and do
    interprocedural updates.  While here, also improve it to make fewer empty
    blocks, and rename it to "LowerIfAndFor" since that is what it does.  This is
    a net reduction of ~170 lines of code.
    
    As drive-bys, change the splitBlock method to *not* insert an unconditional
    branch, since that behavior is annoying for all clients.  Also improve the
    AsmPrinter to not crash when a block is referenced that isn't linked into a
    function.
    
    PiperOrigin-RevId: 227308856

commit 4bb67a1452b2e0fe70a95072f2b8e8b63b68ba7e
Author: Chris Lattner <clattner@google.com>
Date:   Sat Dec 29 15:33:43 2018 -0800

    Extend InstVisitor and Walker to handle arbitrary CFG functions, expand the
    Function::walk functionality into f->walkInsts/Ops which allows visiting all
    instructions, not just ops.  Eliminate Function::getBody() and
    Function::getReturn() helpers which crash in CFG functions, and were only kept
    around as a bridge.
    
    This is step 25/n towards merging instructions and statements.
    
    PiperOrigin-RevId: 227243966

commit 5d5c4acd56f31384e709179cb961e22888db7007
Author: Feng Liu <fengliuai@google.com>
Date:   Thu Dec 27 16:51:09 2018 -0800

    add a method to get FloatAttr value as double
    
    Sometimes we have to get the raw value of the FloatAttr to invoke APIs from
    non-MLIR libraries (i.e. in the tpu_ops.inc and convert_tensor.cc files). Using
    `FloatAttr::getValue().convertToFloat()` and
    `FloatAttr::getValue().convertToDouble()` is not safe because interally they
    checke the semantics of the APFloat in the attribute, and the semantics is not
    always specified (the default value is f64 then convertToFloat will fail) or
    inferred incorrectly (for example, using 1.0 instead of 1.f for IEEEFloat).
    Calling these convert methods without knowing the semantics can usually crash
    the compiler.
    
    This new method converts the value of a FloatAttr to double even if it loses
    precision. Currently this method can be used to read in f32 data from arrays.
    
    PiperOrigin-RevId: 227076616

commit 9b9254008ead046ceaa487c5c74c93058266d022
Author: Alex Zinenko <zinenko@google.com>
Date:   Thu Dec 27 08:16:39 2018 -0800

    LoopAnalysis: isContiguousAccess fail gracefully
    
    Existing implementation of isContiguousAccess asserts that one of the
    function arguments is within certain range, depending on another parameter.
    However, the value of this argument may come from outside, in particular in the
    loop vectorization pass it may come from command line arguments.  This leads
    to 'mlir-opt' crashing on an assertion depending on flags.  Handle the error
    gracefully by reporting error returning a negative result instead.  This
    negative result prevents any further transformation by the vectorizer so the IR
    remains valid.
    
    PiperOrigin-RevId: 227029496

commit 7c264cac9266b285d398d7aceefe8bb22e038ec0
Author: Uday Bondhugula <bondhugula@google.com>
Date:   Mon Dec 3 11:20:10 2018 -0800

    FlatAffineConstraints::composeMap: return failure instead of asserting on semi-affine maps
    
    FlatAffineConstraints::composeMap: should return false instead of asserting on
    a semi-affine map. Make getMemRefRegion just propagate false when encountering
    semi-affine maps (instead of crashing!)
    PiperOrigin-RevId: 223828743

commit 751b62bbbd6d622b62ff24cfc2ce1afd055ce09d
Author: Smit Hinsu <hinsu@google.com>
Date:   Fri Nov 9 21:24:37 2018 -0800

    Handle VectorOrTensorType parse failure instead of crashing
    
    This was unsafe after cr/219372163 and seems to be the only such case in the
    change. All other usage of dyn_cast are either handling the nullptr or are
    implicitly safe.  For example, they are being extracted from operand or result
    SSAValue.
    
    TESTED with unit test
    
    PiperOrigin-RevId: 220905942

commit f8b5a281862ea7bdb18a19dfa5d5aab9c9a0d074
Author: Jacques Pienaar <jpienaar@google.com>
Date:   Tue Oct 9 14:40:41 2018 -0700

    Fix some leak and crash found via fuzzing.
    
    Tried adding a fuzzer target (cl/216378253) and ran into a few problems, and fixing two of these.
    
    PiperOrigin-RevId: 216425403

commit 3d6107561e4044612e89f545eb7aa222ad94bfca
Author: Chris Lattner <clattner@google.com>
Date:   Wed Sep 19 09:18:36 2018 -0700

    Add missing verifier logic for addf, and fix b/116054838 - Parser crash handling alloc with no affine mappings.
    
    PiperOrigin-RevId: 213639056

commit ffde6e971b32b436f076c7260b06ded0d5473940
Author: Chris Lattner <clattner@google.com>
Date:   Thu Sep 6 09:17:08 2018 -0700

    Several minor infra improvements:
     - Make the tf-lower-control flow handle error cases better.  Add a testcase
       that (currently) fails due to type mismatches.
     - Factor more code in the verifier for basic block argument checking, and
       check more invariants.
     - Fix a crasher in the asmprinter on null instructions (which only occurs on
       invalid code).
     - Fix a bug handling conditional branches with no block operands, it would
       access &operands[0] instead of using operands.data().
     - Enhance the mlir-opt driver to use the verifier() in a non-crashing mode,
       allowing issues to be reported as diagnostics.
    
    PiperOrigin-RevId: 211818291

commit 0a917a98221f08e71eabaf6167f056eead70a186
Author: Tatiana Shpeisman <shpeisman@google.com>
Date:   Fri Aug 31 22:33:47 2018 -0700

    Fix asan failure introduced by cl/210618122 and statement walker crash for if statements without else clause.
    
    PiperOrigin-RevId: 211186361

commit ea5c3dc837e49032c6fd19c4e1266cc61c7ef834
Author: Chris Lattner <clattner@google.com>
Date:   Tue Aug 21 08:42:19 2018 -0700

    Finish support for function attributes, and improve lots of things:
     - Have the parser rewrite forward references to their resolved values at the
       end of parsing.
     - Implement verifier support for detecting malformed function attrs.
     - Add efficient query for (in general, recursive) attributes to tell if they
       contain a function.
    
    As part of this, improve other general infrastructure:
     - Implement support for verifying OperationStmt's in ml functions, refactoring
       and generalizing support for operations in the verifier.
     - Refactor location handling code in mlir-opt to have the non-error expecting
       form of mlir-opt invocations to report error locations precisely.
     - Fix parser to detect verifier failures and report them through errorReporter
       instead of printing the error and crashing.
    
    This regresses the location info for verifier errors in the parser that were
    previously ascribed to the function.  This will get resolved in future patches
    by adding support for function attributes, which we can use to manage location
    information.
    
    PiperOrigin-RevId: 209600980

commit f7bdf9518bce828d894515d1fa686532ebfb6da0
Author: Chris Lattner <clattner@google.com>
Date:   Sun Aug 5 21:12:29 2018 -0700

    Continue wiring up diagnostic reporting infrastructure, still WIP.
     - Implement a diagnostic hook in one of the paths in mlir-opt which
       captures and reports the diagnostics nicely.
     - Have the parser capture simple location information from the parser
       indicating where each op came from in the source .mlir file.
     - Add a verifyDominance() method to MLFuncVerifier to demo this, resolving b/112086163
     - Add some PrettyStackTrace handlers to make crashes in the testsuite easier
       to track down.
    
    PiperOrigin-RevId: 207488548

commit cb9ba66ffcca6857c823cad05550296bf213aafb
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Fri Mar 29 19:16:42 2019 +0000

    Fix crash of GFile in python 3.7
    
    This fix tries to address the issue raised in 27276 where
    in Python 3.7, opening a zip file (of GFile) will results in
    the error of
    ```
        bytes = self.zip.open(key)
      File "/usr/lib64/python3.7/zipfile.py", line 1480, in open
        self._fpclose, self._lock, lambda: self._writing)
      File "/usr/lib64/python3.7/zipfile.py", line 722, in __init__
        self.seekable = file.seekable
    AttributeError: 'GFile' object has no attribute 'seekable'
    ```
    
    The issue is that Python 3.7 adds seekable check:
    https://github.com/python/cpython/commit/066df4fd454d6ff9be66e80b2a65995b10af174f
    
    This fix adds `seekable()` and returns True, as GFile is indeed seekable.
    
    This fix fixes 27276
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 4dd52fbdc6476d7b562bea24de6b306135b8705c
Author: Smit Hinsu <hinsu@google.com>
Date:   Thu Mar 28 21:43:33 2019 -0700

    Use ASSERT_TRUE in TensorRT tests for is_tensor method calls
    
    This is to avoid crash later on in tensor method calls that fails if it is not
    tensor.
    
    PiperOrigin-RevId: 240917681

commit 0a9195cc36a3647966f320610cf1b5b107f4c9c7
Author: Trevor Morris <tmorris@nvidia.com>
Date:   Wed Mar 27 11:19:49 2019 -0700

    Fix type mismatch crash in CombinedNMS test. Fix compilation error due to absl::InlinedVector

commit 9acfe8a5922f76ea9b30a91fb3a17dba3a78ab77
Author: Tim Shen <timshen@google.com>
Date:   Fri Mar 22 17:52:30 2019 -0700

    Crash the program under debug flags only after logging the convolution protos.
    
    PiperOrigin-RevId: 239897994

commit cf0015569d9f4065344b93796af6241537b78204
Author: Tim Shen <timshen@google.com>
Date:   Fri Mar 22 14:44:39 2019 -0700

    Fix unintended nullptr arithmetic in BFCAllocator. This fixes occasional crashes when dumping OOM message under VLOG(1).
    
    PiperOrigin-RevId: 239867923

commit 063e47bf39352efbc5a89c2004ebb408599aebaa
Author: George Karpenkov <cheshire@google.com>
Date:   Wed Mar 20 09:20:07 2019 -0700

    Explicitly prohibit tuples as `select` HLO instruction operands,
    `tuple-select` should be used instead.
    Previously this was crashing during codegen.
    
    PiperOrigin-RevId: 239410490

commit 3aa72b5efc83f96c4279118d34576c06d990f16d
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Mar 15 03:57:19 2019 -0700

    cuDNN *is* safe to call from different threads with different handles. The crashes we saw were related to an ODR violation in our code, unrelated to cuDNN.
    
    PiperOrigin-RevId: 238616814

commit 987d993b18c6dedd7a2b3fba87417135d6ae7e04
Author: Smit Hinsu <hinsu@google.com>
Date:   Mon Mar 11 15:48:50 2019 -0700

    Fix crash from use of iterator after invalidation in grappler MutableGraphView
    
    PiperOrigin-RevId: 237900336

commit 94be8f012aa59730570bf71e6ba7cd2aa432a589
Author: Tim Shen <timshen@google.com>
Date:   Thu Mar 7 11:16:18 2019 -0800

    Roll-forward:
    
    Log convolutions during Tensorflow GPU conv autotuning. Also removed the same functionality from StreamExecutor.
    
    We decided to move the loggings from SE to TF and XLA for several reasons:
    * Proto formats already exist in TF and XLA that are suitable for logging. No need to create a third proto.
    * In TF and XLA autotuning stage, we also do/plan to do correctness checking. We want to log the checking results.
    * We are considering simplifying SE, so we prefer to keep SE simple for now.
    
    The original patch fails on Windows because the Windows linker crashes if it links an object file generated from an empty source file. In this CL, such empty source file is gpu_utils.cc, in the case where everything is #ifdef'ed out by GOOGLE_CUDA. To work-around it, simply don't compile such empty file at all for non-CUDA builds.
    
    PiperOrigin-RevId: 237284443

commit a20f47d5415453d883cd1d7fedd2a7a7b8447d9c
Author: Derek Murray <mrry@google.com>
Date:   Thu Mar 7 08:36:28 2019 -0800

    Provide a CancellationManager to kernels that run in a GraphRunner.
    
    Some kernels are (for example) constant foldable, but use
    `OpKernelContext::cancellation_manager()` internally (typically when
    running functions). A recent change made it possible for more kernels
    to run the GraphRunner (by providing a FunctionLibraryRuntime to the
    OpKernelConstruction), but no CancellationManager was available,
    leading to crashes when attempting to run those kernels.
    
    PiperOrigin-RevId: 237253404

commit f147da65a68dfd8cf8f7e0c3dc888936bd22e8e3
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Mar 5 05:52:51 2019 -0800

    Work around crash in nvcc by using the same #include files and order as max_pooling, which seems to not trigger the crash.
    
    PiperOrigin-RevId: 236832623

commit 710b322a8be78b8aff6b148575fcfe5301f42b64
Author: Alexandre Passos <apassos@google.com>
Date:   Tue Mar 5 09:04:41 2019 -0800

    Fixes #26048 , a crash with gradient tape and invalid states.
    
    PiperOrigin-RevId: 236858702

commit a543de12a902ddcf22fa9f4ef81941ad1f28d325
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Mar 5 05:52:51 2019 -0800

    Work around crash in nvcc by using the same #include files and order as max_pooling, which seems to not trigger the crash.
    
    PiperOrigin-RevId: 236832623

commit 383228b0d27f227eb6cf27deb8e3d02a4f09b45b
Author: Benjamin Kramer <kramerb@google.com>
Date:   Tue Mar 5 01:00:24 2019 -0800

    [XLA] Correctly expand scatters into scalars
    
    This is a valid edge case, don't crash on it.
    
    PiperOrigin-RevId: 236802786

commit 90f8ea920b082fc41d09026f6c788920d010d63f
Author: Mark Ryan <mark.d.ryan@intel.com>
Date:   Wed Feb 20 14:26:16 2019 +0100

    Fix eigen_spatial_convolutions_test benchmarks
    
    This commit fixes a crash in PackRhsHelper caused by a memory corruption
    error.  The function contains a loop that populates two vectors, one
    containing input Tensors and the other containing InputMappers that point to
    those input Tensors.  The problem is that the emplace_back call on the
    vector of input Tensors can cause that vector to grow which can
    invalidate the pointers to the previously allocated input Tensors.
    Unfortunately, these invalidated pointers are still used by the InputMappers
    in the second vector and so when we use the InputMappers we get a crash.
    The commit fixes the issue by reserving sufficient space in the input vector
    thereby preventing reallocations and invalidation of the pointers to the
    Input Tensors.
    
    Although the PackLhsHelper function does not crash on my machine it suffers
    from the same error and so this commit also contains a fix for that function.
    
    Fixes: https://github.com/tensorflow/tensorflow/issues/26251

commit fd0cbac98c605f5dd46662ada63efb1d6cc8516a
Author: Alexandre Passos <apassos@google.com>
Date:   Wed Feb 20 11:00:44 2019 -0800

    No need to crash when @tf.function arg names are not valid op names
    
    PiperOrigin-RevId: 234829230

commit 75a83c9a96d3ef8b64566e89da66505752c197a7
Author: Mustafa Ispir <ispir@google.com>
Date:   Tue Feb 19 15:40:28 2019 -0800

    Supports 0. regularization. Without this user needs to add an 'if else' when they do hyper parameter tuning for regularization.
    Currently it crashes if you provide `activity_regularizer=l2(0.)`. Core reason is that L1L2(..)() returns non-tensor object in case of `l=0.`.
    
    PiperOrigin-RevId: 234689073

commit 12c5e6c4ce6e22d5407abf7bb7c42748c313c5a5
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Feb 15 10:10:32 2019 -0800

    For negative dimension size of a tile, print "Invalid value xxx"
    instead of crashing.
    
    PiperOrigin-RevId: 234165280

commit b51e21629485ab6b6388304f19301cdf9c88502d
Author: Benjamin Kramer <kramerb@google.com>
Date:   Thu Feb 14 12:51:22 2019 -0800

    [XLA] Don't crash in when trying to simplify batch dots with no contraction dims
    
    Dot with no contraction is just a multiply. Not a super useful operation but
    valid HLO. AlgebraicSimplifier will rewrite it into a multiply, so don't even
    try simplifying it.
    
    PiperOrigin-RevId: 234010983

commit 6baa1f85beae5ce9410afed8666b355fe394cc3d
Author: Derek Murray <mrry@google.com>
Date:   Wed Feb 13 10:00:06 2019 -0800

    Replace CHECK with an error status in BaseRemoteRendezvous::RecvAsync().
    
    It should not be possible for RecvAsync to be called on an uninitialized BaseRemoteRendezvous, but some users have reported this happening, leading to server crashes. Replace it with an error status to enable recovery, and thread that error status back to the caller.
    
    PiperOrigin-RevId: 233774643

commit ce3ee9b6a45913c82d88331f12cf693cbe5e6014
Author: Davide Libenzi <dlibenzi@google.com>
Date:   Tue Feb 12 10:50:22 2019 -0800

    Initialize object variables in HLO evaluator.
    The lack of initialization of the dynamic_dimension_inference_ member was causing random crashes when used from a PT client.
    
    PiperOrigin-RevId: 233636726

commit ec7958da20ab7259b133d4e3c76d170fdb9f699b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Feb 6 13:05:13 2019 -0800

    Fewer TOCO crashes.
    
    PiperOrigin-RevId: 232730162

commit 3bfbcb2abdd02508ba2224df7315798805e7e198
Author: Bixia Zheng <bixia@google.com>
Date:   Wed Feb 6 10:36:35 2019 -0800

    [XLA] Fix algebraic simplifier to handle instruction without layout when
    transforming A / Const to A * (1 / Const).
    
    If the instruction that contains the constant value doesn't have a layout,
    algebraic simplifier crashes when creating the inverse of the constant value.
    The change is to always use the shape of the literal to create the new value.
    
    PiperOrigin-RevId: 232700905

commit 8b491637336083b40e9d4a38524463b18ba2825c
Author: Bixia Zheng <bixia@google.com>
Date:   Mon Feb 4 15:39:54 2019 -0800

    [XLA] InferGetTupleElementShape should report an error instead of crashing when
    the tuple index is a negative value.
    
    Add a shape_inference test case.
    
    PiperOrigin-RevId: 232380529

commit 25a1ab5dd01c34926048c931ecdf9f2ec63946eb
Author: Alexandre Passos <apassos@google.com>
Date:   Fri Feb 1 15:32:13 2019 -0800

    Fix issue where tf.function(variable, variable) crashes.
    
    PiperOrigin-RevId: 232049223

commit 983a547e85b5cd6e6abf62bacc0e2370d474577b
Author: Michael Kuperstein <mkuper@google.com>
Date:   Thu Jan 31 13:15:04 2019 -0800

    [XLA] Make replay_computation not crash when compile fails.
    
    PiperOrigin-RevId: 231840092

commit d7640706ca636b590e0d2cb272c0ca48a038720c
Author: Tong Shen <endlessroad@google.com>
Date:   Thu Jan 31 13:13:44 2019 -0800

    Fix FunctionalizeCond crash when fed with invalid control flow graph.
    
    In some cases, we might get invalid control flow graph where Merge node inputs are not in any CondContext. As a result, in JoinCondStatesMerge(), the CondId 'src' will be nullptr. Check this case and return an error.
    
    PiperOrigin-RevId: 231839691

commit 2cb0880812a9a99485feb2bbbfa9b8aca430a6c6
Author: Bixia Zheng <bixia@google.com>
Date:   Wed Jan 30 09:52:02 2019 -0800

    [XLA] Fix problems in handling kParameter HLO instruction with negative
    parameter number.
    
    When the input is HLO text that contains kParameter instructions with negative
    parameter numbers, an HLO tool such as run_hlo_module, crashes in creating the
    HloComptation. We fix the HLO parser to report errors instead. Add an HLO
    parser test case.
    
    When the input is a binary HLO proto that contains kParameter instructions with
    negative parameter numbers, run_hlo_module crashes in verifying the module. We
    fix the DynamicParameterBinding verifier to report errors instead. Add an HLO
    proto corpus for fuzzing.
    
    PiperOrigin-RevId: 231612816

commit 87120ddf5881215bb7bb76169543d1705ca754f4
Author: Justin Lebar <jlebar@google.com>
Date:   Tue Jan 29 16:05:40 2019 -0800

    [XLA] Add literal C64/C128 support to HLO parser.
    
    Now the parser can handle complex numbers.
    
    In addition, this patch fixes a few bugs I discovered:
    
     - We weren't checking for out-of-range values in sparse literals.
     - We were saying that bf16 values > F16_MAX were invalid, but in fact bf16 has
       a higher dynamic range than this.
     - We were accepting invalid sparse indices.  Strangley this doesn't crash or
       anything.
    
    PiperOrigin-RevId: 231492104

commit fc4dbb6ab580776cfe0c5e88374c425f49728621
Author: Bixia Zheng <bixia@google.com>
Date:   Mon Jan 28 21:25:53 2019 -0800

    [XLA:GPU] Fix a bug related to GPU constant buffer name collision.
    
    Having a hyphen or a dot in the name of an LLVM global variable for a GPU
    constant buffer can crash the LLVM PTX backend. This happens when a constant
    buffer is created for an HLO constant instruction that contains such
    characters in its name. Previously, we sanitize the names of the HLO constant
    instruction by replacing such characters with underscores during LLVM IR
    emission. However, this approach has a problem in handling name collision due
    to name sanitization. In particular, when the same sanitized name is used to
    create global variables for the constant buffers of two different HLO constant
    instructions, LLVM resolves the name conflict by appending a unique number to
    the sanitized name. Later on, during LLVM IR emission or GPU kernel execution,
    we simplify use the sanitized name of an HLO constant instruction to look up
    the global buffer for the constant and find a wrong buffer. This change adds
    an HLO pass to sanitize the HLO constant instruction names before LLVM IR
    emission.
    
    Relocate gpu_buffer_assignment_test.cc to gpu_sanitize_constant_names_test.cc
    and modify the tests for the purpose of testing the new pass that sanitizes HLO
    constant instruction names.
    
    PiperOrigin-RevId: 231342192

commit 93b8126565fa3ad8808142e81370a81d19d81ea1
Author: Bixia Zheng <bixia@google.com>
Date:   Fri Jan 25 21:40:01 2019 -0800

    [XLA:GPU] Avoid using hyphens in global buffer names.
    
    Having a hyphen in a global variable name can crash the PTX backend. When the
    name of an Hlo instruction is used to construct a name of the global buffer for
    the instruction, replace hyphens with underscores.
    
    Add two test cases.
    
    PiperOrigin-RevId: 231017603

commit 12888c45f6e1d12836bf79afdd1035f1c566ca9a
Author: Bixia Zheng <bixia@google.com>
Date:   Wed Jan 23 15:34:07 2019 -0800

    [XLA] Fix the ShapeVerifier to report an error for non-array returning iota
    instructions.
    
    Previously, the ShapeVerifier crashes when handling non-array returning iota
    instructions.
    
    Add a test case.
    
    PiperOrigin-RevId: 230616042

commit 76aa6cf917d719183a82d47970a6f98333740420
Author: Dimitris Vardoulakis <dimvar@google.com>
Date:   Tue Jan 22 22:34:07 2019 -0800

    [TF:XLA] Fix the AR/CRS combiner to avoid crashing when two cross-module AllReduces lead to the same cross-replica AllReduce.
    Also, add tests RewriteMultipleAdds and RewriteArSubtractCrs to document existing behavior of the pass.
    
    This graph:
    
    A
    |
    AR    B   C
     \   /    |
       +     AR
        \   /
          +
          |
         CRS
    
    gets rewritten to:
    
        B  const  C
         \   /    |
     A    Div    AR  const
      \   /      |  /
        +       Div
         \     /
            +
            |
           CRS
    
    Ideally, we would remove both cross-module AllReduces. It's not not straightforward to do that, so I'm leaving it for a separate CL.
    
    PiperOrigin-RevId: 230472380

commit 708090d48995456bfa66615398d8c56dadebe018
Author: James Ring <sjr@google.com>
Date:   Fri Jan 18 15:59:16 2019 -0800

    Make TF_DeleteKernelBuilder not crash on nullptr.
    
    After this change, TF_DeleteKernelBuilder will comply with the
    conventions established in c_api.h, namely that *Delete* functions are
    safe with nullptr parameters.
    
    PiperOrigin-RevId: 230009727

commit 53c44a9ac4e69c788ef5b707d21c0f364eedb9a8
Author: Guangda Lai <laigd@google.com>
Date:   Thu Jan 17 09:06:26 2019 -0800

    Make a real repro for IConstantLayer: we need to call getType() before
    getDimensions(), then if CreateConstantLayer() doesn't set the dtype, the test
    will fail.
    
    Before CreateConstantLayer() was added, graphs which trigger conversion of INT32
    weights to IConstantLayer will crash the TRT conversion. This is a bug in TRT
    5.0 and I has reported it to NVIDIA. CreateConstantLayer() fixed that by setting
    the dtype of the output ITensor of the IConstantLayer, but the added test could
    not reproduce the error when we remove the setting code. This change fix the
    test, so when removing the dtype setting logic the test will fail.
    
    Note that, after this fix, during conversion it'll report a lot of spammy logs
    but won't crash. Once NVIDIA fixed the TRT bug we should remove the dtype
    setting logic and the test should still pass.
    
    PiperOrigin-RevId: 229758150

commit 04181795a31d2b332aa0d0fc5daf9d254432c042
Author: Igor Ganichev <iga@google.com>
Date:   Wed Jan 16 10:24:17 2019 -0800

    Add num_values argument to Tensor::DebugString()
    
    Non-CPU Tensors cause a crash when DebugString() tries to access
    their values. num_values can be used not to access the values or
    print more than default of 3 during debugging.
    
    PiperOrigin-RevId: 229581029

commit bf5cd5e750f31b95cd06f8ff75fe9bda30d84bee
Merge: 2225d4d16dc e55ec99c9ef
Author: TensorFlower Gardener <gardener@tensorflow.org>
Date:   Wed Jan 16 07:01:56 2019 -0800

    Merge pull request #24345 from ajweiss:xla_old_gpu_crash
    
    PiperOrigin-RevId: 229550001

commit 0bc02af7db9e43c37a89278a2e7c99ecdfe4fb00
Author: Andrew Selle <aselle@google.com>
Date:   Tue Jan 15 23:12:00 2019 -0800

    Fix demo app to handle some cases more properly
    
    - Don't crash when threads are changes with a delegate. This is done by now recreating interpreter every time threads is changes.
    - Don't call showToast() every updateFrame() when classifier is null. This prevents hanging and allows the proper error message to be displayed.
    
    PiperOrigin-RevId: 229503428

commit 01c19850c0fd6b587f44ab5938e2d874744a2cbf
Author: Dimitris Vardoulakis <dimvar@google.com>
Date:   Mon Jan 14 15:21:18 2019 -0800

    [TF:XLA] Fix crash in AR/CRS combiner, when a cross-module AllReduce is immediately followed by a cross-replica AllReduce.
    
    PiperOrigin-RevId: 229265445

commit e55ec99c9ef627d84750853f9ae83196723852d5
Author: Adam Weiss <adam@signal11.com>
Date:   Thu Dec 13 15:22:36 2018 -0500

    [XLA] Wrap LocalComputationBuilder::GetOrCreateLocalClient with StatusOr<T>
    
    Prevents crashes when GPUs present, but below minimum capability level

commit 5a02334ec90f2c6a91418ae14f3f28428fd52249
Author: Tom Hennigan <tomhennigan@google.com>
Date:   Tue Dec 18 01:27:52 2018 -0800

    Improve error message when function local variables are GC'd.
    
    New message:
    
    ```
    ValueError: A tf.Variable created inside your tf.function has been garbage-collected. Your code needs to keep Python references to variables created inside `tf.function`s.
    
    A common way to raise this error is to create and return a variable only referenced inside your function:
    
    @tf.function
    def f():
      v = tf.Variable(1.0)
      return v
    
    v = f()  # Crashes with this error message!
    
    The reason this crashes is that @tf.function annotated function returns a **`tf.Tensor`** with the **value** of the variable when the function is called rather than the variable instance itself. As such there is no code holding a reference to the `v` created inside the function and Python garbage collects it.
    
    The simplest way to fix this issue is to create variables outside the function and capture them:
    
    v = tf.Variable(1.0)
    
    @tf.function
    def f():
      return v
    
    f()  # <tf.Tensor: ... numpy=1.>
    v.assign_add(1.)
    f()  # <tf.Tensor: ... numpy=2.>
    ```
    
    PiperOrigin-RevId: 225957777

commit ab6229b58371c8f1c384a8a77d2bec5f72b4d990
Author: Peter Hawkins <phawkins@google.com>
Date:   Fri Dec 14 06:11:14 2018 -0800

    [XLA] Fix crash if a zero-element array was passed to TriangularSolve.
    
    In passing, remove redundant xla:: prefixes from the triangular solve test and reformat.
    
    PiperOrigin-RevId: 225530438

commit 27cffd795981f6d86e3b09b6d82c384d8b4e117a
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu Dec 13 11:36:51 2018 -0800

    [XLA:CPU:Mac] Add __bzero intrinsic on Mac.
    
    Make the log message on missing intrinsic louder (ideally, we wouldn't crash, too.)
    
    PiperOrigin-RevId: 225407043

commit dba64a3f5a7998166b36e4b9287504ed506e9379
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Dec 11 08:18:58 2018 -0800

    Reset XRT memory allocations at ConfigureDistributedTPU time.
    Using XRTAllocate to register device memory, a user gets back int64 handles which needs to be explicitly deleted in order to avoid memory leaks.
    If a client crashes (or has bugs in its handle release logic), a remote TF server will be leaking memory with no possibility of recover.
    Since clients always run a ConfigureDistributedTPU at boot time, we clear the XRT allocated resource manager container at that time.
    Also add a new XRTReleaseAllAllocations operation, to clear all the XRT memory on the target host.
    
    PiperOrigin-RevId: 225006277

commit c07297759059a953351f1d5e531b6e6af878365c
Author: Peter Hawkins <phawkins@google.com>
Date:   Mon Dec 10 10:04:47 2018 -0800

    [XLA:CPU] Add missing intrinsics on Mac OS X.
    
    Fixes crashes seen in JAX test suite on Mac OS.
    
    PiperOrigin-RevId: 224832861

commit 7578e120de2a3a5282ced8d41881f19363f83466
Author: Dan Jarvis <daj@users.noreply.github.com>
Date:   Thu Nov 23 13:06:02 2017 -0500

    Fix crash on closing the app when classifier failed to initialize
    
    When testing on an API 21 emulator, the classifier fails to initialize.
    `E/TfLiteCameraDemo: Failed to initialize an image classifier.`
    
    In this situation, the app crashes when pressing Back to exit.  Here's the cause:
    ```
    java.lang.NullPointerException: Attempt to invoke virtual method 'void com.example.android.tflitecamerademo.ImageClassifier.close()' on a null object reference
                                                                                            at com.example.android.tflitecamerademo.Camera2BasicFragment.onDestroy(Camera2BasicFragment.java:331)
                                                                                            at android.app.Fragment.performDestroy(Fragment.java:2266)
    ```
    The fix is to check for null before calling `.close()`.
    
    I'll investigate why the classifier is failing to initialize separately. :-)

commit 99c20bf32e29a90dbb31f480360eb8881f0bd411
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 28 17:48:11 2018 -0800

    Register DataFormatVecPermute with label "host" on CPU to work around crash due to missing kernel.
    
    PiperOrigin-RevId: 223268202

commit 02a69ef199e2ed05a3498d3ee738bd493fe48b77
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 28 15:18:56 2018 -0800

    Test to show how constant 1D gather crashes toco.
    
    PiperOrigin-RevId: 223245378

commit f96b9ab51fbad077eb75af8595dcd7779a01b97b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 21 15:55:03 2018 -0800

    This CL marks the `ReduceDataset` op as not differentiable, to avoid crashes when it gets caught inside functions whose gradients are computed.
    
    PiperOrigin-RevId: 222471432

commit 8242bee9287540979a509afb4e6f3f21e18f0fe4
Author: Tim Shen <timshen@google.com>
Date:   Mon Nov 19 17:00:51 2018 -0800

    Fix some crashes caused by adding kInt32.
    
    PiperOrigin-RevId: 222163922

commit 7b712dcdccb45b958e415166b0a2460dbcda85f4
Author: olicht <29300900+olicht@users.noreply.github.com>
Date:   Sun Nov 18 12:29:30 2018 +0200

    Preventing crash when building with local MKL
    
    Preventing crash when MKL include dir. contains something else (e.g. fortran defs.).

commit 7edeed733eda7eb3e591afe95562097e72d3b173
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 14 13:11:08 2018 -0800

    This CL fixes a crash that happens when fitting in Keras without scipy sparse libraries being installed.
    
    PiperOrigin-RevId: 221496911

commit 5db911ce7c9392c96966ba7f8031c2e512b4b924
Author: Peter Hawkins <phawkins@google.com>
Date:   Fri Nov 9 12:40:02 2018 -0800

    [TF:XLA] Fix a crash when returning a variable update from a computation with a zero-element shape.
    
    PiperOrigin-RevId: 220847491

commit e66aea59e0367618f924ffe3bc3b1140be8eaf45
Author: Brennan Saeta <saeta@google.com>
Date:   Sun Oct 28 17:20:28 2018 -0700

    [tf.data / Cloud Bigtable]: Avoid underflow.
    
    Previously, because the size_t type is unsigned, if keys_.empty(), we would underflow, instead of returning end_of_sequence, resulting in a runtime crash. This change switches around the arithmetic so that it's robust to underflow.
    
    PiperOrigin-RevId: 219062746

commit a0bfbd2241f4ca8b01dc78fb9ffe856477e47c7f
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Oct 25 15:23:36 2018 -0700

    Add test for a bug in broadcast_to_op.h, and then verify that it is fixed.
    
    The bug is a crash when running on the GPU in the constant construction.
    
    PiperOrigin-RevId: 218760066

commit 3f7d60ca9d3f8037ba752220e80fc95d3c0be71a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Oct 16 17:56:15 2018 -0700

    Cleanup: Don't crash when querying node for non-existing attributes.
    
    PiperOrigin-RevId: 217420663

commit 109a0c1b15d5ba7389bb82facd48aeb8477e89af
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Sat Oct 13 20:16:31 2018 -0700

    Disables logging and summaries of steps, steps/s, loss etc. when RunConfig.log_step_count_steps is None.
    
    This is already how Estimator works (as one can see in line 2136 where we explicitly replace log_step_count_steps as None).  It should be backward compatible as current code would have crashed if log_step_count_steps is None.
    
    PiperOrigin-RevId: 217019985

commit c304bd9bc9165cc3c600c8e77713e884844dc0e3
Author: Mark Heffernan <meheff@google.com>
Date:   Thu Oct 11 12:07:19 2018 -0700

    Add Unimplemented visitor for token element types to HLO evaluator.
    The evaluator would crash when encountering an instruction which produced a
    TOKEN shape.
    
    PiperOrigin-RevId: 216737937

commit dd03b7d2a55b5501f3fcabc4ff0701ac2e9b3364
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Oct 10 15:54:35 2018 -0700

    Don't crash an XRT server if a client leaks a compilation reference.
    
    PiperOrigin-RevId: 216608167

commit 68e869eb40ff0acd03515336bf31eecbabf97adc
Author: Todd Wang <toddwang@gmail.com>
Date:   Thu Oct 4 15:54:17 2018 -0700

    Disable tensorrt:unary_test in OSS since it crashes with SEGV. (#22754)
    
    PiperOrigin-RevId: 215814732

commit a08ca5bb74fcd828c19060216923ad0f378bb518
Author: Todd Wang <toddw@google.com>
Date:   Thu Oct 4 15:29:58 2018 -0700

    Disable tensorrt:unary_test in OSS since it crashes with SEGV.
    
    PiperOrigin-RevId: 215814732

commit a12b8c4afdca3ac2945d62b3b83ca2599ab360f9
Author: Keno Fischer <keno@juliacomputing.com>
Date:   Sun Sep 16 18:39:50 2018 -0400

    [xla] Improve validation of Broadcast shape
    
    If one misreads the semantics of this instruction, it's easy to cause
    an out of bounds access into the dimensions here. Add an extra check
    to return a proper error to the user rather than crashing in that
    case.
    
    Ref #22130

commit cc5555d3d3daa64f462cc7f8d31fe915073429f4
Author: Tim Shen <timshen@google.com>
Date:   Mon Sep 24 16:57:45 2018 -0700

    Short-circuit AllOf as well. This fixes a crash in ConstantScalar, as it
    uses Cast internally.
    
    PiperOrigin-RevId: 214356411

commit 167272ead245ac9e0183da807d996ba9d6e401b0
Author: Derek Murray <mrry@google.com>
Date:   Sun Sep 23 18:28:36 2018 -0700

    [tf.data] Add `tf.contrib.data.Optional` support to `Structure`.
    
    This change switches `tf.contrib.data.Optional` to use a `Structure` class to represent
    the structure of its value, instead of `output_types`, `output_shapes`, and `output_classes` properties. It adds support for nesting `Optional` objects and representing their structure.
    
    This change also makes a modification to the `Structure` class: `Structure.is_compatible_with(x)` now takes another `Structure` as the `x` argument, instead of a value. This makes it easier to work with nested structures (where we might not have a value readily available), and better matches the interface of other `is_compatible_with()` methods (e.g. in `tf.TensorShape` and `tf.DType`).
    
    Finally, in the process of making this change, I observed possible crash-failures when a DT_VARIANT tensor containing another DT_VARIANT tensor is copied between CPU and GPU. This change "fixes" the immediate problem by raising an UnimplementedError, but more work will be necessary to support the full range of use cases.
    
    PiperOrigin-RevId: 214198993

commit 86b4d8e65c62ff0be930e8c179f077cb83666aff
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Sep 21 13:27:50 2018 -0700

    Don't crash on Pack nodes with no axis argument set.
    
    PiperOrigin-RevId: 214035048

commit 97011c17de3f21ae7d40f89f09bf7513dc0e49aa
Author: Geoffrey Irving <irving@naml.us>
Date:   Fri Sep 7 09:01:56 2018 -0700

    Make tf.random_uniform([0], maxval=0, dtype=tf.int32) not crash
    
    For integers, tf.random_uniform enforces a nonempty range with minval < maxval.
    However, an empty range is fine if we're producing no output values, and
    this degenerate case occurs naturally for some code patterns.
    
    Thus, tf.random_uniform now allows empty ranges for integer random
    numbers if the output shape is empty.

commit 3a2276ced02b217596080fb34654d2dce5069f81
Author: Benjamin Kramer <kramerb@google.com>
Date:   Fri Sep 14 01:24:52 2018 -0700

    [XLA:TF] Make FloorDiv not crash on unsigned types
    
    FloorDiv (which corresponds to the // operator in python) supports uint8 and
    uint16 (but not uint32) in TF. Using xla::Abs on unsigned types throws an error,
    but the rounding logic is trivial for unsigned types so just do a plain Div.
    
    This isn't tested yet because we don't have any targets supporting uint8 or
    uint16 yet.
    
    PiperOrigin-RevId: 212946132

commit 87ab69541f71e83a490fc2e1563bf1094665d2ab
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Aug 30 14:00:46 2018 -0700

    Make dtype in Image class actually modifiable.
    
    Changing dtype to any other type other than default will cause a crash because
    decode_jpeg or decode_image will promise to return uint8 all the time while
    decode_raw will actually vary its return type. This mismatch of types causes
    tf.case to fail and  makes dtype parameter unusable.
    
    PiperOrigin-RevId: 210975290

commit a73bc982669c8eb4bec9418a94a96b64551e641b
Author: Yunxing Dai <yunxing@google.com>
Date:   Thu Aug 23 14:53:20 2018 -0700

    Do not crash when an empty tuple is passed into hlo_sharding.
    
    PiperOrigin-RevId: 210005372

commit 4f41091f88cca9c87a627864ccd6962e7bb44313
Author: Benjamin Kramer <kramerb@google.com>
Date:   Tue Aug 21 12:35:33 2018 -0700

    [XLA] Propagate invalid shape errors through reduce folding and turn it on
    
    HloEvaluator should be stable enough for reduce folding, but it shouldn't
    crash when it encounters an instruction without a layout. Verify the layout on
    every instruction that gets evaluated and return an error on failure.
    
    PiperOrigin-RevId: 209641401

commit ce3ad57dd94f5b0c16b96768dc2acfca3db5f5ee
Author: Tim Shen <timshen@google.com>
Date:   Thu Aug 16 13:42:48 2018 -0700

    Add a flag to crash on cuDNN cross checking failures.
    
    PiperOrigin-RevId: 209039444

commit d2bec062040bfa083195c06deef56981c6f0f946
Author: Andrew Selle <aselle@google.com>
Date:   Fri Aug 10 11:51:36 2018 -0700

    Fix crash where model_path input to tflite python interpreter segv.
    
    Fix by holding reference to passed in model_content and relying on
    immutability of PyString (pointer doesn't change).
    
    PiperOrigin-RevId: 208244957

commit aed8f42bafabf11c5d92ce4109a5e0408b31f9c5
Author: Peter Hawkins <phawkins@google.com>
Date:   Tue Aug 7 03:53:15 2018 -0700

    [TF:XLA] Add test that verifies that transfers on and off XLA devices do not crash, even for unsupported types.
    
    PiperOrigin-RevId: 207691957

commit f8e8c0c6f7746d3f2b5820e76c9e382149090034
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jul 23 14:53:58 2018 -0700

    Fix for conditional attributes crashing in static analysis
    
    PiperOrigin-RevId: 205729321

commit 36a66347e8e344cddee4a8d9123ccbcae40011b1
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Jul 17 17:04:15 2018 -0700

    Error on some documented invalid Cudnn inputs. Cudnn should have
    returned errors, but crashes instead.
    
    PiperOrigin-RevId: 205000883

commit 814f9ccd9b34a828f93d33eee6265e0cac07095a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jul 16 12:06:37 2018 -0700

    Use the safe sparse tensor API that returns errors rather than crashing
    in all TensorFlow core kernels.
    
    PiperOrigin-RevId: 204782675

commit b50e7b980c983beab90e62f6013aa3dc2f50ac7f
Author: Adrian Kuegel <akuegel@google.com>
Date:   Wed Jul 11 03:10:49 2018 -0700

    Clamp gather indices instead of wrap-around.
    
    So far, the behavior for out of bounds cases is undefined as
    long as it does not crash. Clamping is cheaper because we don't
    need a URem operation, and for DynamicSlice we already do that.
    
    PiperOrigin-RevId: 204096995

commit 0063183a62f69c2523a3982c70d72e231428fb60
Author: Adrian Kuegel <akuegel@google.com>
Date:   Mon Jul 9 02:47:53 2018 -0700

    Fix crash when running with --v=2.
    
    When doing multi-output fusion and using sibling fusion, it can happen that we
    don't need to clone the 'instruction_to_fuse' argument. Right now, we clone,
    and then delete the clone again, and at the end of the function try to print
    the debug string for the clone (which then crashes).
    Instead, we can simply not generate the clone if it is not needed, and catch
    this case before printing the debug string.
    
    PiperOrigin-RevId: 203733796

commit 98a829817c027b9681a728160c746bcc63ad86b9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jun 18 19:14:12 2018 -0700

    HloInstruction::CreateFromProto should not crash on CHECK, instead needs to return error status.
    PiperOrigin-RevId: 201100918

commit 80eb65f367c8a5b8a80e752984e001f2479761d6
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 7 16:17:00 2018 -0700

    TOCO: return Status instead of crashing while converting "Conv".
    
    PiperOrigin-RevId: 199714511

commit 93cb963ed957fa6f061b3aced65dd04791970cb8
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Jun 6 10:37:45 2018 -0700

    Fixes an error where a defun with no outputs crashes when called on inputs being taped.
    
    PiperOrigin-RevId: 199488561

commit 7d195d0d4936cbf289d2d5c590f82471ee8259ad
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jun 4 16:43:33 2018 -0700

    Fix an floating point inaccuracy issue in precision_recall_at_equal_thresholds due
    to accumulating the tp/fp/tn/fn values in float32, which can become highly inaccurate
    as the number of values increases.
    
    In the common case, the method sums the value 1.0f to the tp/fp/tn/fn bucket for every
    value in the predictions tensor.  If the tensor is large (say, it represents an image
    and we have one tp/fp/tn/fn value per pixel), then we are essentially adding many 1.0f's
    together, across the entire batch and also across all the batches.  By doing it in
    float32 the value starts becoming inaccurate at around 16M, which is very small.
    
    In practice, we see a deviation of 100x when the total reaches about 3e10 (the previous
    code reports a number about 1e8 when the actual value should be 3e10).
    
    We avoid all these issues by always accumulating in float64.
    
    Also fix a bug that the method cannot be called with predictions dtype being anything
    other than float32.  Preivously it would crash due to the eps code near the end.
    Added tests for using float64 and float16.
    
    PiperOrigin-RevId: 199216173

commit 69340bdffcc1507e39880decfb467f8d68981a86
Author: Ruoxin Sang <rxsang@google.com>
Date:   Wed May 30 18:11:10 2018 -0700

    Remove code returning bad status when the input pointer is nullptr in internal
    functions. That should be a programmatic error and we have full control of
    internal functions, so it is OK to crash if error happens.
    
    PiperOrigin-RevId: 198651749

commit 4efdf365fa5a86c83ea29880ec5043fbb0e018d8
Merge: 5cfa305bf49 ce11f0b65d3
Author: Xiaoqiang Zheng <zhengxq@google.com>
Date:   Fri May 18 16:37:27 2018 -0700

    Merge pull request #19338 from girving/clip
    
    Make tf.clip_by_value not crash on empty tensors

commit b9459a1014bdffa6ab7a5a0944181410f0b5c0be
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Fri May 18 17:29:26 2018 +0000

    Add test case for empty tensor with clip ops.
    
    This fix is based on 19337 and 19338. The issue was that
    previously an empty tensor for tf.clip_by_value on GPU
    triggers a crash. The issue should have been fixed by 19338 and
    the recent master. It makes sense to adds the test case for this issue.
    
    This fix adds the test case.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit a3b86f9c2dfbe2cff6a3b6362f9e0f131246eb0b
Author: Younghee Kwon <youngheek@google.com>
Date:   Thu May 17 16:52:17 2018 -0700

    boosted_trees: fixed the crash when eval/prediction is attempted with the initial checkpoints (at step 0) before training.
    
    PiperOrigin-RevId: 197073582

commit ba30ba07b213687d0014a2149963780a26c59e64
Author: Mark Ryan <mark.d.ryan@intel.com>
Date:   Thu May 17 18:17:39 2018 +0100

    Fix alignment crashes in AVX512 builds (#19121)
    
    * Fix issue #15588 by simplifying the code
    
    The allocator.h code tried to be clever and use 32 byte alignment for SSE/AVX2/etc use,
    and 64 byte alignment for AVX512.
    
    Unfortunately, the #ifdef in use (from EIGEN) is not useful; the bazel BUILD files do
    not propagate the tf_copts() compiler flags when the allocator.cc/allocator.h files get
    compiled, to EIGEN does not see the actual AVX512 using compiler flags...
    
    Rather than changing compiler flag propagation throughout a whole bunch of code,
    there's an opportunity to just simplify the code and always use 64 byte alignment.
    Yes it wastes a bit of space, but on the other hand now these allocations are
    cache line aligned which isn't a bad thing... and an ifdef can be dropped
    
    Signed-off-by: Arjan van de Ven <arjan@linux.intel.com>
    
    * Set EIGEN_MAX_ALIGN_BYTES=64
    
    This patch sets a 64 byte upper bound on the alignment of memory allocated by
    eigen.  This is necessary to prevent crashes during the execution of the unit
    tests when they are compiled with AVX512 support.
    
    Signed-off-by: Mark Ryan <mark.d.ryan@intel.com>
    
    * Update the tensorflow/compiler/aot tests for 64 byte alignment
    
    Modifications to the tensorflow/core/framework/allocator.h to always
    use 64 byte alignment causes failures in the tensorflow/compiler/aot
    unit tests.  This patch updates these tests so that they pass with
    64 byte aligned allocated memory.
    
    Signed-off-by: Mark Ryan <mark.d.ryan@intel.com>
    
    * Update Tensor.Slice_Basic for 64 byte alignment
    
    The test case
    
    //tensorflow/core:framework_tensor_test:Tensor.Slice_Basic
    
    fails with EIGEN_MAX_ALIGN_BYTES set to 64.  The reason is that the
    slices it takes of the sample tensor are 32 byte and not 64 byte
    aligned.  This commit increases one of the dimensions of the original
    tensor to ensure that the slices taken by the test cases are indeed 64
    byte aligned.
    
    Signed-off-by: Mark Ryan <mark.d.ryan@intel.com>
    
    * Update ScopedAllocatorConcatOpTest.Reshape for 64 byte alignment
    
    The ScopedAllocatorConcatOpTest.Reshape test requires that the elements
    of the field_shapes parameter of ExecOp are multiples of
    Allocator::kAllocatorAlignment in size.  If they are not, the backing
    tensor allocated by PrepOp will have too many elements and reshaping
    will fail.  This commit modifies the test case, making the elements
    64 bytes in size, the new value for Allocator::kAllocatorAlignment.
    
    Signed-off-by: Mark Ryan <mark.d.ryan@intel.com>

commit ce11f0b65d3e4d0bf2b03f5956cb34cb3d96ad89
Author: Geoffrey Irving <irving@naml.us>
Date:   Wed May 16 15:47:58 2018 -0700

    Make tf.clip_by_value not crash on empty tensors
    
    Also rearrange the code to remove duplication.  No tests yet; I'll leave
    refactoring the test cases for empty tensor coverage to someone else.
    
    Fixes #19337.

commit 2451eef12c6b6b09dbf6b5b4a19d95272e197409
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Mon May 14 16:07:33 2018 -0700

    Fix bug where custom layers could crash.
    
    Layer.add_weight would crash when called without a dtype or initializer.
    
    PiperOrigin-RevId: 196583182

commit 22d5f0b6a94a9f5b05444b4141f39f4703c23515
Author: AG Ramesh <ag.ramesh@intel.com>
Date:   Sat May 12 18:35:11 2018 -0700

    Fix for crash in mkl_layout_pass_test (#19107)

commit 7a7bbc303c451fea5b3dd93109028531a89a18ab
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri May 4 02:22:14 2018 -0700

    Do not crash on ROOT outfeed operations.
    
    PiperOrigin-RevId: 195388075

commit a82e0e7922d6dc657b42ef2b3a7a1a52194454c8
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue May 1 09:07:57 2018 -0700

    Fix crash in HloGraphDumper where it crashes on tuple shaped constants
    
    The problem is that it tries to use a special logic for 0 element constants
    but the logic used to check the number of elements only supports array shapes.
    
    PiperOrigin-RevId: 194945246

commit 1ff23a314f355a9ebaaf207dbeae56ebc1634d63
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 30 16:43:14 2018 -0700

    Small fix to prevent a crash if the delegate has not implemented FreeBufferHandle.
    
    PiperOrigin-RevId: 194866595

commit 173aadc6b62dd95691257c2d9f158dd9044bb4ef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Apr 19 11:55:46 2018 -0700

    Change estimator to only log non-binary eval metrics, because logging binary metrics such as images will lead to crash.
    
    PiperOrigin-RevId: 193551927

commit f3d2fdf088ea6674f0c0b034af04b99fc1a830dc
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Apr 18 13:54:52 2018 -0700

    Replace six.get_unbound_function with a simpler version that doesn't crash for methods of tf.keras.Model.
    
    PiperOrigin-RevId: 193411332

commit 111e04aed22fdeed494580dae127720326c1b8ee
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 9 10:38:58 2018 -0700

    Add validation for output_index of Feed.id.
    Return error instead of crash if output_index is not less than the output number of the operation.
    
    PiperOrigin-RevId: 192148911

commit c9ae6a7bc7b8dfdb438207f265b61b3212651b64
Author: David G. Andersen <dga@google.com>
Date:   Tue Jan 30 12:06:40 2018 -0800

    Eliminate crash on a 'no error' return from DecodeGif when parsing an invalid
    gif.  (Previous code tried to strcat a null).
    
    PiperOrigin-RevId: 183870288

commit 3a279f15fde94882c27670dee313ce501cba92b9
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 9 10:38:58 2018 -0700

    Add validation for output_index of Feed.id.
    Return error instead of crash if output_index is not less than the output number of the operation.
    
    PiperOrigin-RevId: 192148911

commit 3c1d5bc91be37396c73060bf123ead784741c6ef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 9 10:38:58 2018 -0700

    Add validation for output_index of Feed.id.
    Return error instead of crash if output_index is not less than the output number of the operation.
    
    PiperOrigin-RevId: 192148911

commit eb35f19cf7e8c43cfb759bce2fab266ae753f0d0
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 16 19:51:13 2018 -0700

    Supply a dtype to super constructor, without which build() seems to crash.
    
    PiperOrigin-RevId: 193139585

commit 9e4818375f3853c1a8cdd18fe22d1b1f447cfaef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Apr 13 10:30:32 2018 -0700

    Disable x * x -> square(x) Grapler rewrite for complex types unless the op is on CPU. Square is not registered for complex types on GPU, and doing so produces a crash in with CUDA_ILLEGAL_INSTRUCTION when running it on open source ubuntu.
    
    PiperOrigin-RevId: 192788160

commit 0c2ca00e1082ab2692af68af183083e41393f6c4
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Fri Apr 13 11:38:43 2018 -0700

    Fix crash when invalid dtype was passed (#18481)
    
    * Fix crash when invalid dtype was passed
    
    This fix tries to address the issue raised in 18474
    where crash may happen if invalid dtype (e.g., `"[,]"`)
    is passed to `tf.constant(tf.string, "[,]")`. The crash
    happens during the comparision of `"[,]"` and numpy dtype
    candidate (e.g., `np.dtype([("qint8", np.int8, 1)])`:
    ```
    >>> import numpy as np
    >>> np.dtype([("qint8", np.int8, 1)]) == "[,]"
    Segmentation fault: 11
    ```
    
    This fix adds a type check to make sure the type of the passed
    dtype is either numpy.dtype or type.
    
    This fix fixes 18474.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test case for invalid type to tf.constant
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 692a71da6aad55dcaa597633aaf88de8322ca8ab
Author: Yu-Cheng Ling <ycling@google.com>
Date:   Fri Apr 13 11:33:07 2018 -0700

    Fix the broken TFLite iOS example. (#18483)
    
    The demo app is only relying on CocoaPod now, but it's incorrectly
    configured to use the headers on Github. It crashes the app when
    the header is different between Github and CocoaPod.

commit 6e8c908c8e299ddb46ac20b6a668e37ed37f24c0
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Apr 13 10:30:32 2018 -0700

    Disable x * x -> square(x) Grapler rewrite for complex types unless the op is on CPU. Square is not registered for complex types on GPU, and doing so produces a crash in with CUDA_ILLEGAL_INSTRUCTION when running it on open source ubuntu.
    
    PiperOrigin-RevId: 192788160

commit c89ab82a82585cdaa90bf4911980e9e845909e78
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 9 10:38:58 2018 -0700

    Add validation for output_index of Feed.id.
    Return error instead of crash if output_index is not less than the output number of the operation.
    
    PiperOrigin-RevId: 192148911

commit 19f7990d06b672e9a8f5085b42bb6822e4877a8b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 2 16:45:16 2018 -0700

    Add a config option to run Grappler optimizers more than once.
    Don't crash in layout optimizer if no cluster is given.
    Clean up Cluster::DisableOptimizer() so it actually turns all current optimizers off.
    
    PiperOrigin-RevId: 191368433

commit ddbb2c52db5cfab02b80b2ef563d8d6251dcfe77
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Mar 30 08:23:30 2018 -0700

    Fix a crash in Quantize() when tf.contrib.framework.get_name_scope() == None.
    
    PiperOrigin-RevId: 191068059

commit 28b95b35482d665a9483803ae9fb7b081b4f8a75
Author: Rui Zhao <rzhao@google.com>
Date:   Thu Mar 29 19:02:29 2018 -0700

    Add output info into op_context otherwise the estimator crashes when OOM.
    
    PiperOrigin-RevId: 191021184

commit 4979e1d55783d05520fda56fd89641f817daf119
Author: Max Galkin <maxgalkin@google.com>
Date:   Tue Mar 27 18:06:30 2018 -0700

    Disable new Gather/Slice estimators for now to fix the crashes during some TF graphs optimizations.
    
    PiperOrigin-RevId: 190705686

commit b761b841c4e4880c17bb37148e9f74bc9c05f626
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Mar 23 13:15:26 2018 -0700

    * Added links to Machine Learning Crash Course.
    * Removed a link to the script that diagnosed Windows installation errors
      because that script is now deprecated.
    
    PiperOrigin-RevId: 190264199

commit c7334fef9d1173525f6111b8ab50360b6531d76b
Author: Brennan Saeta <saeta@google.com>
Date:   Wed Mar 21 18:02:01 2018 -0700

    [tf.data] Do not crash when combining .cache().take().repeat()
    
    Currently, if the .cache() iterator is not fully consumed before
    being repeated, it will cause an exception to be raised to Python.
    Instead, cache should act as an identity transformation and log
    an error, as this will not affect the correctness of the user's
    program (at the cost of an unexpected performance cost: i.e. not
    actually caching).
    
    PiperOrigin-RevId: 189999552

commit d7cb36a6876e02540c13f31f468a84f54c8591d4
Author: Justin Lebar <jlebar@google.com>
Date:   Wed Mar 21 10:47:18 2018 -0700

    [XLA:GPU] Don't crash if a GTE feeds into a bitcast.
    
    GTE and bitcast are sort of "implicitly fused", so we have to handle
    them in this way.
    
    PiperOrigin-RevId: 189931422

commit c4a50c5897170edf3055afcce25c981ee331de07
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Mar 1 16:06:22 2018 -0800

    Do not crash if we failed to get the field name.
    
    PiperOrigin-RevId: 187549153

commit 46306ad7bd02c613a59aa6074f830f0de011cfbf
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Feb 26 21:25:22 2018 -0800

    Improve error handling in strided_slice_op to fail more gracefully and return an error status instead of crashing.
    
    PiperOrigin-RevId: 187126888

commit 1f18f757042e678cc935f645e9e5c21208ddc9ac
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Feb 27 11:40:05 2018 -0800

    Don't crash on missing inputs in dependency analyzer. This is a temporary mitigation until the underlying bug is found.
    
    PiperOrigin-RevId: 187207594

commit b053b1006abdfcf1f790a729a412001ebbaf679f
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Feb 26 21:25:22 2018 -0800

    Improve error handling in strided_slice_op to fail more gracefully and return an error status instead of crashing.
    
    PiperOrigin-RevId: 187126888

commit 7575f334ee0879825ceed23928f5e99d0f71b5f8
Author: Justin Lebar <jlebar@google.com>
Date:   Tue Feb 13 17:16:29 2018 -0800

    [XLA:GPU] Don't crash when the root instruction of a computation is a multi-output fusion node, and avoid some pointer chasing with tuples.
    
    Previously, the kernels we generated would have one argument per
    *top-level* buffer of the input/output.  This was fine for inputs.  But
    it doesn't work for outputs: Imagine you're a node that returns a tuple
    -- e.g. multi-output fusion -- if all you get is a pointer to the
    top-level buffer of your output (which should contain pointers to the
    lower-level buffers at some point, but at the moment is just empty), how
    are you supposed to figure out where to write your output?
    
    (This usually worked because most of the time your output would live
    inside of the big XLA temp buffer, and kernels always get a pointer to
    that.)
    
    Now we pass all the buffers, top-level and otherwise, to our kernel.  In
    addition, we're now willing to dereference statically tuples that live
    entirely in XLA's temp buffer.  Pointers in input tuples must still be
    dereferenced dynamically, because the caller has the option of giving us
    these values or not when invoking XLA.
    
    This change makes some parts of BufferAssignment/BufferAllocations more
    truthful.  Previously, if you passed a tuple-shaped input to XLA, we'd
    say in BufferAllocations that the pointer for some subshape of the param
    was the *top-level tuple pointer*.  XLA then knew that this was a lie
    and would dereference it accordingly.  Now we have an explicit notion of
    a BufferAllocation pointing to a subshape of an input parameter.
    
    PiperOrigin-RevId: 185614060

commit eec85cb5e4eac9764a34debccac0e70d37519b3d
Author: Peter Hawkins <phawkins@google.com>
Date:   Mon Feb 12 22:45:49 2018 -0800

    [TF:XLA] Work around crash in Gather op on CPU backend by making loop bound a compile-time constant.
    
    PiperOrigin-RevId: 185486148

commit b47dcaf853f56f2709db06eb5aec83c545a5c87e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Feb 12 14:01:51 2018 -0800

    Return false instead of crashing in Tensor::SharesBufferWith if neither tensor has a buffer assigned yet, since that is a valid state. Returning
    
      buf_ != nullptr && b.buf_ != nullptr &&  buf_->root_buffer() == b.buf_->root_buffer();
    
    still satisfies the contract in the header, i.e. "True iff the two tensors use the same underlying refcounted storage."
    
    PiperOrigin-RevId: 185431574

commit 3d86d8ce14989ca65a59ad4cf37f690694bf6267
Author: Phil <ijund.phil@gmail.com>
Date:   Wed Feb 7 19:59:59 2018 +0100

    Add unsortedsegment(prod/min/max/sqrt_n/mean). (#15858)
    
    * Add unsortedsegment(prod/min/max/sqrt_n/mean).
    
    This commit adds CPU/GPU implementations for prod/min/max
    ops and python implementations for mean/sqrt_n. Also, it adapts and unifies the
    corresponding tests of all unsorted reductions.
    Note: The new gradient of unsorted_segment_max fixes the crash occuring when
    negative indices on CPU are used.
    
    * update golden API
    
    * Fix compilation of atomicAdd for cuda_arch < 600. \n This commit moves the std::complex specialization of atomicAdd below the double specialization of atomicAdd for cuda_arch 600.
    
    * Enable bfloat16, change inline to EIGEN_STRONG_INLINE.
    
    * fix includes of cuda_device_functions; fix typo

commit adaabc11680fa2823d029cf67214b23fa6652a4b
Author: Jie <jiej@nvidia.com>
Date:   Mon Feb 5 18:56:48 2018 -0800

    [DEBUG]
      multiple GPU crash with [cuda_illigal_memory_address]
        added cudaSetDevice before ICudaEngine::createExecutionContext()
    
      To make sure TRT engine gets allocated on the same GPU (to access IO memory)

commit 395550bc423f6a5d9c96233f34f21fce6bd23b4e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Feb 5 15:30:54 2018 -0800

    Assign total_loss in order not to crash if training loop exists early.
    
    PiperOrigin-RevId: 184596877

commit ab06a9c865abe58b882ea76a3bf008799c4c0ea4
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Feb 5 01:03:32 2018 -0800

    Fixed sequence_mask behavior on unknown shape.
    
    `sequence_mask` crashed when fed with a tensor of unknown rank.
    Added a test for that, and expanded a bit existing tests.
    
    Also fixed pre-existing lint errors.
    
    PiperOrigin-RevId: 184493239

commit c48431588e7cf8aff61d4c299231e3e925144df8
Author: David G. Andersen <dga@google.com>
Date:   Tue Jan 30 12:06:40 2018 -0800

    Eliminate crash on a 'no error' return from DecodeGif when parsing an invalid
    gif.  (Previous code tried to strcat a null).
    
    PiperOrigin-RevId: 183870288

commit 4078ecd4e107cb61da8e4a3ce0293bbb8d9dbb62
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Fri Jan 26 10:11:50 2018 -0800

    Improve profiler error message when graph_path is not available. (#16463)
    
    This fix tries to address the issue raised in 16451 to provide
    a better error message when graph_path is not available for profiler.
    
    Previously if graph_path is not available, the process will crash
    with not very imformative message and a core dump:
    ```
    2018-01-26 01:43:29.458032: F tensorflow/core/profiler/profiler.cc:206] Non-OK-status: ReadProtoFile(Env::Default(), FLAGS_graph_path, graph.get(), false) status: Not found: ; No such file or directory
    Aborted (core dumped)
    ```
    
    With this fix, the error message is improved to:
    ```
    Failed to read graph_path: Invalid argument: Cannot parse proto file.
    ```
    and the process exit with 1.
    
    This fix fixes 16451.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 02c2214b8da916a4a9e9eb3fde2711e49e7b4703
Author: Justin Lebar <jlebar@google.com>
Date:   Wed Jan 24 12:12:02 2018 -0800

    [XLA] Fix crash in HloOrdering::ToString().
    
    HloOrdering::ToString() was crashing when given a computation containing
    a fusion instruction.
    PiperOrigin-RevId: 183121645

commit 07e6ca0ac7cdfcb6105fb3410fc68355c04df1d5
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Tue Jan 23 13:12:40 2018 -0800

    Fix crash on GPU (out of GPU memory) for `softmax_cross_entropy_with_logits` (#16051)
    
    * Fix crash on GPU (out of GPU memory) for `softmax_cross_entropy_with_logits`
    
    This fix tries to address the issue raised in 6766 where
    `softmax_cross_entropy_with_logits` will trigger the crash on GPU (out of GPU memory)
    if the first dimension is 0.
    
    This fix fixes 6766.

commit 9e2846a611f0cad4423151f486cd30659976fb9d
Merge: 9b7b8813961 6e56e195d29
Author: Fred <fredbertsch@users.noreply.github.com>
Date:   Tue Jan 23 10:36:34 2018 -0800

    Merge pull request #16105 from yongtang/16101-decode_video-crash
    
    Fix crash in `tf.contrib.ffmpeg.decode_video`

commit f52fc39c31b03cecc97cf64f732b44c6f95a2bef
Author: Steven Hickson <me@stevenhickson.com>
Date:   Tue Jan 23 13:28:27 2018 -0500

    Update download_dependencies.sh to prevent crash from 403 (#16084)
    
    * Update download_dependencies.sh for eigen
    
    The eigen bitbucket seems to have changed causing the scrip to crash with a unrecognized archive error.
    Changing to grep -v mirror.bazel seems to fix this because otherwise we get a 403 forbidden error.
    
    * Update download_dependencies.sh

commit 6e56e195d29f33c42b4b58f83c508544e2bb59a7
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Sat Jan 13 19:48:57 2018 +0000

    Fix crash in `tf.contrib.ffmpeg.decode_video`
    
    This fix fixes the crash in `tf.contrib.ffmpeg.decode_video`.
    The reason for the crash was that, `decode_video` dumps
    the information about streaming etc. (as opposed to dump
    to stderr) info a file and read from it. As the loglevel
    was `error` the file was empty.
    
    This fix addresses the issue.
    
    The fix could be verifed by manually running
    ```
    bazel test -s --config=opt --cache_test_results=no //tensorflow/contrib/ffmpeg:decode_video_op_test
    ```
    
    With this fix, the above test works.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 4b7d9fec149b3bd96e3eea72c0c3475b293feeb0
Author: Justin Lebar <jlebar@google.com>
Date:   Tue Jan 9 10:06:58 2018 -0800

    [XLA] Run the LLVM verifier after lowering HLO -> LLVM IR.
    
    This way if we generate bad IR, we emit a nice error message, instead of
    (probably) crashing somewhere in LLVM.
    
    PiperOrigin-RevId: 181334588

commit 41ceb56c7f8e54dc6a11c0349c112404bdb3db54
Author: Skye Wanderman-Milne <skyewm@google.com>
Date:   Wed Jan 3 15:40:03 2018 -0800

    Run C++ control flow validation on FunctionDefs before running.
    
    Clients should ideally prevent such functions from being created in
    the first place, but we still want the runtime to be robust to
    malformed functions. Trying to run functions with invalid control flow
    constructs can result in crashes or hangs, so we want to catch it
    before running.
    
    PiperOrigin-RevId: 180727589

commit 711b10c280534c0ab73351bb4fd3e7ec32585236
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Dec 28 12:03:59 2017 -0800

    [XLA] Fix hlo_graph_dumper: don't crash if the computation has a constant root instruction.
    
    PiperOrigin-RevId: 180285687

commit 29c74939eed478690410150292f511c70f359ff1
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Dec 19 12:38:19 2017 -0800

    Protect all calls to launch cuSolver & cuBlas kernels by a lock. The code appears not to be threadsafe pre Cuda 9, and we have several report of crashes. Since the overhead is modest, better to be safe.
    
    PiperOrigin-RevId: 179589983

commit a37d4ae2e63648f0225b1a514b50642101c3161b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Dec 19 12:38:19 2017 -0800

    Protect all calls to launch cuSolver & cuBlas kernels by a lock. The code appears not to be threadsafe pre Cuda 9, and we have several report of crashes. Since the overhead is modest, better to be safe.
    
    PiperOrigin-RevId: 179589983

commit 1203dc0832133250de970ce10833ba43b71daf7b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Dec 18 19:07:23 2017 -0800

    [XLA] Hlo parser: don't crash if no computation is specified as ENTRY. Also disallow multiple entry computations and multiple root intructions.
    
    PiperOrigin-RevId: 179498839

commit 228b3ebc91ff351befcef641d01d1a82d532a6d1
Author: Justin Lebar <jlebar@google.com>
Date:   Mon Dec 11 21:38:05 2017 -0800

    [XLA] Don't call timer->Nanoseconds() on a not-ok stream.
    
    If the stream is not OK, the timer might not have been initialized and
    finalized, in which case calling timer->Nanoseconds() is illegal and
    will crash.
    
    PiperOrigin-RevId: 178717089

commit 6ebb6d6465ddf2380430de7aa287676e9440df7e
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Nov 30 14:14:29 2017 -0800

    TF server should not crash when -v=1 is enabled.
    
    These WriteTextProto() calls are purely for diagnostics (and are usually called within IF_VLOG_IS_ON(1) guards), but if they fail to write to a file, they'll take down the entire calling process.  Which makes debugging difficult, and seems rather astonishing.
    
    PiperOrigin-RevId: 177506379

commit 4cc4d5329122f0f97c3804e6f8d27ed4b5874028
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Thu Nov 30 11:14:36 2017 -0800

    Fix decode_bmp crash by adding length check before reading the data in buffer (#14967)
    
    * Fix decode_bmp crash by adding length check before reading the data in buffer
    
    This fix tries to address the issue raised in 14959 where
    the bmp content length was not checked before reading the buffer.
    As a result, decode_bmp might trigger a crash if the content of bmp
    is incomplete.
    
    This fix fixes the issue by adding the needed check before
    reading the data.
    
    This fix fixes 14959.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Sanitize decode_bmp_op.cc with clang-format -i --style=Google
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add additional check to make sure header is safe to access in bmp
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Not require padding (as paddings are not accessed)
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Remove duplicated row_size calculation.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for decoding incomplete bmp
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 459153ab91ede37a3175a4dee5aa3f38690d3ebb
Author: Artem Belevich <tra@google.com>
Date:   Wed Nov 15 14:36:49 2017 -0800

    Improve ptxas-related error handling.
    
    * Don't crash on cubin file cleanup as the file may not have been created.
    * Log only one error message if ptxas is not found.
    
    PiperOrigin-RevId: 175882482

commit 25bd6f7a6717f5253b6f015bfab93c7e12426397
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Tue Nov 7 12:42:15 2017 -0800

    Allow tfcompile_flags to be a list (#12769)
    
    * Allow tfcompile_flags to be a list
    
    This fix tries to fix the issue raised in 12767 where
    it was not possible to specify tfcompile_flags as a list:
    ```
    tf_library(
      ...
      tfcompile_flags = ["--target_cpu='core-avx2'", "--xla_enable_fast_math=false"]
    )
    ```
    will crash upon build with '+' operator applied to incompatible types (select of string, list)
    
    This is inconsistent with other rules like 'copts' in cc_binary.
    
    The issue is from tfcompile.bzl:
    ```
    " " + (tfcompile_flags or "")),
    ```
    
    This fix uses `" ".join(tfcompile_flags or [])` instead so that it
    is possible to specify the list.
    
    This fix fixes 12767.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add support of string for tfcompile_flags
    
    so that backward compatibility could be maintained.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit 88917888f509e3e61ffe632534476e7b09d3326a
Author: Andrew Harp <andrewharp@google.com>
Date:   Thu Nov 2 15:22:08 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit d77b99809 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by gunan<gunan@google.com>:
    Update docs for `begin_params_axis` (#13979)
    
    This fix fixes the issue raised in 13975 where `begin_shift_axis`
    is actually `begin_params_axis`.
    
    This fix fixes 13975.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    ---
    Commit e6a242b4e authored by Yifei Feng<fengyifei2026@gmail.com>
    Committed by gunan<gunan@google.com>:
    Add GCC/Compiler version to issue template. (#14113)
    
    As suggested in #13930
    ---
    Commit 7ece1c0b8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Moving model_pruning library to tf.contrib
    
    PiperOrigin-RevId: 174214419
    
    ---
    Commit 693325c83 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Log the full traceback in Coordinator.request_stop if it's available
    
    PiperOrigin-RevId: 174213375
    
    ---
    Commit 6c4a769ab authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete duplicate label_image script.
    
    The version in examples/label_image is more complete (with image size and normalization options), so it can be used with `mobilenets`.
    
    Also: removed bazel from main tutorial instructions.
    PiperOrigin-RevId: 174212674
    
    ---
    Commit 7a5b81c29 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Materialize shape for ShapeN.
    
    PiperOrigin-RevId: 174211500
    
    ---
    Commit 78041b1dd authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change
    
    PiperOrigin-RevId: 174211190
    
    ---
    Commit 2118fcf62 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BUILD cleanup in contrib/tensor_forest/...
    
    PiperOrigin-RevId: 174201884
    
    ---
    Commit 6849ef8f6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change.
    
    PiperOrigin-RevId: 174197506
    
    ---
    Commit 37370d98f authored by resec<resec0109@gmail.com>
    Committed by gunan<gunan@google.com>:
    Support more Android arch in Makefile build (#12806)
    
    * Support more Android arch in Makefile build
    
    * update Makefile
    
    * fix MARCH_OPTION
    
    * persist multiple architectures across builds
    
    * persist multiple architectures across builds
    
    * persist multiple architectures across builds
    
    * persistence bug fix
    
    * persistence bug fix
    
    * persistence bug fix
    
    * add -latomic to linker flags for benchmark
    
    * Change ANDROID_OS_ARCH to ANDROID_HOST_OS_ARCH
    
    ---
    Commit c40d54173 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Exposes recall_at_top_k under tf.metrics.
    
    PiperOrigin-RevId: 174189641
    
    ---
    Commit 18bf5b2d9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Return a classifier score of the same type as the logits.
    
    PiperOrigin-RevId: 174184871
    
    ---
    Commit 9da02be11 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make 'collections' a list, as documented and expected by downstream custom getters.
    
    PiperOrigin-RevId: 174184867
    
    ---
    Commit 16b0bb095 authored by loki der quaeler<quaeler@users.noreply.github.com>
    Committed by gunan<gunan@google.com>:
    Adding a feed for boolean tensors to TensorFlowInferenceInterface (#14059)
    
    * Sublime Text index-ignore file (a copy of .gitignore)
    
    * Adding the requested implementation to TensorFlowInferenceInterface
    
    * Removing Sublime Text .ignore file from remote repository
    
    * indeed there was
    
    ---
    Commit fa9d8aab4 authored by Urs K?ster<ursk@users.noreply.github.com>
    Committed by gunan<gunan@google.com>:
    Add  'log_progress' argument for tf.estimator.Estimator's evaluate function (#13695)
    
    * Add  argument for tf.estimator.Estimator's evaluate function
    
    * add log_progress argument to ._convert_eval_steps_to_hooks for TPU estimator
    
    * log only every 10th step if more than 100 iterations in _StopAfterNEvalsHook
    
    * ensure last step is logged and aim for 10 outputs total
    
    ---
    Commit 07a91dac5 authored by nolan liu<nolan.liou@gmail.com>
    Committed by gunan<gunan@google.com>:
    make `gather` cpu kernel to be multiple threads. (#12246)
    
    * Change the gather op to multi-thread.
    
    * Modify the gather kernel of xla compiler in order to be compatible with multi-threads cpu kernel.
    
    * Add prefetch logic to gather op kernel.
    
    * Update the indention of gather op kernel code.
    
    * Update the gather kernel code for multiple thread.
    
    * Remove reference to ealier version of code in gather functor.
    
    * Change the framework_lite dep of gather_functor to framework.
    
    * Remove mutex guard in gather functor.
    
    ---
    Commit a956486be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove an erronous __attribute__((...)) tag.
    
    There is no __attribute__((guarded)) or __attribute__((pt_guarded)) attribute in Clang, and if we turn on warnings for unknown attributes (which are currently turned off), this causes build failures.  This means that, when the warnings are turned off, this is simply a no-op.
    
    PiperOrigin-RevId: 174134252
    
    ---
    Commit 27412f3b6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add compiler/tf2xla/sharding_util.h with utilities for getting the core device from
    a Node.
    
    PiperOrigin-RevId: 174133602
    
    ---
    Commit ab4349a26 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BUILD cleanup in selected packages in contrib/...
    
    PiperOrigin-RevId: 174115744
    
    ---
    Commit 4aa90bfd3 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add HLO matchers that check parameter numbers and GTE indices.
    
    This lets you do
    
      EXPECT_THAT(foo, op::Parameter(42));
    
    and
    
      EXPECT_THAT(bar, op::GetTupleElement(baz, 8));
    
    PiperOrigin-RevId: 174113597
    
    ---
    Commit f97e7c69b authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    partially exposing the _set_attr and _get_attr method in python
    
    PiperOrigin-RevId: 174113043
    
    ---
    Commit 8e732a312 authored by Artem Belevich<tra@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Prefer cubin over PTX when we launch CUDA kernels.
    
    Native GPU code, if we have it, should be preferred over JIT compilation of PTX.
    
    PiperOrigin-RevId: 174110646
    
    ---
    Commit 2ccf3aba4 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Permanently remove several modules from tf.contrib.bayesflow.
    
    These modules are very infrequently used and will not be developed moving forward.
    Removing this code paves the way for remaining modules in tf.contrib.bayesflow
    to move to their own repo.
    
    PiperOrigin-RevId: 174110067
    
    ---
    Commit ef7052fbd authored by Andrew Selle<aselle@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Open source build support for TensorFlow Lite Toco.
    
    - Handle proto incompatibilities
    - Mixed bazel compatibility fixes.
    - Add link to absl libraries
    
    PiperOrigin-RevId: 174103981
    
    ---
    Commit d6a9cd40c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix "hides overloaded virtual function" error in default/gpu_tracer.cc when compiled with -Werror,-Woverloaded-virtual.
    
    PiperOrigin-RevId: 174101519
    
    ---
    Commit b242a7988 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set metric variable initializers as lambda.
    
    PiperOrigin-RevId: 174100686
    
    ---
    Commit 57b1c5621 authored by Alan Yee<alyee@ucsd.edu>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Add deprecation notes (#12614)
    
    * Update lookup_ops.py
    
    Minor comment fix
    
    * Update metrics_ops.py
    
    Add deprecated notes
    
    * Update tensor_util.py
    
    Update deprecated note on remove_squeezable_dimensions
    
    * Update metric_ops.py
    
    Add deprecated notes
    
    ---
    Commit 453dd5848 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Support for tf.AUTO_REUSE when re-using registrations. Multi-tower support for FullFB, NaiveDiagonalFB. Removal of LayerCollection.generic_registrations.
    
    PiperOrigin-RevId: 174092003
    
    ---
    Commit 0a7be5a2f authored by Sanjoy Das<sanjoy@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Rename (Add|Get)ProfileResult to something more specific; NFC
    
    PiperOrigin-RevId: 174084570
    
    ---
    Commit f1916f8f6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    - Remove slice hack to properly initialize missing entries in weight matrices
      - Add real support for EmbeddingColumns / input_layer()
    - Fix warmstarting for non-PartitionedVariables
    
    PiperOrigin-RevId: 174083777
    
    ---
    Commit f567ddf87 authored by Alex Sergeev<alexander.sergeev@live.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Add tf.sysconfig.get_compile_flags() & tf.sysconfig.get_link_flags() for custom operators (#13496)
    
    * Add flags for custom op compilation
    
    * Move ABI logic into version_info.cc
    
    * Add #include <string> to be able to read _GLIBCXX_USE_CXX11_ABI value.
    
    * Make flags to be lists
    
    * Add _flag to cxx11_abi
    
    * Address review comment.
    
    * Move CXX import to the top level.
    
    * Add goldens update
    
    ---
    Commit 0cddb9bca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 174074499
    
    ---
    Commit ba8c38959 authored by Neal Wu<wun@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change wide_deep.md and wide.md to reference the TensorFlow official models version rather than the tf.contrib.learn version
    
    PiperOrigin-RevId: 174074112
    
    ---
    Commit f3006422c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make `RunTrainOpsHook` public.
    
    PiperOrigin-RevId: 174073925
    
    ---
    Commit 21dafd6d2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 174073569
    
    ---
    Commit 66fc99a3b authored by Artem Belevich<tra@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:GPU] Short-circuit compilation of no-op IR -> empty PTX.
    
    There's no point constructing/running LLVM pipeline if we know that we have no
    kernels in the IR we've generated for the given HLO op. This is often the case
    for ops we can optimize away at the HLO level.
    
    PiperOrigin-RevId: 174072540
    
    ---
    Commit c911d0f16 authored by Dhananjay Nakrani<dhananjayn@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch over python calls to RandomPoissonV2.
    
    Part 2 of Support int32/64 in tf.random_poisson().
    
    PiperOrigin-RevId: 174071745
    
    ---
    Commit b5d5326c6 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:GPU] Fix race condition in gpu_compiler.cc.
    
    We were racing on libdevice_dir_.
    
    PiperOrigin-RevId: 174070334
    
    ---
    Commit 35939d2d3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Fix string to HLO opcode conversion for atan2, complex, imag and real.
    
    Make sure that we can't forget opcodes by auto-generating the conversion
    functions.
    
    Add auto-generated functions to test HLOs for properties (like IsVariadic,
    IsComparison, etc.)
    
    This makes changing HLO more robust and easier because there are fewer places
    to update when adding or removing an HLO opcode.
    
    Also:
    * Fix IsElementwiseBinary for atan2.
    * Add a unit test for HLO opcode helpers.
    * Express IsElementwiseBinary in terms of IsElementwise() and operand_count()
      to avoid having to keep the two in sync manually.
    PiperOrigin-RevId: 174069664
    
    ---
    Commit 3b845c80d authored by Allen Lavoie<allenl@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Disable resnet50_graph_test under TSAN due to timeouts.
    
    PiperOrigin-RevId: 174066937
    
    ---
    Commit 8a09bbc4a authored by Igor Ganichev<iga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add TFE_Py_TensorShapeSlice function
    
    TFE_Py_TensorShapeSlice takes a list of EagerTensors and returns a list
    of their i'th dimensions. This utility is fairly niche but it is simple
    and reduces SPINN training time by over 12%.
    
    PiperOrigin-RevId: 174065044
    
    ---
    Commit 585432cc2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor ArgMin / ArgMax index ops as XlaHelpers.
    
    PiperOrigin-RevId: 174061370
    
    ---
    Commit e6faa845c authored by Michael Case<mikecase@chromium.org>
    Committed by gunan<gunan@google.com>:
    Merge v1.4-rc1 back into master branch. (#13960)
    
    * Update RELEASE NOTES for TensorFlow 1.4
    
    * Update the version strings for TF 1.4-rc0.
    
    * Update version strings in POM files missed by update script.
    
    * Pin TensorBoard 0.4 to TensorFlow 1.4
    
    * Fixing the name of the disabled test. (#13592)
    
    * Revert "Implementing ghost batch norm as defined in https://arxiv.org/pdf/1705.08741."
    
    This reverts commit 125f7afa4a483855dc75791445d2dea64587876a.
    
    * Disable iterator_ops_test on Windows for 1.4 release (#13609)
    
    * Disable failing Windows tests for r1.4 release.
    
    testRemoteIteratorUsingRemoteCallOpDirectSessionGPUCPU test is failing
    with "TypeError: only integer scalar arrays can be converted to a scalar
    index" on the Windows GPU Release bot. Disabling test.
    
    * Fix typo.
    
    * Also disalbe iterator_ops_test from contrib/.
    
    * Add contributing authors to 1.4 Release notes.
    
    Thanks!
    
    * Fixes to authors.
    
    Removed duplicate and removed googler from contributing author list.
    
    * Fixes and additions to release notes.
    
    Added line about Keras moving into core.
    Added line about CUDA/cuDNN versions.
    Added line about custom ops.
    
    * Fixing a master regression (#13562)
    
    * Update version strings for 1.4.0rc1
    
    * Remaining cherry-picks for 1.4.0rc1 (#13700)
    
    * Java: Tweak to address some Javadoc errors.
    
    PiperOrigin-RevId: 171987329
    
    * Fix S3 BUILD not including files explicitly.
    
    This causes remote builds to fail since they AWS headers were missing.
    
    PiperOrigin-RevId: 171718021
    
    * Add missing default config setting in aws.BUILD (#13662)
    
    * Remove setting AWS logging for S3 file system.
    
    Was causing issues with tests. Can repro test failures on Macs by running...
    
    bazel test --config=s3  --cache_test_results=no --test_output=streamed
    //tensorflow/core/kernels:control_flow_ops_test
    
    Possible reason for error is symbol collision with AWS logging code.
    One possible solution would be to split out another shared object for
    the S3 filesystem op which does not link in libtensorflow_framework.so.
    This is done, for example, by libforestprotos.so in
    tensorflow/contrib/tensor_forest/BUILD
    
    PiperOrigin-RevId: 171246381
    
    * Relanding change to add config to enable S3 file system support.
    
    Pass --config=s3 argument to Bazel to build with S3 file system support.
    Change was originally rolled back due to a failure it caused in
    //tensorflow/core/kernels:control_flow_ops_test on Macs which is now fixed.
    
    PiperOrigin-RevId: 171579378
    
    * Update release notes about Amazon S3 file system support being default.
    
    * Add documentation to sloppy_interleave function
    
    PiperOrigin-RevId: 171303413
    
    * Add `cudnn_rnn_ops` to the Windows build
    
    Fixes #13696.
    
    * Creating a patch for the wrong links that still point to dev. (#13753)
    
    * tfdbg release notes in r1.4
    
    * Fix ambiguous type comparison in s3_crypto.cc (#13758)
    
    tensorflow/contrib/s3/s3_crypto.cc(74): error C2666:
    'std::fpos<_Mbstatet>::operator ==': 3 overloads have similar conversions
    could be 'bool std::fpos<_Mbstatet>::operator ==(std::streamoff) const'
    or 'bool std::fpos<_Mbstatet>::operator ==(const std::fpos<_Mbstatet> &)
    We were seeing this compilation error on Windows builds.
    
    * Set estimator run_config default random seed to None. This will make it aligned with other parts of the TF. Many users are not aware of impact of non-random seed. For example it may lead to train only on a small fraction of training data due to preemptions.
    We're changing default behavior since we consider it as a bug fix.
    
    PiperOrigin-RevId: 172519268
    
    * Move global_step_read dependency to model_fn instead of input_fn.
    
    PiperOrigin-RevId: 172366972
    
    * [tf.data] Fix broken implementation of `Dataset.from_generator()` on Windows.
    
    Due to a mix-up between NumPy's default array element type for a Python `int` on Windows and Linux, a tf.py_func() in `Dataset.from_generator()` would appear to return the wrong type on Windows (np.int32 instead of np.int64).
    
    All code using `Dataset.from_generator()` on Windows was previously broken. This change fixes both `tf.data.Dataset.from_generator()` and `tf.contrib.data.Dataset.from_generator()`. It also enables test coverage for this method on Windows, which should prevent future breakage.
    
    PiperOrigin-RevId: 172346533
    
    * Update RELEASE notes for change to run_config random seed.
    
    * Disable probable timeout flake on Ubuntu machines.
    
    PiperOrigin-RevId: 172408922
    
    * Disabling failing contrib tests.
    
    * Disable S3 on Windows due to build issues.
    
    * Update serving_input_fn argument name to serving_input_receiver_fn
    
    PiperOrigin-RevId: 172787460
    
    * Update the C++ API guide (#13858)
    
    - Adds the standard warning at the top that people may want the master branch
    - Includes a documentation fix for 1.4 (cc_binary -> tf_cc_binary to avoid
      undefined symbols).
    
    * Add known Dataset issue to RELEASE.md. (#13870)
    
    Adding info about issue using Unicode strings with Datasets.
    
    * Fixes to merge.
    
    * Fix spelling of tensorflow in install_sources.md
    
    ---
    Commit 6eac524ef authored by cglewis<clewis@iqt.org>
    Committed by cglewis<clewis@iqt.org>:
    Use 'LABEL maintainer=' in Dockerfile
    
    * Use 'LABEL maintainer=' in Dockerfile
    
    This fix is a follow up of 13961 to replace `MAINTAINER`
    with `LABEL maintainer=` in Dockerfile. The keyword
    `MAINTAINER` has long been deprecated and is replaced by `LABEL`,
    which is much more flexible and is easily searchable through `docker
    inspect`.
    
    This fix replaces remaining `MAINTAINER` with `LABEL`.
    
    Signed-off-by: Charlie Lewis <clewis@iqt.org>
    
    * Additional `MAITAINER` -> `LABEL`
    
    Signed-off-by: Charlie Lewis <clewis@iqt.org>
    
    ---
    Commit 469970260 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Modify quantization to support add ops that occur after Conv2D
    
    PiperOrigin-RevId: 174058697
    
    ---
    Commit 938643b56 authored by Amit Patankar<amitpatankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Replace the docker check with an OS check.
    
    PiperOrigin-RevId: 174057778
    
    ---
    Commit 5f1a66ccb authored by Igor Saprykin<isaprykin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add more recovery functionality to MonitoredSession.run_step_fn.
    
    Current implemention wouldn't recover from one of `_PREEMPTION_ERRORS` during a fetch through the raw session that is made available to the step_fn.
    
    The changelist presents a way to map the desired functionality to the hiearchy of _MonitoredSession > (possibly!) _RecoverableSession > _CoordinatedSession > _HookedSession.
    
    PiperOrigin-RevId: 174053865
    
    ---
    Commit 9a2b0983a authored by Yifei Feng<fengyifei2026@gmail.com>
    Committed by gunan<gunan@google.com>:
    Add apt-key for ubuntu keyserver (#14114)
    
    ---
    Commit 479ee24a0 authored by Asim Shankar<asimshankar@gmail.com>
    Committed by gunan<gunan@google.com>:
    eager: Update broken link in README (#14136)
    
    ---
    Commit ad7bb2b9e authored by Asim Shankar<asimshankar@gmail.com>
    Committed by gunan<gunan@google.com>:
    eager: Update broken links in guide.md (#14135)
    
    ---
    Commit c37ebf0d5 authored by Thomas Deegan<tadeegan@gmail.com>
    Committed by gunan<gunan@google.com>:
    Resolve //tensorflow relative to tensorflow repo so that tfcompile.bzl can be correctly loaded from another Bazel project (#14103)
    
    ---
    Commit b2ff3ad96 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added GraphKeys.METRIC_VARIABLE collection. Added all variables under tf.metrics and tf.contrib.metrics into this collection. This will enable replication of model for evaluation. When we replicate a metric in multiple towers (let's say for each qpu we replicate same model/metric), we cannot reduce the output of metrics. On the other hand internal state (local-variables) of those metrics can reducible via sum.
    
    PiperOrigin-RevId: 174051559
    
    ---
    Commit 98dad195d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds sigmoid to the list of operations that can be recomputed.
    
    PiperOrigin-RevId: 174047825
    
    ---
    Commit 123749fb1 authored by Yuan (Terry) Tang<terrytangyuan@users.noreply.github.com>
    Committed by Martin Wicke<martin.wicke@gmail.com>:
    Remove Scikit Flow link and description (#14036)
    
    ---
    Commit 0d118e4dc authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implemented tensorflow::port::NominalCPUFrequency()
    
    PiperOrigin-RevId: 174041196
    
    ---
    Commit 648993e82 authored by Andrew Harp<andrew.harp@gmail.com>
    Committed by Andrew Harp<andrew.harp@gmail.com>:
    delete extraneous file
    
    ---
    Commit c2ff8a5ab authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete backticks
    
    PiperOrigin-RevId: 174030921
    
    ---
    Commit 333ba224d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Dependency information for Skylark macros
    
    PiperOrigin-RevId: 174023371
    
    ---
    Commit 9ee0cecec authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Shrink the model size for unit test.
    
    PiperOrigin-RevId: 174001263
    
    ---
    Commit c44f67a7e authored by Yifei Feng<fengyifei2026@gmail.com>
    Committed by gunan<gunan@google.com>:
    Disable clang_format check. (#14115)
    
    Different clang_format version can cause different formats with the same style option. This check might be too strict. Disable for now.
    ---
    Commit a6a618843 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Documentation and example models.
    
    - Updated README
    - A preliminary "User's Guide"
    - A few example models, some with benchmarks
    
    PiperOrigin-RevId: 173996303
    
    ---
    Commit de38e5dff authored by ???<dev@goodow.com>
    Committed by GitHub<noreply@github.com>:
    fix broken link
    ---
    Commit cd81bc8e0 authored by Rohan Jain<rohanj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds a PrefetchWithFn op to contrib/data. Alongwith the FunctionBufferingResource, this can be used to prefetch and fill up a buffer by making repeated function calls.
    
    Also fixes a TODO in the ProcessFLR implementation to respect alloc_attrs for Rendezvous calls.
    
    PiperOrigin-RevId: 173990680
    
    ---
    Commit 17695212c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Don't pass HLO operands in HandleAtan2.
    
    This makes it consistent with the rest of the Visit methods where we only
    pass the HLO itself.
    
    PiperOrigin-RevId: 173990595
    
    ---
    Commit 113be5746 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    A few profiler improvements
    1. Track the full allocation history of each tensor, visualized in timeline.
    2. Better ProfileContext for tracing step selection.
    3. Small bug fix.
    
    PiperOrigin-RevId: 173988293
    
    ---
    Commit 6d1263cdf authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Remove dead opcode kIndex.
    
    PiperOrigin-RevId: 173987428
    
    ---
    Commit a4b5356e4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Reduce boilerplate code in HLO visitors.
    
    Only pass the HloInstruction into visitor methods. This makes changing
    instructions and visitors easier.
    
    PiperOrigin-RevId: 173983398
    
    ---
    Commit d9cee35b6 authored by LevineHuang<levinehuang@163.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    Typo fix in file 'fully_connected_feed.py' (#14033)
    
    * Typo fix in file 'fully_connected_feed.py'
    
    * Minor edits to coding style
    
    ---
    Commit bb7ed1c88 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Multi-tower ConvNet example.
    
    PiperOrigin-RevId: 173982527
    
    ---
    Commit 2ba529856 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Initial add of docs for Tensorflow on Mobile.
    
    PiperOrigin-RevId: 173980290
    
    ---
    Commit 187453d61 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change momentum optimizer to allow callable learning_rate and momentum
    parameters. This can be useful for implementing learninge rate decay.
    
    PiperOrigin-RevId: 173975321
    
    ---
    Commit 542b323e5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Register quint16/qint16 for GatherOp.
    
    PiperOrigin-RevId: 173974904
    
    ---
    Commit 309e34061 authored by Allen Lavoie<allenl@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid uncollectable cycles with a separate deleter object for resources.
    
    PiperOrigin-RevId: 173972515
    
    ---
    Commit 73fdaf0b5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Summary-writing support for Evaluators.
    
    PiperOrigin-RevId: 173971621
    
    ---
    Commit 72be26dc8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.data] Iterator Save and Restore for Dataset.from_tensors(..), Dataset.from_tensor_slices(..) and dataset.concatenate(..).
    
    PiperOrigin-RevId: 173971324
    
    ---
    Commit 09f62ab38 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Speeding up the case for sparse float columns that have only 1 value.
    
    PiperOrigin-RevId: 173971121
    
    ---
    Commit c315cf1ee authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal-only changes
    
    PiperOrigin-RevId: 173968246
    
    ---
    Commit 293ba20be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make learning_rate_decay.piecewise_constant work in Eager mode.
    
    PiperOrigin-RevId: 173967531
    
    ---
    Commit 0e6abfcda authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Example for multi-tower support for MNIST MLP.
    
    PiperOrigin-RevId: 173967370
    
    ---
    Commit b46c196e9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    * Add graph rewrite rule that removes repeated application of scalar unary ops that are involutions (their own inverse).
    * Update rewrite rule for Transpose to also handle ConjugateTranspose.
    
    PiperOrigin-RevId: 173967184
    
    ---
    Commit ff5c276ad authored by Stephan Hoyer<shoyer@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Longer README for tf.contrib.labeled_tensor
    
    PiperOrigin-RevId: 173966577
    
    ---
    Commit 558f146e1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 173966068
    
    ---
    Commit f9a673cb7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the overloaded HloVerifier::CheckShape, include the failing instruction in
    the error message.
    
    PiperOrigin-RevId: 173965368
    
    ---
    Commit 302ab0ff7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173965174
    
    ---
    Commit 89120eb68 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    scatter_update for resource variables
    
    PiperOrigin-RevId: 173963715
    
    ---
    Commit 8f7903b4c authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduce SQLite SummaryWriterInterface
    
    This change allows tensors to be written from the graph, as they flow, directly
    to the database. Many of the important details haven't been implemented yet.
    
    This has been done with the new summary interface that's going to be used with
    eager.
    
    PiperOrigin-RevId: 173961448
    
    ---
    Commit 9aaa49a4e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid using variables as booleans (similarly to tensors).
    
    PiperOrigin-RevId: 173956625
    
    ---
    Commit a60cd87c4 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    No need for unique variable names in eager.
    
    PiperOrigin-RevId: 173954805
    
    ---
    Commit f17f389d8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a workaround in the Grappler arithmetic optimizer for the "Add" op not being marked commutative. This will allow Grappler to dedup nodes Add(x,y) and Add(y,x).
    
    PiperOrigin-RevId: 173950586
    
    ---
    Commit e40eb810a authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Add errors for classic tf.summary.* ops and FileWriter
    
    PiperOrigin-RevId: 173949980
    
    ---
    Commit 25620825b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Dataset: Adds eager warnings to make_initializable_iterator and make_one_shot_iterator.
    
    PiperOrigin-RevId: 173949737
    
    ---
    Commit 1d6dae88e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add check to tf.device when called with a function in eager mode.
    
    PiperOrigin-RevId: 173947845
    
    ---
    Commit 3639aa7ff authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Always run iterator deleter in eager mode for safety.
    
    PiperOrigin-RevId: 173947019
    
    ---
    Commit efcbf6e34 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Supported in this CL:
      * Attaching sharding descriptors to HLO ops
      * Partitioning the HLO graph into per-device computations based on those sharding descriptors.
      * All operator support for device placement and ops replicated on all devices.
      * Elementwise op support for tiled shardings.
      * 2D Convolution support for tiled shardings (no stride or dilation support).
    
    PiperOrigin-RevId: 173946036
    
    ---
    Commit 682a6ed64 authored by Jon Shlens<shlens@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update the documentation for sample_distorted_bounding_box
    
    PiperOrigin-RevId: 173943029
    
    ---
    Commit 4f6e6ea4c authored by Sanjoy Das<sanjoy@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix typo in comment; NFC
    
    PiperOrigin-RevId: 173942305
    
    ---
    Commit 07584221f authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set visibility to HIDDEN for hidden Python ops in ApiDef.
    
    PiperOrigin-RevId: 173942001
    
    ---
    Commit 35cc8bb0a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Multiple minibatches support for LayerCollection.register_conv2d()
    
    PiperOrigin-RevId: 173941279
    
    ---
    Commit 32f3c3a43 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 173933228
    
    ---
    Commit 8cc7b47a4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173932574
    
    ---
    Commit b9337de5b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Multi-tower support for ConvKFCBasicFB
    
    PiperOrigin-RevId: 173932013
    
    ---
    Commit 1b6b7e208 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add registration for op AddV2, which is identical to Add, except that it does does not implement string concatenation. This allows us to mark AddV2 is_commutative and is_aggregate, which will allow optimizers more freedom.
    
    PiperOrigin-RevId: 173931848
    
    ---
    Commit 629e6d0c1 authored by Joshua V. Dillon<jvdillon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Bugfix: Make `tf.contrib.distributions.Independent` tests not flaky.
    
    PiperOrigin-RevId: 173921378
    
    ---
    Commit 4b63f47d9 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] Don't crash if someone tries to do dot(X, X) or dot(X, X^T).
    
    PiperOrigin-RevId: 173919310
    
    ---
    Commit 89582677c authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    EagerVariableStore, for compatibility with functional layers.
    
    PiperOrigin-RevId: 173915730
    
    ---
    Commit cef680b53 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enable shape inference on functions in grappler.
    
    PiperOrigin-RevId: 173914941
    
    ---
    Commit e8ac0b48f authored by Akshay Agrawal<akshayka@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Report a nicer error message when differentiating a function
    that returns None in eager
    
    PiperOrigin-RevId: 173914883
    
    ---
    Commit 85f8d9240 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tensorflow training input] If SparseTensors are used in batch* ops, ensure restoration.
    
    This forces the ST restore op to be called if any tensors are accessed at the output
    of the batch, thus fixing a memory leak.
    
    Solution suggested by Derek Murray.
    
    Fixes #13999.
    
    PiperOrigin-RevId: 173904309
    
    ---
    Commit 7fd261602 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add TF_GraphVersions() to C API and use in Graph.graph_def_versions()
    
    PiperOrigin-RevId: 173902666
    
    ---
    Commit 4723f8f6e authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support SymbolicGradient for functions with non-trainable arguments.
    
    The non-trainable arguments end up with None as their incoming out_grad, which is not a valid input to SymbolicGradient (inputs have to be convertible to Tensor, and None isn't).
    
    PiperOrigin-RevId: 173901727
    
    ---
    Commit 494672475 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added "NOTE: You may only install TensorFlow on 64-bit machines" to all the
    TensorFlow Install guides.
    
    PiperOrigin-RevId: 173899394
    
    ---
    Commit b73743e3a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove accidental disablation of (already manual) tests.
    
    PiperOrigin-RevId: 173898910
    
    ---
    Commit ce0238198 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add ability to fetch return nodes and unused input mappings from C API GraphDef import
    
    This change introduces yet another ImportGraphDef function to the C
    API (TF_GraphImportGraphDefWithResults), but this one has extensible
    return values so we shouldn't have to add more in the future.
    
    This change also modifies the ImportGraphDef C interface to manage all
    string data for the user.
    
    PiperOrigin-RevId: 173894710
    
    ---
    Commit ef4490f63 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BUILD cleanup in contrib/...
    
    PiperOrigin-RevId: 173889798
    
    ---
    Commit 2e54fd6de authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds eager execution compatibility note in Readers, Queues, and QueueRunner.
    
    Raises a RuntimeError in base classes for QueueBase, ReaderBase, and QueueRunner.
    
    PiperOrigin-RevId: 173888425
    
    ---
    Commit 32ab30cb0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes typo in compatibility.
    
    PiperOrigin-RevId: 173887031
    
    ---
    Commit 325c8e5ef authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Improve C++ SQLite veneer
    
    - Use shared_ptr for Sqlite
    - Don't need unique_ptr on SqliteStatement
    - Don't need db namespace
    - Include SQL in error statuses
    
    PiperOrigin-RevId: 173802267
    
    ---
    Commit 0eba15fe6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds eager compatability message for PartitionedVariable.
    
    PiperOrigin-RevId: 173772851
    
    ---
    Commit e7645b629 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] DOT dumper: Handle fusion nodes nested inside other nodes (e.g. map).
    
    PiperOrigin-RevId: 173752314
    
    ---
    Commit 8ec7540e0 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Fix pip test for tf.contrib.summary
    
    Fixes test failure in tensorflow/contrib/summary:summary_ops_test, e.g.,
    http://ci.tensorflow.org/job/tensorflow-cl-cpu-python3-pip/10933/console
    
    PiperOrigin-RevId: 173749502
    
    ---
    Commit c16797ec3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds eager execution compatibility note in Estimators.
    
    Raises a RuntimeError in Estimator base class.
    
    PiperOrigin-RevId: 173744765
    
    ---
    Commit e8a62a30b authored by ???<dev@goodow.com>
    Committed by GitHub<noreply@github.com>:
    Fix minor typo
    ---
    Commit 36696ad58 authored by ???<dev@goodow.com>
    Committed by Larry Tin<dev@goodow.com>:
    tf.zeros doesn't accept a tensor argument
    
    ValueError: Shape must be rank 1 but is rank 0 for 'zeros_2' (op: 'Fill') with input shapes: [], [].
    
    ---
    Commit 9f4b12bb5 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] DOT dumper: Print constant shape when we elide the constant's value.
    
    For example, instead of "operand 1 = %constant.42", we now print
    "operand 1 = %constant.42 (f32[100])".
    
    PiperOrigin-RevId: 173741373
    
    ---
    Commit 45c5118f0 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    When creating an HloModule from an HloProto construct the HloModuleConfig
    with a correct ProgramShape which matches the shapes of the entry computation.
    Previously the module config had a bogus or default constructed ProgramShape.
    
    PiperOrigin-RevId: 173741104
    
    ---
    Commit 09a89ae57 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add `tf.contrib.distributions.bijectors.Reshape`.
    
    PiperOrigin-RevId: 173740491
    
    ---
    Commit 729db035e authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allow compatibility notes in class, property and module doc-strings
    
    PiperOrigin-RevId: 173739674
    
    ---
    Commit ca56fa49a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 173739110
    
    ---
    Commit 48df7c972 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173738765
    
    ---
    Commit fb2c84cb2 authored by Jeremy Lau<lauj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change
    
    PiperOrigin-RevId: 173738655
    
    ---
    Commit 245a5c171 authored by Akshay Agrawal<akshayka@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make functional_ops compatible with eager exeuction by ignoring
    caching devices when in eager mode
    
    PiperOrigin-RevId: 173737949
    
    ---
    Commit d1c59bd37 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tf.quantize op, which is the same as tf.quantize_v2.
    
    PiperOrigin-RevId: 173735986
    
    ---
    Commit 3ff9c8d2a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix typos in Linear Model Tutorial samples
    
    1. test_file_name is undefined (should be test_file.name)
    2. train_file_name is undefined (should be train_file.name)
    
    PiperOrigin-RevId: 173733442
    
    ---
    Commit abbab2430 authored by Michael Case<mikecase@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add bazel mirror links for newly added workspace dependencies.
    
    PiperOrigin-RevId: 173732606
    
    ---
    Commit 46a577feb authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [CMake] Generate audio_ops wrappers in the CMake build.
    
    Fixes #14004.
    
    PiperOrigin-RevId: 173732397
    
    ---
    Commit 7cb7f88c5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add count metric, a helper function that computes the total number or total weight of examples.
    
    PiperOrigin-RevId: 173731046
    
    ---
    Commit e1d7615eb authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix issue with gradients of functions which return multiple values.
    
    PiperOrigin-RevId: 173730922
    
    ---
    Commit 80374a7b4 authored by Joshua V. Dillon<jvdillon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Breaking change: Rename `tf.contrib.distributions.Independent` parameter from
    `reduce_batch_ndims` to `reinterpreted_batch_ndims`. Also change default;
    `reinterpreted_batch_ndims` default has semantics of `tf.layers.flatten`, i.e.,
    all batch dimensions except the first (batch axis 0) are interpretted as being
    part of the event.
    
    PiperOrigin-RevId: 173729585
    
    ---
    Commit 5426a3c93 authored by Allen Lavoie<allenl@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tfe.get_optimizer_variables for fetching a list of variables which an
    optimizer has created. Useful for saving them if executing eagerly.
    
    PiperOrigin-RevId: 173726859
    
    ---
    Commit 02f55400f authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    custom_gradient functions should be able to return their inputs
    
    PiperOrigin-RevId: 173723462
    
    ---
    Commit 78bac7290 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Add compatbility doc string to add_to_collection() and friends
    
    PiperOrigin-RevId: 173716912
    
    ---
    Commit 9bf00c371 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Shorter import for tfe.
    
    PiperOrigin-RevId: 173716375
    
    ---
    Commit 0bc432a44 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Add compatibility errors and doc strings to queues, input pipelines and Supervisor
    
    PiperOrigin-RevId: 173712330
    
    ---
    Commit e9af1af4f authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Fixing the sources docs in master.
    
    ---
    Commit b31b08bb0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds randomized tests for newly introduced complex and related ops.
    
    PiperOrigin-RevId: 173709206
    
    ---
    Commit 466b9ecf8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
      Report total number of bytes to be transferred when the curl request makes no progress.
    
    PiperOrigin-RevId: 173707608
    
    ---
    Commit 7c4e98eb4 authored by Igor Ganichev<iga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Tensor._rank() getter
    
    It appears to speed up SPINN model by about 1%, which is not much, but
    this method is very simple and easier to use than len(tensor._shape_tuple())
    
    PiperOrigin-RevId: 173703259
    
    ---
    Commit d7cffe9c0 authored by Allen Lavoie<allenl@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds save and restore methods to tfe.Network
    
    Save just saves the variables to a checkpoint. Restore either restores immediately or defers the restoration to variable creation time with a custom getter.
    
    PiperOrigin-RevId: 173703075
    
    ---
    Commit 9158f974a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use tf.app.run in gcs_smoke, so that the flags are explicitly parsed, instead of parsed when first accessed.
    
    PiperOrigin-RevId: 173702828
    
    ---
    Commit 3d39b32b9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a tfprof bug. Throws an error when the flops cannot be calculated.
    
    PiperOrigin-RevId: 173702740
    
    ---
    Commit 73155f56a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Small code cleanup. Re-alphabetized.
    
    PiperOrigin-RevId: 173702336
    
    ---
    Commit 32bcf46f1 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal
    
    PiperOrigin-RevId: 173697389
    
    ---
    Commit 97484a4d9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173690751
    
    ---
    Commit 873ef2ca3 authored by Oleg Zabluda<ozabluda@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Fix documentation error in tf.size() - output type
    ---
    Commit 16538dab7 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Saves summaries in the mnist example.
    
    PiperOrigin-RevId: 173690505
    
    ---
    Commit 6b05b36cd authored by Jiri Simsa<jsimsa@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Generalizing sloppy_interleave, making sloppiness an option.
    
    PiperOrigin-RevId: 173687797
    
    ---
    Commit 7775a6604 authored by Michael Case<mikecase@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal Change
    
    PiperOrigin-RevId: 173685895
    
    ---
    Commit 5120e75cf authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Move `@compatibility(eager)` from class docstring to __init__ docstring
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 7d7b2ec58 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Also fixes `@end_compatiblity` -> `@end_compatibility`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 96dc501cd authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Fix incorrect annotation tag in tf.Variable
    
    In tf.Variable the annotation tag of `@compatiblity` should be `@compatibility`
    
    ---
    Commit c22973867 authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete bad links (md links not supported in html blocks).
    
    PiperOrigin-RevId: 173680417
    
    ---
    Commit 4198e27be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] [XLA:GPU] Adds compiler support for C64 primitive type, including relevant elementwise unary and binary op lowering for CPU and GPU.
    
    We use a named LLVM struct "complex64", laid out the same as std::complex<float>. This named struct is accessed via the llvm::Module, which required changes to accessors of PrimitiveTypeToIrType & friends.
    
    Ops that require atan2 (in particular, angle and log) are only supported on GPU at this point. LLVM lacks a CPU intrinsic for atan or atan2, whereas libdevice provides this for GPU.
    
    PiperOrigin-RevId: 173676849
    
    ---
    Commit 4ae245a7d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    n/a (internal change only)
    
    PiperOrigin-RevId: 173674697
    
    ---
    Commit 0ccf5cf60 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Limit the amount of logspam a use of GraphKeys.VARIABLES causes.
    
    Multiple copies of this warning next to each other often make logs unreadable.
    
    PiperOrigin-RevId: 173672701
    
    ---
    Commit a7b872527 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Fix an ouput typo in `ci_sanity.sh`
    
    In the last PR #13924 (clang sanity check) the output message should be changed:
    `due to the absence of Python code changes`
    ->
    `due to the absence of .h or .cc code changes`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 58d2c5f50 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Shanqing Cai<cais@google.com>:
    Add `SANITY_STEPS_DESC` for do_clang_format_check (#14030)
    
    * Add `SANITY_STEPS_DESC` for do_clang_format_check
    
    This fix is a follow up to PR #13924 to add the corresponding
    description in `SANITY_STEPS_DESC`.
    
    See comment #13924#discussion_r147314599
    for details.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update description for Clang Format Check
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 62a9ab28c authored by ???<dev@goodow.com>
    Committed by GitHub<noreply@github.com>:
    fix broken link
    ---
    Commit c6292a3f9 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Sanitize decode_csv_op.cc with `clang-format -i`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 285ea3910 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Add test cases for `double` support of `tf.decode_csv`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 73aaed655 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Update docs for `double` support on `tf.decode_csv`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 3595d1613 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Add `double` support for `tf.decode_csv`
    
    In the current tensorflow `tf.decode_csv` accepts
    `float`, `int32`, `int64`, `string` but not `double`.
    It seems adding `double` support makes sense as `StringToNumber`
    already support `double` type.
    
    This fix adds `double` support for `tf.decode_csv`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 37d483fda authored by Sergii Khomenko<sergii.khomenko@stylight.com>
    Committed by Sergii Khomenko<sergii.khomenko@stylight.com>:
    Fix a typo
    
    ---
    Commit 9c8a520b0 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add WriteEvent method to SummaryWriterInterface
    
    Another change will follow that adds an op for this method. It will be useful
    for loading event logs into other types of summary writer implementations, like
    a database.
    
    This change might also make the new summary file writer go faster, due to less
    memory copying.
    
    PiperOrigin-RevId: 173640116
    
    ---
    Commit a49455812 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 172654120
    
    PiperOrigin-RevId: 174388998

commit 44505e5cfeb01ea715c39d15a571eae4d144230a
Author: Bo Wang <david.b.wang@gmail.com>
Date:   Wed Nov 1 22:36:34 2017 -0700

    Fix LMDBReader crash due to not fully cleanup (#13396)
    
    * Clean up context at LMDBReader::OnWorkStartedLocked()
    
    * Add testcase: test_read_from_file_repeated
    
    * Update lmdb test
    
    * Fix the range issue

commit 3540a4277466d714a975ec4a69d9294b4f65438c
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 1 15:13:03 2017 -0700

    For partitioned variables where there are enough OOV buckets such that one partition may be entirely OOV, GenerateVocabRemapping op will crash when checking if new_vocab_offset_ + num_new_vocab_ <= the new vocabulary table's size.  Instead of removing this requirement, avoid entering the remapping logic if we're operating on a OOV-only partition.
    
    PiperOrigin-RevId: 174243064

commit 4b63f47d9f6e1876b8f7084b0c0c434a0930c070
Author: Justin Lebar <jlebar@google.com>
Date:   Mon Oct 30 11:10:37 2017 -0700

    [XLA:CPU] Don't crash if someone tries to do dot(X, X) or dot(X, X^T).
    
    PiperOrigin-RevId: 173919310

commit 355e25ebcab64e833dfc987638c3e6c79d838266
Author: Benoit Steiner <bsteiner@google.com>
Date:   Tue Oct 24 19:47:46 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit 9f8523640 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 173145770
    
    ---
    Commit 01b6b0638 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cut tracing memory cost
    
    PiperOrigin-RevId: 173144626
    
    ---
    Commit 5e23e0e67 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Erase cloned instructions on the fly when merging fusion nodes.
    
    This avoids the awkward situation where an RNG which is clearly eligible for fusion becomes ineligible mid-fusion because it suddenly has an extra (dead) user.
    
    PiperOrigin-RevId: 173141716
    
    ---
    Commit 1038927c0 authored by Saurabh Saxena<srbs@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add SerializeIterator op that serializes an IteratorResource into a variant tensor.
    Add DeserializeIterator op that builds IteratorResource from a variant tensor.
    Move BundleReaderWrapper and BundleWriterWrapper from dataset.h to iterator_ops.cc.
    Add generic key-value store interfaces IteratorStateReader and IteratorStateWriter for reading/writing state of iterators.
    Get rid of IteratorBundleReader and IteratorBundleWriter.
    
    PiperOrigin-RevId: 173140858
    
    ---
    Commit 57f3e529d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change
    
    PiperOrigin-RevId: 173136642
    
    ---
    Commit 0e56ffb7b authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix breakages in OSS builds
    
    See example breakages logs at:
    http://ci.tensorflow.org/job/tensorflow-cl-cpu-python3-pip/10847/console
    http://ci.tensorflow.org/job/tensorflow-cl-gpu/11008/console
    
    1. CL/172477381 added the no_oss tag to tests with oss_serial tags, which broke the logic of OSS_SERIAL tests in pip.sh and run_pip_test.sh. This CL fixes that.
    
    2. The nccl_kernels BUILD target in contrib/nccl/BUILD was missing some dependencies. This CL adds the missing ones.
    
    Fixes: #13918
    PiperOrigin-RevId: 173133914
    
    ---
    Commit 3ed049b67 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allows calling keras layers in eager mode.
    
    PiperOrigin-RevId: 173129805
    
    ---
    Commit 4ec6f2b07 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switching contrib.summaries API to be context-manager-centric
    
    PiperOrigin-RevId: 173129793
    
    ---
    Commit 03b02ffc9 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Put Bazel mirror URLs first
    
    PiperOrigin-RevId: 173127955
    
    ---
    Commit 46ab25e4d authored by David Majnemer<majnemer@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add support for convolutions with no spatial dimensions
    
    PiperOrigin-RevId: 173126950
    
    ---
    Commit fc56349b7 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.data] Convert dataset arguments to tensors as early as possible.
    
    This change raises a `TypeError` earlier if (for example) the `batch_size`
    argument to `Dataset.batch()` has the incorrect type.
    
    PiperOrigin-RevId: 173126678
    
    ---
    Commit 4f7503a87 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Support for registering multiple minibatches with register_fully_connected()
    
    PiperOrigin-RevId: 173121735
    
    ---
    Commit 2845bfcd6 authored by Tim Harley<tharley@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid listing all modified Enter/RefEnter nodes on INFO, use VLOG(1) instead.
    
    Leave a single, simple, message on INFO.
    
    PiperOrigin-RevId: 173121726
    
    ---
    Commit 434695921 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: _check_registration() supports multiple towers.
    
    PiperOrigin-RevId: 173115870
    
    ---
    Commit 670dddf4a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Multi-minibatch support for
    tf.contrib.kfac.fisher_blocks.FullyConnectedKFACBasicFB.
    
    PiperOrigin-RevId: 173109677
    
    ---
    Commit dc13a8e2f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix import of meta graphs with partitioned variables into a scope.
    
    Saver inspects SliceInfo to decide the variable name when creating a
    checkpoint. Before this fix even if a partitioned variable ("weights")
    was imported into a scope "a" it would still be checkpointed as ("weights")
    instead of ("a/weights") since import_scoped_meta_graph was not adjusting
    the SliceInfo.
    
    WARNING: if you use import_meta_graph on graphs with partitioned_variables WITH an import_scope argument AND then create a Saver to write/read checkpoints this change
    may break your checkpoint loading.
    PiperOrigin-RevId: 173105796
    
    ---
    Commit eea089bdb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    K-FAC: Multi-tower support for ConvDiagonalFB.
    
    PiperOrigin-RevId: 173105412
    
    ---
    Commit 9b9cbbe2a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 Tperm type support for `Transpose` (#13909)
    
    * Add int64 Tperm type support for `Transpose`
    
    This fix adds int64 Tperm support for `Transpose`. In
    `array_ops.cc`, `Transpose` and `ConjugateTranspose`
    have been specified as accepting int32 and int64 perm
    types. However, only int32 kernels has been registered.
    
    This fix adds the int64 perm support by removing
    the constraint on Tperm, resolve the type at runtime,
    and copying the data type accordingly to correctly handle
    the int64/int32 types.
    
    Additional tests have been added as well.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 of perm in Transpose.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add namespace to hide PermutationHelper
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Enable use_gpu=True for perm type test.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * extra // namespace annotation
    
    * Adding a comment about int32 casting that should be safe.
    
    Permutations only contain values that refer to dimensions, and the maximum number of dimensions we have is 254, so an int32 is always safe here.
    
    ---
    Commit ac0004e71 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 shape support on GPU for stateless random ops. (#13908)
    
    * Add int64 shape support on GPU for stateless random ops.
    
    This fix adds int64 shape support on GPU for stateless random ops
    `StatelessRandomUniform`, `StatelessRandomNormal`, `StatelessTruncatedNormal`.
    
    The int64 shape for stateless random ops is already supported on CPU
    with int32/int64 processed properly through `MakeShape`.
    
    However, on GPU a type constraint `.TypeConstraint<int32>("T")`
    has been improperly added. Such a type constraint actually prevents
    an int64 shape type to run on GPU. (As a comparision, no type constraint
    on CPU).
    
    This fix removes the type constraint and allows int64 shape to be run on GPU.
    
    This fix also adds test cases for int64 shape support on stateless random ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 shape support for stateless random ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int32 to shape types tested.
    
    ---
    Commit 0d437c3be authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 padding support for MirrorPad (#13907)
    
    * Add int64 padding support for MirrorPad
    
    This fix adds int64 padding support for `MirrorPad`.
    In the `array_ops.cc` the `MirrorPad`/`MirrorPadGrad`
    has been specified as supporting int64 padding. The related
    kernels does not have the int64 padding registered though.
    This fix adds the int64 padding support. This fix also adds
    additional test cases for coverage.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update template for CPU and GPU support of int64 paddings.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 padding support for MirrorPad
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Put eigen header first like before, just in case.
    
    ---
    Commit 690003cc0 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add `int64` type `multiples` support for `tf.tile` (#13884)
    
    * Add `int64` type `multiples` support for `tf.tile`
    
    In the doc of `tf.tile` (tf.tile.__doc__) both `int32`
    and `int64` are supported for `multiples`. However, the kernel
    for `int64` is not registered yet.
    
    This fix adds the support of `int64` `multiples` so that the
    behavior matches the description of the docs.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update functors for int64 multiples support in `tf.tile`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update test cases for int64 of multiples in `tf.tile`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add GPU and non GPU tests
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * format with clang-format -i
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Move Tmultiples after T (as it is  auxilliary)
    
    And use `use_gpu=True`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit fd8d517b9 authored by Yunxing Dai<yunxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tests for convolution 1D
    RELNOTES: n/a
    
    PiperOrigin-RevId: 173060283
    
    ---
    Commit 40c475b48 authored by formath<jinpengliu@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    add segment_reduction_ops to tf_op_files (#13901)
    
    ---
    Commit bfa4ec194 authored by Tayo Oguntebi<10927929+tayo@users.noreply.github.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Update node_def.proto comments (#13874)
    
    The device field had outdated comments.
    
    Note: We could consider adding tpu as an example here, e.g. "gpu" | "cpu" | "tpu".  Thoughts?
    ---
    Commit c9cb5a58d authored by formath<jinpengliu@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    protobuf lib path bug fix for benckmark on osx (#13878)
    
    ---
    Commit 1c1dad105 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Add int64 axis support for reduction ops. (#13891)
    
    * Add int64 axis support for reduction ops.
    
    This fix is a follow up to PR 13863. In PR 13863 the
    program crash is fixed if int64 axis is passed to reduction ops,
    e.g. reduce_sum, reduce_max, etc. However, 13863 does not
    process the case of int64 support, it merely fixes the crash.
    
    This fix adds the support for int64 axis of reduction ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for mean, prod, sum
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for min and max.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for reduce_all and reduce_any
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 axis support of reduce_any and reduce_all
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 17096081e authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Improve resize_bicubic performance by reorganizing loops (#13840)
    
    * Improve resize_bicubic performance by reorganizing loops
    
    This fix tries to address the issue raised in 13693 where
    performance of `resize_bicubic` is not on par with opencv.
    
    This fix rearranges the loops so that it is the same for
    num_channel=40 and num_channel=3:
    
    Pre-fix:
    ```
    CHANNEL=40
    opencv: 145.08ms
    tf: 314.26ms
    
    CHANNEL=3
    opencv: 11.95ms
    tf: 8.95ms
    ```
    
    Post-fix:
    ```
    CHANNEL=40
    opencv: 144.25ms
    tf: 214.55ms
    
    CHANNEL=3
    opencv: 11.78ms
    tf: 14.07ms
    ```
    
    This fix fixes 13693.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Keep special handling of `num_channels=3` for `resize_bicubic`
    
    This commit keeps special handling of `num_channels=3` for
    `resize_bicubic`:
    Without special handling:
    ```
    opencv: 11.78ms
    tf: 14.07ms
    ```
    With special handling:
    ```
    opencv: 11.74ms
    tf: 9.46ms
    ```
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Expand Benchmark test for resize_bicubic
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update from review feedback.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit b927df57f authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Update protobuf.cmake to b04e5cba356212e4e8c66c61bbe0c3a20537c5b9 (#13893)
    
    This fix tries to address the issue raised in 8187 where
    protobuf.cmake used different version as bazel.
    
    The reason for discrepancy was due to the fact that a customerized
    protobuf was needed with Windows patch. Since the patch has been
    merged in (https://github.com/google/protobuf/pull/2203),
    it makes sense to update protobuf.cmake so that the same version
    of cmake is used.
    
    This fix fixes 8187.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    ---
    Commit d1183ca6a authored by Vijay Vasudevan<vrv@google.com>
    Committed by GitHub<noreply@github.com>:
    Give each variable a unique name in accumulate_n_v2_eager_test. (#13886)
    
    ---
    Commit a69945810 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update pin for bazel-toolchains to latest version
    
    PiperOrigin-RevId: 173002530
    
    ---
    Commit 9d55c249c authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix doc in TF_CALL_ when invoked in mobile platform (#13881)
    
    * Fix doc in TF_CALL_ when defined(IS_MOBILE_PLATFORM) && !defined(__ANDROID_TYPES_FULL__)
    
    This is a small doc fix that includes bool as part of the types
    that is supported in mobile (IS_MOBILE_PLATFORM && !__ANDROID_TYPES_FULL__),
    as bool is clearly invoked in the following define.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Also add bool to android full version.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit ba49d8583 authored by Bjarke Hammersholt Roune<broune@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Slight change to reduce_test to avoid generating inf, which was triggering an inf detector unnecessarily.
    
    PiperOrigin-RevId: 172965466
    
    ---
    Commit 93e8f3c67 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding Python ApiDef overrides.
    
    PiperOrigin-RevId: 172960496
    
    ---
    Commit 0d6a2e353 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change.
    
    PiperOrigin-RevId: 172960439
    
    ---
    Commit 62df65c72 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add dtype argument to Mean and Accuracy object-oriented metrics.
    
    PiperOrigin-RevId: 172957714
    
    ---
    Commit d7409d32b authored by Simone Cirillo<my.accounts@gmx.se>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix import of spatial_softmax from tensorflow.contrib.layers (#13833)
    
    ---
    Commit df8bce63d authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix crash when `int64` axis is passed to `tf.reduce_sum` (#13863)
    
    * Fix crash when `int64` axis is passed to `tf.reduce_sum`
    
    This fix tries to fix the crash triggered by `int64` axis passed
    to `tf.reduce_sum`:
    ```
    ubuntu@ubuntu:~/tensorflow2$ (cd && python)
    Python 2.7.12 (default, Nov 19 2016, 06:48:10)
    [GCC 5.4.0 20160609] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import tensorflow as tf
    >>> v = tf.reduce_sum([1,2,3], tf.constant(0, tf.int64))
    2017-10-20 15:55:06.993430: F tensorflow/core/framework/tensor.cc:601] Check failed: dtype() == expected_dtype (9 vs. 3)
    ubuntu@ubuntu:~/tensorflow2$
    ```
    
    The issue is caused by the fact that shape inference in `common_shape_fns.cc`
    only assumes int32 without proper handling of diffent types. In `math_ops.cc`
    both int32 and int64 are mentioned.
    
    NOTE that this fix does not address the issue that int64 is not supported.
    To allow int64 axis it is more than adding a template in `ReductionOp` as the type
    of the axis seems to be decided by some other ways in Eigen.
    
    This fix merely fixed the crash so that an error message will return without
    exit from the python program "No OpKernel was registered to support Op 'Sum' with these attrs".
    
    Still, I think its worth to at least allow the program to continue in case of unsupported kernel.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update implementation with a template helper function.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 29c7b4658 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding the Stanford Tensorflow class to community resources.
    
    PiperOrigin-RevId: 172956049
    
    ---
    Commit f758b24a8 authored by Alexandre Passos<apassos@google.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Variable name for the eager test (#13873)
    
    ---
    Commit a5fe66b15 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removed some unnecessary broadcasts in binary ops where only one input needs
    broadcasting (which is a fairly common case, even in the fallback path).
    
    PiperOrigin-RevId: 172950493
    
    ---
    Commit c77090a0a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Fix issues where int64 crops could not be passed to batch_to_space. (#13862)
    
    * Fix issues where int64 crops could not be passed to batch_to_space.
    
    This fix tries to address the issue where int64 `crops` could
    not be passed to `batch_to_space` even though both int32 and
    int64 are specified as supported in the docs (tf.batch_to_space.__doc__)
    
    The reason is that BatchToSpace kernel puts a constraint of int32 to crops
    data types.
    
    This fix removed the constraint so that int64 `crops` could be supported.
    
    NOTE: Just removing the constraint should work and it is not necessary
    to add specification to the kernel class template, as `SubtleMustCopyFlat`
    called in the class already correctly handled both int32 and int64 cases.
    Besides, other data types (e.g., float or double) will not be passed to the
    kernel as they are guarded by the specification in `array_ops.cc`.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Also remove int64/int32 type constraints for SpaceToBatch kernels
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 crops of batch_to_space and space_to_batch
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failures.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 494837936 authored by Joshua V. Dillon<jvdillon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make `tf.contrib.distributions` quadrature family accept a `Tensor` for
    `quadrature_grid_and_probs` argument.
    
    PiperOrigin-RevId: 172950094
    
    ---
    Commit 9c825d32c authored by Jinze Bai<baijinze1994@163.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    Merge two GPU kernel launching to one in DiagOp. (#13859)
    
    ---
    Commit c0ca50a47 authored by Yan Facai (???)<facai.yan@gmail.com>
    Committed by Vijay Vasudevan<vrv@google.com>:
    ENH: add Relu6GradGrad (#13268)
    
    * ENH: add Relu6GradGrad
    
    * TST: add test case
    
    * CLN: import nn_grad
    
    * TST: add init value
    
    ---
    Commit 8ff33271e authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Dump the computation's SessionModule as part of the tf_compile rule.
    
    PiperOrigin-RevId: 172946149
    
    ---
    Commit ebcae4a5e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add streaming_precision_recall_at_equal_thresholds
    
    This helper method computes streaming tp, fp, tn, fp, precision, and recall for the user in a way that exhibits O(T + N) time and space complexity (instead of O(T * N)), where T is the number of thresholds and N is the size of the predictions tensor.
    
    Thanks to Frank Chu for the efficient algorithm!
    
    PiperOrigin-RevId: 172946073
    
    ---
    Commit ccfd9c1e5 authored by Sanjoy Das<sanjoy@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Log Hlo IR during AOT compilation
    
    PiperOrigin-RevId: 172944165
    
    ---
    Commit 985031a10 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allows tfe.enable_eager_execution(device_policy=tfe.DEVICE_POLICY_WARN).
    
    PiperOrigin-RevId: 172943398
    
    ---
    Commit 703182d85 authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add performance guide for fused decode_and_crop_jpeg optimization.
    
    PiperOrigin-RevId: 172943116
    
    ---
    Commit 66b1f4383 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make Network compatible with eager mode. Currently it only allows to instantiate a Network in eager mode using the regular Keras API, and call it on eager tensors.
    
    PiperOrigin-RevId: 172942569
    
    ---
    Commit 41df2cec2 authored by ashankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Testing pending CL: 172939383
    
    ---
    Commit 37fd95179 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplifies capturing code in graph_callable to use recent function improvements.
    
    PiperOrigin-RevId: 172937003
    
    ---
    Commit d1e7382af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 172924803
    
    PiperOrigin-RevId: 173347587

commit dfc7b26b0dc0dd54038a1be3b31b05bd39c1e79f
Author: Alexandre Passos <apassos@google.com>
Date:   Tue Oct 24 14:42:15 2017 -0700

    Exception instead of crashing on resource.numpy()
    
    PiperOrigin-RevId: 173313459

commit 1c1dad105a57bb13711492a8ba5ab9d10c91b5df
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Sat Oct 21 23:01:42 2017 -0700

    Add int64 axis support for reduction ops. (#13891)
    
    * Add int64 axis support for reduction ops.
    
    This fix is a follow up to PR 13863. In PR 13863 the
    program crash is fixed if int64 axis is passed to reduction ops,
    e.g. reduce_sum, reduce_max, etc. However, 13863 does not
    process the case of int64 support, it merely fixes the crash.
    
    This fix adds the support for int64 axis of reduction ops.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for mean, prod, sum
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for min and max.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add int64 axis support for reduce_all and reduce_any
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add test cases for int64 axis support of reduce_any and reduce_all
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit df8bce63d6de6e728e69eb9f45862b816f88a0db
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Fri Oct 20 17:40:40 2017 -0700

    Fix crash when `int64` axis is passed to `tf.reduce_sum` (#13863)
    
    * Fix crash when `int64` axis is passed to `tf.reduce_sum`
    
    This fix tries to fix the crash triggered by `int64` axis passed
    to `tf.reduce_sum`:
    ```
    ubuntu@ubuntu:~/tensorflow2$ (cd && python)
    Python 2.7.12 (default, Nov 19 2016, 06:48:10)
    [GCC 5.4.0 20160609] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import tensorflow as tf
    >>> v = tf.reduce_sum([1,2,3], tf.constant(0, tf.int64))
    2017-10-20 15:55:06.993430: F tensorflow/core/framework/tensor.cc:601] Check failed: dtype() == expected_dtype (9 vs. 3)
    ubuntu@ubuntu:~/tensorflow2$
    ```
    
    The issue is caused by the fact that shape inference in `common_shape_fns.cc`
    only assumes int32 without proper handling of diffent types. In `math_ops.cc`
    both int32 and int64 are mentioned.
    
    NOTE that this fix does not address the issue that int64 is not supported.
    To allow int64 axis it is more than adding a template in `ReductionOp` as the type
    of the axis seems to be decided by some other ways in Eigen.
    
    This fix merely fixed the crash so that an error message will return without
    exit from the python program "No OpKernel was registered to support Op 'Sum' with these attrs".
    
    Still, I think its worth to at least allow the program to continue in case of unsupported kernel.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Update implementation with a template helper function.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>

commit cbb705f10149a11b8d17182343ef12ab2dbfd7a8
Author: Yong Tang <yong.tang.github@outlook.com>
Date:   Tue Oct 17 14:35:51 2017 -0700

    Fix crash when `tf.pad` is used with int64 paddings. (#13517)
    
    * Add int64 bounds support for `tf.image.pad_to_bounding_box`
    
    This fix tries to fix the issue raised in 13506 where int64 data types
    for bounds in `tf.image.pad_to_bounding_box` crashes.
    
    The reason of the crash is caused by the fact that int64 was directly
    converted into int32 without passing through kernel registeration.
    
    This fix fixes the issue by adding `typename Tpadding` to the template.

commit 684f88fa7e61721c3264dc70abeed2b3e6fa7717
Author: Justin Lebar <jlebar@google.com>
Date:   Mon Oct 16 17:22:26 2017 -0700

    [XLA:GPU] Don't crash with --vmodule=gpu_compiler=2 if we can't run ptxas.
    
    At --vmodule=gpu_compiler=2, we run ptxas over our generated PTX, to
    validate it, and also to dump out stats like the number of registers
    used.
    
    But previously, this would fail if your GPU was anything other than
    sm_35 (i.e. K20/40/80), because we didn't pass down cc_major/cc_minor to
    ptxas.  And moreover, if ptxas failed to compile your program, we'd
    LOG(FATAL), which is probably no what you want.
    
    This change fixes both those issues.  Tested on my local GTX1080.
    
    PiperOrigin-RevId: 172403304

commit 7679a2ec746bec36191087feaf9ec8371180669c
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Fri Oct 13 15:22:19 2017 -0700

    Fix crash if tf.nn.conv2d_backprop_filter or tf.nn.conv2d_backprop_input is run with empty filter or input respectively. Resolves #13643.
    
    PiperOrigin-RevId: 172153646

commit f49f6cd1758b9ecc92eedd377983e8047b05d964
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Oct 9 16:39:21 2017 -0700

    Replace CHECK() with a WARNING in StepStatsCollector so that Save after Finalize won't crash.
    
    PiperOrigin-RevId: 171605724

commit d749f56a3e0b17a5fe5f3252446223b84e485f04
Author: Chris Leary <leary@google.com>
Date:   Fri Oct 6 11:06:12 2017 -0700

    [XLA] Fix a bug in ComputationBuilder::Collapse and add more tests/docs.
    
    Also updated test infrastructure so a shape mismatch does not cause a fatal
    crash in index_util, but rather reports an appropriate test failure message.
    
    PiperOrigin-RevId: 171315165

commit b99457c2138482470ae976a6364ce0ba754503cf
Author: Chris Leary <leary@google.com>
Date:   Fri Oct 6 11:06:12 2017 -0700

    [XLA] Fix a bug in ComputationBuilder::Collapse and add more tests/docs.
    
    Also updated test infrastructure so a shape mismatch does not cause a fatal
    crash in index_util, but rather reports an appropriate test failure message.
    
    PiperOrigin-RevId: 171315165

commit 2a5fb08bf2885cba29065d7269c5f6a32614b89a
Author: Eugene Brevdo <ebrevdo@google.com>
Date:   Wed Sep 27 13:48:03 2017 -0700

    SymbolicGradients: create the underlying runtime with the correct step container.
    
    This fixes a bug where calling tf.gradients of a tf.while_loop inside a Defun
    would hard crash the program.
    
    Also added some safety checks inside StackOps to avoid the hard crash if
    something like this happens again.
    
    PiperOrigin-RevId: 170246274

commit e2e3a943c0a28b7656325acb3fcd035743d55ea0
Author: Shanqing Cai <cais@google.com>
Date:   Mon Sep 25 19:35:53 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit 1e1b3d902 authored by Pete Warden<pete@petewarden.com>
    Committed by gunan<gunan@google.com>:
    Changed output directory for Pi CI build to fix permissions problem with nightlies (#13257)
    
    * Fix for RTLD_GLOBAL breakage of Pi builds, and removed Eigen version change for Pi that's no longer needed
    
    * Fixed Pi Zero OpenBLAS build problems and tidied up directories used
    
    * More robust checks in Pi build script
    
    * Changed output directory for Pi CI build to fix permissions problem
    
    ---
    Commit fe3a2e65c authored by Yan Facai (???)<facai.yan@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    check invalid string type for dest_nodes in extract_sub_graph (#13057)
    
    * BUG: check str type
    
    * TST: add unit test
    
    * CLN: remove list check
    
    * CLN: use warning
    
    * CLN: 2 indent
    
    * CLN: raise TypeError if not list
    
    * CLN: check string only
    
    ---
    Commit 225ab7629 authored by Jean Wanka<jm.wanka@gmail.com>
    Committed by Jean Wanka<jm.wanka@gmail.com>:
    Fix polynomial decay with cycle for global step=0
    
    For polynomial decay with cycle=True the learning rate at
    step 0 becomes NaN, because in the process of calculating it we
    devide by 0. This change should fix it, by setting the multiplier
    for the decay steps to one for global_step=0.
    
    ---
    Commit 286f57061 authored by Bjarke Hammersholt Roune<broune@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make Service::TransferToClient not attempt to manipulate the literal when the transfer failed, preventing a crash and allowing the caller to see the reason for the failed transfer.
    
    PiperOrigin-RevId: 169770126
    
    ---
    Commit e0501bc4d authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Shanqing Cai<cais@google.com>:
    Fix GRUBlockCell parameter naming inconsistency (#13153)
    
    * Fix GRUBlockCell parameter naming inconsistency
    
    This fix tries to fix the issue in 13137 where
    parameter `cell_size` is used instead of `num_units`.
    This is inconsistent with other RNN cells.
    
    This fix adds support of `num_units` while at the same
    time maintains backward compatiblility for `cell_size`.
    
    This fix fixes 13137.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Add `@deprecated_args` for 'cell_size' in `GRUBlockCell`
    
    This commit adds `@deprecated_args` for 'cell_size' in `GRUBlockCell`
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Address review comment
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 02a2eba05 authored by Pete Warden<pete@petewarden.com>
    Committed by gunan<gunan@google.com>:
    Fix for RTLD_GLOBAL breakage of Pi builds, and removed Eigen version change that's no longer needed (#13251)
    
    * Fix for RTLD_GLOBAL breakage of Pi builds, and removed Eigen version change for Pi that's no longer needed
    
    * Fixed Pi Zero OpenBLAS build problems and tidied up directories used
    
    * More robust checks in Pi build script
    
    ---
    Commit 8ef722253 authored by Sanjoy Das<sanjoy@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove a redundant setName.
    
    The EmitComputation should have emitted a function with the right name, so use a
    CHECK instead.
    
    PiperOrigin-RevId: 169764856
    
    ---
    Commit 1b94147dc authored by Neal Wu<wun@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix broken GitHub links in tensorflow and tensorflow_models resulting from The Great Models Move (a.k.a. the research subfolder)
    
    PiperOrigin-RevId: 169763373
    
    ---
    Commit b1ada5f0c authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix TensorBoard python -m invoke in docs
    
    PiperOrigin-RevId: 169758752
    
    ---
    Commit 2957cd894 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Local run option of estimator training.
    
    PiperOrigin-RevId: 169756384
    
    ---
    Commit 1dc2fe7ac authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 166264198
    
    PiperOrigin-RevId: 169998124

commit 286f57061cb8a21d3cc87b5ee06a87e3f51467c8
Author: Bjarke Hammersholt Roune <broune@google.com>
Date:   Fri Sep 22 20:38:54 2017 -0700

    Make Service::TransferToClient not attempt to manipulate the literal when the transfer failed, preventing a crash and allowing the caller to see the reason for the failed transfer.
    
    PiperOrigin-RevId: 169770126

commit b8614b5059ba00328a54db53d973d0e1262859bd
Merge: e04b47d9ef8 846454faae5
Author: Shanqing Cai <cais@google.com>
Date:   Wed Sep 20 16:38:20 2017 -0400

    Merge pull request #13185 from anight/golang_fix_random_crashes
    
    Fix random crashes in SessionRun()

commit d10902f0a947da40f80479d74e9a487617759085
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Sep 18 19:03:33 2017 -0700

    [XLA] Fix HLO-graph-dump handling of nodes near computation edges, and indicate root node.
    
    Previously, attempting to dump the neighborhood of a node that was too close to a computation edge would result in a crash when we tried to create an edge that went outside the bounds of the computation to a node that wasn't included in the graph.  This CL fixes that bug.
    
    In addition, we previously did not indicate the root node of the outermost computation, so that it wasn't obvious whether a "bottom" node on the graph was actually the root node or simply didn't have its outputs drawn (or didn't have any outputs).  This CL adds a "psuedonode" tag onto the root node that makes it clear that it's the root.
    
    This also adds a little verbosity to the graph title.  When the graphed computation is a fused computation, we also mention which fusion instruction it's associated with.
    
    Finally, this adds some verbose-mode logging that's useful to trace the operation of the graph-generation.  (I added this when debugging the crash mentioned above.)
    
    PiperOrigin-RevId: 169182331

commit e55574f28257bdacd744dcdba86c839e661b1b2a
Author: drpngx <drpngx@users.noreply.github.com>
Date:   Fri Sep 15 19:38:25 2017 -0700

    Branch 168917534 (#13077)
    
    * Use HLO name, rather than pointer address, for profile counter name.
    
    This removes a source of nondeterminism in IR generation.
    
    PiperOrigin-RevId: 168779489
    
    * Eager gradient tape doesn't keep tensors alive.
    
    PiperOrigin-RevId: 168782341
    
    * Add missing back-quote
    
    PiperOrigin-RevId: 168785422
    
    * Add in a comment that I forgot to add to a previous commit; NFC.
    
    PiperOrigin-RevId: 168786760
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168787665
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168788051
    
    * Fix typo "comptuation" (computation)
    
    PiperOrigin-RevId: 168799777
    
    * Fix a bug in export GTFlow model to shared format with sparse float split
    
    PiperOrigin-RevId: 168802503
    
    * Add signature def utility functions for inspection of input and output types and shapes.
    
    PiperOrigin-RevId: 168820997
    
    * Apply const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168824461
    
    * TFE: Clearer error message when enable_eager_execution is called more than once
    
    PiperOrigin-RevId: 168834147
    
    * [tf.contrib.data] Add colocation constraints between Iterator and Datasets.
    
    This restores the colocation behavior that was present when Dataset
    objects were passed as DT_RESOURCE tensors, and avoids the (currently
    not supported) case where TensorFlow may attempt to split the dataset
    pipeline across devices.
    
    PiperOrigin-RevId: 168841061
    
    * Optimize C++ kernels for the matrix_band_part op, which is used in various ops operating on triangular or banded matrices:
     * Add benchmark for matrix_band_part.
     * Implement simple optimized CUDA kernel instead of calling Eigen generator.
     * Parallelize CPU kernel for matrix_band_part.
     * Support on-the-fly transposition in the underlying functors (to be used for future QR op in followup).
    
    Benchmarks:
    
    First column is of the form {device}_{shape}_{num_lower,num_upper}
    
    Test case                        Before       After    Speedup
    cpu_(10,16,16)_(-1,-1)          5.6505e-05  6.2108e-05  -9.92%
    cpu_(10,16,16)_(-1,0)           0.00010848  0.00010908  -0.55%
    cpu_(10,16,16)_(0,-1)            0.0001055  0.00011396  -8.02%
    cpu_(10,16,16)_(2,2)              0.000108  0.00011706  -8.39%
    cpu_(10,101,101)_(-1,-1)        0.00013697  6.0558e-05 +55.79%
    cpu_(10,101,101)_(-1,0)         0.00054002  0.00017703 +67.22%
    cpu_(10,101,101)_(0,-1)         0.00051188  0.00017607 +65.60%
    cpu_(10,101,101)_(2,2)          0.00050449  0.00016904 +66.49%
    cpu_(10,256,256)_(-1,-1)        0.00032043  5.6028e-05 +82.51%
    cpu_(10,256,256)_(-1,0)           0.001335   0.0004015 +69.93%
    cpu_(10,256,256)_(0,-1)          0.0013521  0.00038862 +71.26%
    cpu_(10,256,256)_(2,2)            0.001269  0.00039959 +68.51%
    cpu_(10,1000,1000)_(-1,-1)       0.0090729  6.3419e-05 +99.30%
    cpu_(10,1000,1000)_(-1,0)          0.01712   0.0047594 +72.20%
    cpu_(10,1000,1000)_(0,-1)         0.016647   0.0046474 +72.08%
    cpu_(10,1000,1000)_(2,2)          0.012737   0.0041161 +67.68%
    cpu_(10,1024,1024)_(-1,-1)       0.0093709  5.8889e-05 +99.37%
    cpu_(10,1024,1024)_(-1,0)         0.017075   0.0051999 +69.55%
    cpu_(10,1024,1024)_(0,-1)         0.016867    0.004617 +72.63%
    cpu_(10,1024,1024)_(2,2)          0.013191    0.003759 +71.50%
    cpu_(10,2048,2048)_(-1,-1)        0.028427  6.2466e-05 +99.78%
    cpu_(10,2048,2048)_(-1,0)         0.048134    0.017642 +63.35%
    cpu_(10,2048,2048)_(0,-1)         0.048773    0.017558 +64.00%
    cpu_(10,2048,2048)_(2,2)          0.036153    0.015452 +57.26%
    cpu_(10,10,4,4)_(-1,-1)         5.8055e-05  5.8055e-05  +0.00%
    cpu_(10,10,4,4)_(-1,0)          0.00015557   0.0001564  -0.54%
    cpu_(10,10,4,4)_(0,-1)          0.00015855  0.00015199  +4.14%
    cpu_(10,10,4,4)_(2,2)           0.00016379  0.00018096 -10.48%
    cpu_(10,10,10,10)_(-1,-1)       6.0558e-05  6.0558e-05  +0.00%
    cpu_(10,10,10,10)_(-1,0)          0.000368  0.00038695  -5.15%
    cpu_(10,10,10,10)_(0,-1)        0.00036263  0.00038612  -6.48%
    cpu_(10,10,10,10)_(2,2)         0.00038648  0.00042963 -11.17%
    cpu_(10,10,16,16)_(-1,-1)       6.9022e-05  5.7578e-05 +16.58%
    cpu_(10,10,16,16)_(-1,0)         0.0005815   0.0001874 +67.77%
    cpu_(10,10,16,16)_(0,-1)        0.00059354   0.0001924 +67.58%
    cpu_(10,10,16,16)_(2,2)         0.00062239  0.00019097 +69.32%
    cpu_(10,10,101,101)_(-1,-1)     0.00014806  6.2823e-05 +57.57%
    cpu_(10,10,101,101)_(-1,0)       0.0039785  0.00078249 +80.33%
    cpu_(10,10,101,101)_(0,-1)       0.0040585  0.00076556 +81.14%
    cpu_(10,10,101,101)_(2,2)        0.0039514  0.00077307 +80.44%
    cpu_(10,10,256,256)_(-1,-1)      0.0026824  6.0558e-05 +97.74%
    cpu_(10,10,256,256)_(-1,0)        0.017269   0.0031619 +81.69%
    cpu_(10,10,256,256)_(0,-1)        0.020287   0.0030774 +84.83%
    cpu_(10,10,256,256)_(2,2)         0.011919   0.0026599 +77.68%
    cpu_(10,10,1000,1000)_(-1,-1)     0.065783  5.6982e-05 +99.91%
    cpu_(10,10,1000,1000)_(-1,0)        0.1361    0.054533 +59.93%
    cpu_(10,10,1000,1000)_(0,-1)        0.1397    0.053405 +61.77%
    cpu_(10,10,1000,1000)_(2,2)        0.10173    0.048561 +52.26%
    cpu_(10,10,1024,1024)_(-1,-1)     0.066231  7.5579e-05 +99.89%
    cpu_(10,10,1024,1024)_(-1,0)       0.13615    0.059931 +55.98%
    cpu_(10,10,1024,1024)_(0,-1)       0.13745    0.064931 +52.76%
    cpu_(10,10,1024,1024)_(2,2)        0.10493    0.054258 +48.29%
    cpu_(10,10,2048,2048)_(-1,-1)      0.23487  6.6042e-05 +99.97%
    cpu_(10,10,2048,2048)_(-1,0)       0.41014     0.24283 +40.79%
    cpu_(10,10,2048,2048)_(0,-1)       0.43621     0.26393 +39.49%
    cpu_(10,10,2048,2048)_(2,2)        0.29919     0.22302 +25.46%
    
    gpu_(10,16,16)_(-1,-1)          0.00010753  0.00010753  +0.00%
    gpu_(10,16,16)_(-1,0)           0.00011253  0.00012445 -10.59%
    gpu_(10,16,16)_(0,-1)           0.00012493  0.00013399  -7.25%
    gpu_(10,16,16)_(2,2)              0.000108  0.00011754  -8.83%
    gpu_(10,101,101)_(-1,-1)        0.00011849  8.7976e-05 +25.75%
    gpu_(10,101,101)_(-1,0)         0.00012743  0.00012243  +3.93%
    gpu_(10,101,101)_(0,-1)         0.00012958  0.00012362  +4.60%
    gpu_(10,101,101)_(2,2)          0.00011504  0.00011504  +0.00%
    gpu_(10,256,256)_(-1,-1)        0.00013447  9.7513e-05 +27.48%
    gpu_(10,256,256)_(-1,0)         0.00018752  0.00014746 +21.36%
    gpu_(10,256,256)_(0,-1)         0.00017798  0.00016904  +5.02%
    gpu_(10,256,256)_(2,2)           0.0001514  0.00013697  +9.53%
    gpu_(10,1000,1000)_(-1,-1)       0.0005095  9.8586e-05 +80.65%
    gpu_(10,1000,1000)_(-1,0)       0.00088501  0.00056589 +36.06%
    gpu_(10,1000,1000)_(0,-1)       0.00090456  0.00055242 +38.93%
    gpu_(10,1000,1000)_(2,2)        0.00080955  0.00049639 +38.68%
    gpu_(10,1024,1024)_(-1,-1)      0.00050902  9.7036e-05 +80.94%
    gpu_(10,1024,1024)_(-1,0)       0.00098789  0.00058246 +41.04%
    gpu_(10,1024,1024)_(0,-1)            0.001  0.00059545 +40.46%
    gpu_(10,1024,1024)_(2,2)        0.00082254  0.00049961 +39.26%
    gpu_(10,2048,2048)_(-1,-1)        0.001495  9.8944e-05 +93.38%
    gpu_(10,2048,2048)_(-1,0)         0.003535   0.0017736 +49.83%
    gpu_(10,2048,2048)_(0,-1)        0.0034965   0.0017921 +48.75%
    gpu_(10,2048,2048)_(2,2)         0.0027704   0.0015399 +44.41%
    gpu_(10,10,4,4)_(-1,-1)         0.00011086  9.1076e-05 +17.85%
    gpu_(10,10,4,4)_(-1,0)           0.0001235  0.00013411  -8.59%
    gpu_(10,10,4,4)_(0,-1)          0.00011849   0.0001204  -1.61%
    gpu_(10,10,4,4)_(2,2)           0.00010896  0.00013256 -21.66%
    gpu_(10,10,10,10)_(-1,-1)       0.00010657  9.5844e-05 +10.07%
    gpu_(10,10,10,10)_(-1,0)        0.00011754  0.00013602 -15.72%
    gpu_(10,10,10,10)_(0,-1)        0.00011909  0.00012004  -0.80%
    gpu_(10,10,10,10)_(2,2)         0.00013196  0.00011349 +14.00%
    gpu_(10,10,16,16)_(-1,-1)       0.00012898  0.00010705 +17.01%
    gpu_(10,10,16,16)_(-1,0)        0.00014353  0.00012338 +14.04%
    gpu_(10,10,16,16)_(0,-1)        0.00011599  0.00012493  -7.71%
    gpu_(10,10,16,16)_(2,2)         0.00011539  0.00011349  +1.65%
    gpu_(10,10,101,101)_(-1,-1)     0.00014699  0.00010252 +30.25%
    gpu_(10,10,101,101)_(-1,0)       0.0002141  0.00015497 +27.62%
    gpu_(10,10,101,101)_(0,-1)       0.0002017  0.00015843 +21.45%
    gpu_(10,10,101,101)_(2,2)       0.00018394  0.00015402 +16.27%
    gpu_(10,10,256,256)_(-1,-1)     0.00032747  9.0003e-05 +72.52%
    gpu_(10,10,256,256)_(-1,0)      0.00074494  0.00040746 +45.30%
    gpu_(10,10,256,256)_(0,-1)      0.00072503  0.00042391 +41.53%
    gpu_(10,10,256,256)_(2,2)       0.00061846  0.00038004 +38.55%
    gpu_(10,10,1000,1000)_(-1,-1)    0.0032645  0.00010896 +96.66%
    gpu_(10,10,1000,1000)_(-1,0)      0.007543   0.0038971 +48.34%
    gpu_(10,10,1000,1000)_(0,-1)      0.006058   0.0039405 +34.95%
    gpu_(10,10,1000,1000)_(2,2)       0.005198    0.003448 +33.67%
    gpu_(10,10,1024,1024)_(-1,-1)    0.0034155  9.1434e-05 +97.32%
    gpu_(10,10,1024,1024)_(-1,0)      0.007099    0.004158 +41.43%
    gpu_(10,10,1024,1024)_(0,-1)      0.006843    0.003849 +43.75%
    gpu_(10,10,1024,1024)_(2,2)       0.005506   0.0031376 +43.02%
    gpu_(10,10,2048,2048)_(-1,-1)     0.013119  0.00010097 +99.23%
    gpu_(10,10,2048,2048)_(-1,0)      0.028533    0.015175 +46.81%
    gpu_(10,10,2048,2048)_(0,-1)      0.028458    0.014926 +47.55%
    gpu_(10,10,2048,2048)_(2,2)       0.022175    0.011797 +46.80%
    
    PiperOrigin-RevId: 168849471
    
    * * dataset_ops.read_batch_features() now discards keys for keyed Dataset.
    * dataset_ops.read_batch_features() ignores unnecessary repeat() when num_repeat == 1.
    
    PiperOrigin-RevId: 168855155
    
    * Migrate TFGAN eval to opensource.
    
    PiperOrigin-RevId: 168855880
    
    * [XLA] Remove superfluous locking from xla::ComputationBuilder.
    
    The class is thread compatible, not thread-safe. It is illegal to call non-const methods of the class concurrently. So the mutex is pointless.
    
    Also mark a couple of accessors const.
    
    PiperOrigin-RevId: 168857132
    
    * Add ConvertGraphDefToXla to convert from GraphDef to xla::Computation.
    
    The main logic is simply refactored from tfcompile, with some minor cleanups
    along the way.
    
    PiperOrigin-RevId: 168857174
    
    * Bugfix to tf.contrib.seq2seq beam_search_ops: GPU edge case of seq_len == 0.
    
    PiperOrigin-RevId: 168862288
    
    * [tf.contrib.data] Add `batch_and_drop_remainder` transformation.
    
    This transformation, which is designed for use with `Dataset.apply()`,
    acts like the default of behavior of `tf.train.batch()`, which will
    truncate a finite input source if its number of elements is not an
    exact multiple of the batch size. A benefit of using this
    transformation is that it gives a statically known shape to the output
    elements, because they are all exactly `batch_size` in the 0th
    dimension.
    
    PiperOrigin-RevId: 168863148
    
    * Minor renaming from tfcompile.Config to tf2xla.Config in comments.
    
    PiperOrigin-RevId: 168863860
    
    * Certain ops don't need eager gradients to keep their inputs / outputs alive.
    
    PiperOrigin-RevId: 168864350
    
    * [XLA] Add S64 while loop test.
    
    PiperOrigin-RevId: 168865653
    
    * tfdbg: fix a bug in list_inputs and list_outputs
    
    wherein a tensor name like "x:1" fails to be processed because it were not converted to the node name ("x" in this example) first.
    
    Also simplify analyzer_cli_test.py a little through a new helper function.
    
    PiperOrigin-RevId: 168867948
    
    * Adds multi_label_head in tf.contrib.estimator
    
    PiperOrigin-RevId: 168873313
    
    * Script that generates __init__.py files based on tf_api_names annotations.
    
    PiperOrigin-RevId: 168878737
    
    * Fixing the build command.
    
    PiperOrigin-RevId: 168881605
    
    * Make sure all checked threads are joined before they are terminated.
    
    PiperOrigin-RevId: 168884294
    
    * Output metrics in train mode for multihead.
    
    This is to be consistent with other heads who output the metric tensors in train mode. Outputting the metric tensors allow us for example to plot the metrics on the training set (and compare them to the metircs on the eval set).
    
    PiperOrigin-RevId: 168884726
    
    * Automated g4 rollback of changelist 168458634
    
    PiperOrigin-RevId: 168887778
    
    * Adds DNNEstimator to tf.contrib.estimator.
    
    PiperOrigin-RevId: 168887825
    
    * [tf.contrib.data] Expose `tf.contrib.data.batch_and_drop_remainder()`.
    
    PiperOrigin-RevId: 168888592
    
    * disabling timeout test in opensource build
    
    PiperOrigin-RevId: 168890483
    
    * Add ops that perform color transforms (including changing value, saturation and hue) in YIQ space.
    
    PiperOrigin-RevId: 168897736
    
    * Update the minimum requirement of espsilon for batch norm.
    
    PiperOrigin-RevId: 168897907
    
    * Adding support for capture-by-value.
    
    PiperOrigin-RevId: 168903482
    
    * disabling failing tsan test
    
    PiperOrigin-RevId: 168903876
    
    * disable asan for test timeout
    
    PiperOrigin-RevId: 168903999
    
    * Internal change.
    
    PiperOrigin-RevId: 168910187
    
    * Fix broken test: tensorflow/contrib/eager/python:datasets_test
    
    PiperOrigin-RevId: 168914742
    
    * [XLA:CPU] Implement map fusion.
    
    PiperOrigin-RevId: 168915358
    
    * Merge changes from github.
    END_PUBLIC
    
    I also integrated #13073 by hand to make TAP happy.
    
    ---
    Commit 92362d0f0 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add WhileContext class and add plumbing for creating them.
    
    This change introduces WhileContext, which stores information about a
    while loop and will be used in future changes to generate while loop
    gradient graphs. Exit nodes in a while loop now have a pointer to
    their associated WhileContext. This will be used to retrieve the
    context for a given loop.
    
    This change adds an optional parameter to BuildWhileLoop() to create a
    WhileContext for the while loop (currently this is always true, but
    gradients will generate while loops without associated contexts). This
    change also adds a as-yet-unused option to BuildWhileLoop() to return
    the predicate output.
    
    PiperOrigin-RevId: 168562303
    
    ---
    Commit a4f6e7c1a authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add mel-scale conversion matrix support to tf.contrib.signal.
    
    PiperOrigin-RevId: 168560255
    
    ---
    Commit b00b6d23c authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a segmentation fault caused by invalid log directory in InternalFlush().
    
    PiperOrigin-RevId: 168557063
    
    ---
    Commit 2bc7a155a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    Add uint16 support for tf.decode_raw (#12719)
    
    * Add uint16 support for tf.decode_raw
    
    This fix tries to address the request raised in 10124 where
    uint16 support for tf.decode_raw is needed. tf.decode_raw
    already support half, float32, float64, int8, int16, int32, int64,
    uint8. And uint16 was not supported.
    
    This fix adds uint16 support for tf.decode_raw.
    
    This fix fixes 10124.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failure caused by uint16 support of decode_raw and add unit tests.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 009285c09 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove benchmark for TensorShapeOld.
    
    PiperOrigin-RevId: 168551108
    
    ---
    Commit dc1eda8a6 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix CHECK-failure crash if a non-tuple was passed to GetTupleElement.
    
    PiperOrigin-RevId: 168550703
    
    ---
    Commit 010922ed9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168549989
    
    ---
    Commit c8a6131e9 authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    make `tf.sets` examples executable
    
    Fixes #12969
    
    PiperOrigin-RevId: 168549712
    
    ---
    Commit bece65c6f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use a map instead of a vector of Children() in the BeamEntry.
    
    The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.
    
    PiperOrigin-RevId: 168548814
    
    ---
    Commit 0d5ab82ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168548642
    
    ---
    Commit 3331c574b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implementing gradients for tf.image.resize_bicubic.
    
    PiperOrigin-RevId: 168547412
    
    ---
    Commit 4982ef0fa authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add the ability to warn only once if deprecated functionality is used, and make that the default.
    
    PiperOrigin-RevId: 168545655
    
    ---
    Commit 99423416a authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make shape inference error messages for the While HLO more readable. Build the error lazily.
    
    PiperOrigin-RevId: 168531083
    
    ---
    Commit d10374e45 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Discard some unneccessary logging commands.
    
    PiperOrigin-RevId: 168500721
    
    ---
    Commit 83cbabb85 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix wrong format of logging message.
    
    PiperOrigin-RevId: 168497373
    
    ---
    Commit eec4f1b3a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168494944
    
    ---
    Commit 69301f352 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168494220
    
    ---
    Commit 9d56f419c authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add crop_and_decode_jpeg_op that combines the crop and decode for better
    performance.
    
    PiperOrigin-RevId: 168493125
    
    ---
    Commit 48ddf64d0 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make large params test only run in opt builds.
    
    PiperOrigin-RevId: 168491913
    
    ---
    Commit 11d3ac29d authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for large numbers of parameter / return values and while loops.
    
    PiperOrigin-RevId: 168487225
    
    ---
    Commit 3cd6bdef5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added test cases on R4 slice.
    
    PiperOrigin-RevId: 168482049
    
    ---
    Commit 46a81b5c3 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add cast S64 to F32 test.
    
    PiperOrigin-RevId: 168473650
    
    ---
    Commit 59bdf598d authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add an automatically-generated "tensorflow.python.platform.build_info" script.
    
    The motivation for this script is to provide better tools for
    diagnosing load-time errors (such as the ones that plague the Windows
    build due to DLL issues). Note that the script is intended to be
    self-contained, so that it is possible to import it without loading
    the entire TensorFlow runtime.
    
    This generated script currently contains a single symbol,
    `is_cuda_build`, which records whether the build has GPU support or not.
    
    PiperOrigin-RevId: 168471034
    
    ---
    Commit c3b86347f authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling tests that are passing
    
    PiperOrigin-RevId: 168466361
    
    ---
    Commit c728665ec authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168465926
    
    ---
    Commit bf96fcd13 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use the scalar cache in MeanGrad.
    
    PiperOrigin-RevId: 168462267
    
    ---
    Commit 1cada9ea2 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling test that passed after 100 runs w/o timing out
    
    PiperOrigin-RevId: 168458634
    
    ---
    Commit 00c865566 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Generate error (instead of segfault) when trying to copy string tensor
    to GPU in EagerTensor constructor.
    
    PiperOrigin-RevId: 168457320
    
    ---
    Commit 655f26fc7 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resurrects autograd-free eager gradients.
    
    PiperOrigin-RevId: 168448557
    
    ---
    Commit 8f37f3002 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Cleanups to handling of arguments during XLA compilation:
    * combine resource kinds in XlaCompiler::Argument::Kind, use a separate XlaResource::Kind field to distinguish different kinds of resource.
    * merge XlaContext::HandleOrConstant and XlaExpression, which were almost identical.
    * remove XlaContext::Argument; instead, build XlaExpressions directly from XlaCompiler and add them to the XlaContext.
    
    PiperOrigin-RevId: 168439341
    
    ---
    Commit 7f5346a80 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168432070
    
    ---
    Commit 2ad85aa4d authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use xla/tests:xla_internal_test_main for all tests under tf/compiler/xla
    and remove any main() definitions in tests. This enables use of flags
    in all tests.
    
    PiperOrigin-RevId: 168424796
    
    ---
    Commit cd377811d authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Comment and error message consistency cleanup.
    
    PiperOrigin-RevId: 168422582
    
    ---
    Commit 7c19b82af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf.sparse_reset_shape so that when shrinking the shape of an empty
    sparse tensor, the result has a shape of all zeros.
    
    PiperOrigin-RevId: 168419639
    
    ---
    Commit fcacb40d4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    FirstReadyManager for scheduling nodes in VirtualScheduler.
    The current FIFOManager may yield inefficient scheduling; _Recv pushed to the
    FIFO blocks other nodes that can run before _Recv due to the node order in FIFO.
    FirstReadyManager picks a node with the earliest time_ready in the queue,
    avoiding this problem.
    
    Also, fixed VirtualPlacer to properly set device when Node's device name does not
    include job name and to set GPU:0 as default device.
    
    PiperOrigin-RevId: 168418455
    
    ---
    Commit 7e47624f5 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Initial support for iteration over tf.contrib.data.Dataset objects.
    
    TODO:
    - Support function-valued operation attributes in eager
      (Required for MapDataset, FilterDataset etc. which encode the
      per-element computation in a TensorFlow function)
    PiperOrigin-RevId: 168418250
    
    ---
    Commit b0a397fce authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Remove unnecessary TFE_Context argument to TFE_OpSetDevice.
    
    PiperOrigin-RevId: 168417999
    
    ---
    Commit 86211d554 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Graph transform to flatten atrous (dilated) convolutions (i.e., a sequence of SpaceToBatchND-Conv-BatchToSpaceND ops) to a regular Conv op with upsampled filters.
    
    PiperOrigin-RevId: 168414124
    
    ---
    Commit 3438981ca authored by David G. Andersen<dga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Apply exported symbol filtering to the c++ API analogously to
    what is filtered for the C API.
    Fixes bug reported in comments on #1924
    
    PiperOrigin-RevId: 168413719
    
    ---
    Commit 7e023d865 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] Remove code from parallel CPU backend outlining that was causing unnecessary copies to be inserted, and which is no longer necessary since we added co-located buffer support for kCall.
    *) All bitcast copy is no longer necessary as CopyInsertion will insert copies
    at the root of the computation for a parameter which is live-out.
    *) Copy if root does not define buffer no longer necessary because colocated
    assignment looks at points-to set of root instruction.
    
    PiperOrigin-RevId: 168412076
    
    ---
    Commit 5da4df92c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify some code in grappler_item_builder.cc, no change in logic.
    
    PiperOrigin-RevId: 168409110
    
    ---
    Commit 82ec6241a authored by drpngx<drpngx@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Add six and numpy imports
    ---
    Commit 9c4ce2452 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag parsing to more tests in xla/service specifically those which build
    HLO graphs. This enables, for example, dumping of the graphs with
    --xla_generate_hlo_graph. Also remove some superfluous tensorflow test_main
    dependencies.
    
    PiperOrigin-RevId: 168406746
    
    ---
    Commit d4efa695c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Relax the feed_nodes collection check, which triggers a false positive in some modes where the feed node collection is auto-generated. Keep it as a warning to help correct user-provided feed node lists.
    
    PiperOrigin-RevId: 168396408
    
    ---
    Commit cbc46a856 authored by Changming Sun<chasun@microsoft.com>
    Committed by gunan<gunan@google.com>:
    Add a missing template explicit instantiation of SetZeroFunctor (#12791)
    
    ---
    Commit 7bb08f5bf authored by Kevin Slagle<kjslag@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    fix ExponentialMovingAverage documentation so that ExponentialMovingAverage.apply is evaluated within control_dependencies (#12987)
    
    ---
    Commit e6b011763 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extend c++ gradient_checker to complex types.
    
    PiperOrigin-RevId: 168392949
    
    ---
    Commit 4086219a4 authored by Lyndon White<oxinabox@ucc.asn.au>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Correct minor typo in substr docs example (#12991)
    
    ---
    Commit f63aa7f49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate core TFGAN functions to opensource.
    
    PiperOrigin-RevId: 168391923
    
    ---
    Commit bc6b60f1b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix tuple_losses bug caused by Python bug.
    
    PiperOrigin-RevId: 168386341
    
    ---
    Commit 7a8c63da3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate `leaky_relu` to `nn_ops.py`. Will be used for TFGAN.
    
    PiperOrigin-RevId: 168386268
    
    ---
    Commit f7ba16fdf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Do not export from eval on train data steps.
    
    PiperOrigin-RevId: 168374021
    
    ---
    Commit 9b9e54b34 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding NCCL sum op, register all_sum gradient.
    Streamlining nccl test.
    
    PiperOrigin-RevId: 168347428
    
    ---
    Commit bc300318e authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update gemmlowp hash as the commit history seems to have changed in the
    repository.
    
    PiperOrigin-RevId: 168343607
    
    ---
    Commit 1e96d54d9 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Also accept non-k8 CPU types in build pip package. (#12975)
    
    * Also accept non-k8 CPU types in build pip package.
    Fixes #12735
    
    * Make the script work with `set -e`.
    
    ---
    Commit c0a4c7ffc authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix bug in ShapeUtil::ShapeIs that would lead to type inference errors.
    
    PiperOrigin-RevId: 168323589
    
    ---
    Commit 4af9be964 authored by Amy<amy@infosleuth.net>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    support passing in a source url to the mnist read_data_sets function, to make it easier to use 'fashion mnist' etc. (#12983)
    
    ---
    Commit 9f848734f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Tweak layer a bit to be eager friendly.
    
    PiperOrigin-RevId: 168312865
    
    ---
    Commit 60f15462b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change conv_input_scale and side_input_scale from attributes to inputs for improved flexibility, in fused_conv2d_bias_activation op.
    
    PiperOrigin-RevId: 168311988
    
    ---
    Commit 4b4e10f9c authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds dict support of eval metrics.
    
    PiperOrigin-RevId: 168310444
    
    ---
    Commit ab7f22de6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Move FusedConvBiasActivationShape out of common_shape_fns.cc to a lambda inside the op.
    
    PiperOrigin-RevId: 168300911
    
    ---
    Commit 3a98035fa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Augment metadata output with source-line info, as before.
    
    PiperOrigin-RevId: 168292527
    
    ---
    Commit 349188152 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enable fused batch norm, which is 15-20% faster for training and inference.
    
    PiperOrigin-RevId: 168288154
    
    ---
    Commit 08587d45b authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added back persistent memory tracking in queue op. The new tracking logic has avoided the crash in previous implementation:  the queue_ passed to CreateTypedQueue may be unreffed if the resource is already created by another resource op that shares the same resource name and type.
    
    PiperOrigin-RevId: 168284509
    
    ---
    Commit 733063d55 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Fixing awkward wording.
    
    ---
    Commit c7ad6bfef authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Removing accidental hash.
    
    ---
    Commit 53dbc761a authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Adding Windows self check script to docs.
    
    ---
    Commit ed1135994 authored by Andrew Harp<andrewharp@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add -latomic flag to benchmark_model target to fix Android x86 build.
    
    PiperOrigin-RevId: 168281337
    
    ---
    Commit c0348bb55 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf_export.py to take constant name as an argument instead of a constant.
    
    PiperOrigin-RevId: 168280613
    
    ---
    Commit c3d19e40a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup training_ops to reduce code redudancy.
    
    PiperOrigin-RevId: 168280069
    
    ---
    Commit 123fb01ee authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set fused=False for batch norm, because the test assumes no bessel's
    correction. Fused=True would add bessel's correction to variance.
    
    PiperOrigin-RevId: 168274392
    
    ---
    Commit f0e8c545e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch resource variables from copy-on-read to copy-on-write.
    
    RELNOTES: Change the signature of (C++) GetInputTensorFromVariable in
    training_op_helpers to support new copy-on-write semenatics of resource
    variables.
    PiperOrigin-RevId: 168273249
    
    ---
    Commit 495cc8e47 authored by Yuan (Terry) Tang<terrytangyuan@users.noreply.github.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Minor wording change in timeseries module's README (#12938)
    
    * Minor wording change in timeseries module's README
    
    * Address comments
    
    ---
    Commit f13b876ed authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Making the default build from source version 1.4.0dev. The whl files that are built will be 1.3.0devDDMMYYYY.
    
    ---
    Commit 2356c0ff4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete ScopedTFStatus to avoid leaking it for long running trainers(1+day).
    
    PiperOrigin-RevId: 168259652
    
    ---
    Commit e15f4cae2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't remove all aliases from linalg namespace.
    Get rid of redundant aliases.
    
    PiperOrigin-RevId: 168257658
    
    ---
    Commit c58082642 authored by postBG<profile2697@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Fix minor typo in Programmers guide (#12965)
    
    * Fix minor typo in Programmers guide
    
    * change to "this"
    
    ---
    Commit 509372c2e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a lot of operations' flops calculations
    
    PiperOrigin-RevId: 168256746
    
    ---
    Commit 80ed8afc0 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Flatten to core layers.
    
    PiperOrigin-RevId: 168254118
    
    ---
    Commit a6223c01a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix locking of variables in SparseProximalGradientDescent,
    AdagradDA, SparseAdagradDA.
    
    PiperOrigin-RevId: 168252530
    
    ---
    Commit abde00830 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    adding InputTensor class for symmetry with OutputTensor
    
    PiperOrigin-RevId: 168250085
    
    ---
    Commit 0451032ca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix variable naming style guide violation.
    
    PiperOrigin-RevId: 168245542
    
    ---
    Commit a202a5a94 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168245371
    
    ---
    Commit f93e354cb authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Switch backend Dataset representation to DT_VARIANT.
    
    This change introduces a new `DatasetWrapper` type that wraps a
    `DatasetBase*` and can be stored in a DT_VARIANT tensor. All Dataset
    ops now consume and produce DT_VARIANT instead of DT_RESOURCE, and the
    underlying implementation is simplified because the `DatasetWrapper`
    can be passed directly by value without using the `ResourceMgr`.
    
    PiperOrigin-RevId: 168240571
    
    ---
    Commit a4042cd2a authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces the placeholder for _TrainingExecutor, which serves the implementation of tf.estimator.train_and_evaluate.
    
    PiperOrigin-RevId: 168240151
    
    ---
    Commit 10ba148f7 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch control_flow_ops library to use Resource variants of Stack operators, instead of deprecated Ref variants.
    
    PiperOrigin-RevId: 168234822
    
    ---
    Commit ca43fe82b authored by Ali Yahya<alive@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Improves the interfaces of tape.watch_variable() and implicit_grad().
    
    tape.watch_variable() replaces tape.watch() and now is called on ResourceVariable objects instead of their underlying handles.
    
    implicit_grad() now returns a list of (gradient, variable) pairs to be consistent with tf.Optimizer's interface.
    
    PiperOrigin-RevId: 168232055
    
    ---
    Commit b72862dfc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change
    
    PiperOrigin-RevId: 168225993
    
    ---
    Commit da3280f4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable tsan for sdca_estimator_test.
    
    PiperOrigin-RevId: 168186374
    
    ---
    Commit c936c1155 authored by Yifei Feng<yifeif@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests for contrib/gan.
    - Add *_impl.py so tests can still access removed symbols.
    - Add /python directory layer to make *_impy.py and __init__.py not in the same dir.
    
    PiperOrigin-RevId: 168161722
    
    ---
    Commit ce9a2b00f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance guide update
    
    PiperOrigin-RevId: 168159289
    
    ---
    Commit 3bce4f9a0 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: expose tfe.num_gpus()
    
    PiperOrigin-RevId: 168154345
    
    ---
    Commit 67a7cbc28 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Changed the default eval throttle secs from 2 min to 10 mins.
    
    PiperOrigin-RevId: 168120323
    
    ---
    Commit 92bed178f authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168119914
    
    ---
    Commit 702d59582 authored by joshkyh<joshkyh@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Corrected hyperlink for audio training tutorial (#12923)
    
    ---
    Commit 877c9deca authored by Frank Chen<frankchn@gmail.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Reverse change eb75ded6 so that internal tests will pass. (#12933)
    
    As support for int64 global steps is not ready in TPUs, I am reversing this change so that our internal performance and regression tests will pass.
    ---
    Commit 665966438 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable grpc_session_test.
    
    PiperOrigin-RevId: 168078694
    
    ---
    Commit 405def792 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Switch CallInliner to use CallGraph::VisitNodes.
    
    PiperOrigin-RevId: 168078645
    
    ---
    Commit aba3466f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Exposes Head and factory methods in tf.contrib.estimator.
    
    PiperOrigin-RevId: 168071246
    
    ---
    Commit b76565b39 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Some profiler fixes and cleanup.
    
    PiperOrigin-RevId: 168069346
    
    ---
    Commit 32ffc5a81 authored by Jonas<sauercrowd@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Just a dot in order to be consistent (#12919)
    
    added a dot to the `7` to make clear it's a float (like every other number)
    ---
    Commit 0753b0c79 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Scope the scalar cache in the context.
    
    PiperOrigin-RevId: 168065417
    
    ---
    Commit 48deb206b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate TFGAN features to third_party.
    
    PiperOrigin-RevId: 168060880
    
    ---
    Commit d2ae1311f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing an issue in the BUILD file of the LSH ops.
    
    PiperOrigin-RevId: 168056645
    
    ---
    Commit 2f440eda4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose NumpyReader for reading timeseries data.
    
    PiperOrigin-RevId: 168055838
    
    ---
    Commit be1916ce7 authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added functionality to allow `SqlDataset` to interpret a database column as various numeric types, including several integer types and `dtypes.float64`.
    
    PiperOrigin-RevId: 168055827
    
    ---
    Commit fa2000a0b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Supporting nightly windows pip packages.
    
    PiperOrigin-RevId: 168054959
    
    ---
    Commit a263ea626 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Treat eager tensors as constants during graph construction.
    
    Unless capturing is explicitly enabled.
    
    PiperOrigin-RevId: 168052675
    
    ---
    Commit 6e402d0d2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make TODO a bit more specific.
    
    PiperOrigin-RevId: 168051381
    
    ---
    Commit c779384bc authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added code example to the doc string for `SqlDataset`.
    
    PiperOrigin-RevId: 168049037
    
    ---
    Commit ff6dd474a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use self._in_graph_mode consistently in ResourceVariable
    instead of sometimes getting it from the context.
    
    Also: fix formatting of a comment and use a more precise test to detect
    if initial_value is set.
    PiperOrigin-RevId: 168047258
    
    ---
    Commit f331f528b authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes "fast paths" which are not fast in eager mode.
    
    PiperOrigin-RevId: 168046278
    
    ---
    Commit 86f1713e5 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces TrainSpec and EvalSpec.
    
    PiperOrigin-RevId: 168040435
    
    ---
    Commit c8b9e92f0 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Move "register_function" to context.py
    
    This will allow function registration from other
    modules without having to import "function.py".
    (And besides, the function really does belong on the context).
    
    PiperOrigin-RevId: 168040411
    
    ---
    Commit 74137f994 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix signed int overflow issue in tensor_id.cc
    
    When a node name has a long numeric suffix, e.g.,
    "foo/y_0/gradient_debug_09684b60f2184c67b744721915034528" (as has happened with tfdbg GradientsDebugger),
    
    the parsing algorithm in ParseTensorName() may experience signed int overflow. Replacing the types with "unsigned int" resolves the issue.
    
    PiperOrigin-RevId: 168039195
    
    ---
    Commit 450c3b562 authored by Rohan Jain<rohanj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Using rendezvous manager to pass args / rets between devices during function remote execution. This enables CPU->GPU remote device executions now.
    
    PiperOrigin-RevId: 168038285
    
    ---
    Commit 82cc6529f authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes the wording about StopIteration.
    
    PiperOrigin-RevId: 168034451
    
    ---
    Commit fb5588002 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a statement on install/index.md on what os are supported.
    
    PiperOrigin-RevId: 168032996
    
    ---
    Commit f83f6b9ef authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Handle higher-order HLOs (e.g. While) in CallInliner and test.
    
    PiperOrigin-RevId: 168029345
    
    ---
    Commit 8988ae365 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 167916124
    
    PiperOrigin-RevId: 168916710
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168917157
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168917534

commit a373b1f74215e44920bf9362a51bece530edf88a
Author: Patrick Nguyen <drpng@google.com>
Date:   Fri Sep 15 18:14:40 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    I also integrated #13073 by hand to make TAP happy.
    
    ---
    Commit 92362d0f0 authored by Skye Wanderman-Milne<skyewm@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add WhileContext class and add plumbing for creating them.
    
    This change introduces WhileContext, which stores information about a
    while loop and will be used in future changes to generate while loop
    gradient graphs. Exit nodes in a while loop now have a pointer to
    their associated WhileContext. This will be used to retrieve the
    context for a given loop.
    
    This change adds an optional parameter to BuildWhileLoop() to create a
    WhileContext for the while loop (currently this is always true, but
    gradients will generate while loops without associated contexts). This
    change also adds a as-yet-unused option to BuildWhileLoop() to return
    the predicate output.
    
    PiperOrigin-RevId: 168562303
    
    ---
    Commit a4f6e7c1a authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add mel-scale conversion matrix support to tf.contrib.signal.
    
    PiperOrigin-RevId: 168560255
    
    ---
    Commit b00b6d23c authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a segmentation fault caused by invalid log directory in InternalFlush().
    
    PiperOrigin-RevId: 168557063
    
    ---
    Commit 2bc7a155a authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    Add uint16 support for tf.decode_raw (#12719)
    
    * Add uint16 support for tf.decode_raw
    
    This fix tries to address the request raised in 10124 where
    uint16 support for tf.decode_raw is needed. tf.decode_raw
    already support half, float32, float64, int8, int16, int32, int64,
    uint8. And uint16 was not supported.
    
    This fix adds uint16 support for tf.decode_raw.
    
    This fix fixes 10124.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    * Fix test failure caused by uint16 support of decode_raw and add unit tests.
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 009285c09 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove benchmark for TensorShapeOld.
    
    PiperOrigin-RevId: 168551108
    
    ---
    Commit dc1eda8a6 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix CHECK-failure crash if a non-tuple was passed to GetTupleElement.
    
    PiperOrigin-RevId: 168550703
    
    ---
    Commit 010922ed9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168549989
    
    ---
    Commit c8a6131e9 authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    make `tf.sets` examples executable
    
    Fixes #12969
    
    PiperOrigin-RevId: 168549712
    
    ---
    Commit bece65c6f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use a map instead of a vector of Children() in the BeamEntry.
    
    The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.
    
    PiperOrigin-RevId: 168548814
    
    ---
    Commit 0d5ab82ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168548642
    
    ---
    Commit 3331c574b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implementing gradients for tf.image.resize_bicubic.
    
    PiperOrigin-RevId: 168547412
    
    ---
    Commit 4982ef0fa authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add the ability to warn only once if deprecated functionality is used, and make that the default.
    
    PiperOrigin-RevId: 168545655
    
    ---
    Commit 99423416a authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make shape inference error messages for the While HLO more readable. Build the error lazily.
    
    PiperOrigin-RevId: 168531083
    
    ---
    Commit d10374e45 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Discard some unneccessary logging commands.
    
    PiperOrigin-RevId: 168500721
    
    ---
    Commit 83cbabb85 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix wrong format of logging message.
    
    PiperOrigin-RevId: 168497373
    
    ---
    Commit eec4f1b3a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 168494944
    
    ---
    Commit 69301f352 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168494220
    
    ---
    Commit 9d56f419c authored by Mingxing Tan<tanmingxing@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add crop_and_decode_jpeg_op that combines the crop and decode for better
    performance.
    
    PiperOrigin-RevId: 168493125
    
    ---
    Commit 48ddf64d0 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Make large params test only run in opt builds.
    
    PiperOrigin-RevId: 168491913
    
    ---
    Commit 11d3ac29d authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for large numbers of parameter / return values and while loops.
    
    PiperOrigin-RevId: 168487225
    
    ---
    Commit 3cd6bdef5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added test cases on R4 slice.
    
    PiperOrigin-RevId: 168482049
    
    ---
    Commit 46a81b5c3 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add cast S64 to F32 test.
    
    PiperOrigin-RevId: 168473650
    
    ---
    Commit 59bdf598d authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add an automatically-generated "tensorflow.python.platform.build_info" script.
    
    The motivation for this script is to provide better tools for
    diagnosing load-time errors (such as the ones that plague the Windows
    build due to DLL issues). Note that the script is intended to be
    self-contained, so that it is possible to import it without loading
    the entire TensorFlow runtime.
    
    This generated script currently contains a single symbol,
    `is_cuda_build`, which records whether the build has GPU support or not.
    
    PiperOrigin-RevId: 168471034
    
    ---
    Commit c3b86347f authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling tests that are passing
    
    PiperOrigin-RevId: 168466361
    
    ---
    Commit c728665ec authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add const qualifiers whenever appropriate.
    
    PiperOrigin-RevId: 168465926
    
    ---
    Commit bf96fcd13 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use the scalar cache in MeanGrad.
    
    PiperOrigin-RevId: 168462267
    
    ---
    Commit 1cada9ea2 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    reenabling test that passed after 100 runs w/o timing out
    
    PiperOrigin-RevId: 168458634
    
    ---
    Commit 00c865566 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Generate error (instead of segfault) when trying to copy string tensor
    to GPU in EagerTensor constructor.
    
    PiperOrigin-RevId: 168457320
    
    ---
    Commit 655f26fc7 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resurrects autograd-free eager gradients.
    
    PiperOrigin-RevId: 168448557
    
    ---
    Commit 8f37f3002 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Cleanups to handling of arguments during XLA compilation:
    * combine resource kinds in XlaCompiler::Argument::Kind, use a separate XlaResource::Kind field to distinguish different kinds of resource.
    * merge XlaContext::HandleOrConstant and XlaExpression, which were almost identical.
    * remove XlaContext::Argument; instead, build XlaExpressions directly from XlaCompiler and add them to the XlaContext.
    
    PiperOrigin-RevId: 168439341
    
    ---
    Commit 7f5346a80 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168432070
    
    ---
    Commit 2ad85aa4d authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use xla/tests:xla_internal_test_main for all tests under tf/compiler/xla
    and remove any main() definitions in tests. This enables use of flags
    in all tests.
    
    PiperOrigin-RevId: 168424796
    
    ---
    Commit cd377811d authored by Henry Tan<henrytan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Comment and error message consistency cleanup.
    
    PiperOrigin-RevId: 168422582
    
    ---
    Commit 7c19b82af authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf.sparse_reset_shape so that when shrinking the shape of an empty
    sparse tensor, the result has a shape of all zeros.
    
    PiperOrigin-RevId: 168419639
    
    ---
    Commit fcacb40d4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    FirstReadyManager for scheduling nodes in VirtualScheduler.
    The current FIFOManager may yield inefficient scheduling; _Recv pushed to the
    FIFO blocks other nodes that can run before _Recv due to the node order in FIFO.
    FirstReadyManager picks a node with the earliest time_ready in the queue,
    avoiding this problem.
    
    Also, fixed VirtualPlacer to properly set device when Node's device name does not
    include job name and to set GPU:0 as default device.
    
    PiperOrigin-RevId: 168418455
    
    ---
    Commit 7e47624f5 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Initial support for iteration over tf.contrib.data.Dataset objects.
    
    TODO:
    - Support function-valued operation attributes in eager
      (Required for MapDataset, FilterDataset etc. which encode the
      per-element computation in a TensorFlow function)
    PiperOrigin-RevId: 168418250
    
    ---
    Commit b0a397fce authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Remove unnecessary TFE_Context argument to TFE_OpSetDevice.
    
    PiperOrigin-RevId: 168417999
    
    ---
    Commit 86211d554 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Graph transform to flatten atrous (dilated) convolutions (i.e., a sequence of SpaceToBatchND-Conv-BatchToSpaceND ops) to a regular Conv op with upsampled filters.
    
    PiperOrigin-RevId: 168414124
    
    ---
    Commit 3438981ca authored by David G. Andersen<dga@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Apply exported symbol filtering to the c++ API analogously to
    what is filtered for the C API.
    Fixes bug reported in comments on #1924
    
    PiperOrigin-RevId: 168413719
    
    ---
    Commit 7e023d865 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA:CPU] Remove code from parallel CPU backend outlining that was causing unnecessary copies to be inserted, and which is no longer necessary since we added co-located buffer support for kCall.
    *) All bitcast copy is no longer necessary as CopyInsertion will insert copies
    at the root of the computation for a parameter which is live-out.
    *) Copy if root does not define buffer no longer necessary because colocated
    assignment looks at points-to set of root instruction.
    
    PiperOrigin-RevId: 168412076
    
    ---
    Commit 5da4df92c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify some code in grappler_item_builder.cc, no change in logic.
    
    PiperOrigin-RevId: 168409110
    
    ---
    Commit 82ec6241a authored by drpngx<drpngx@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Add six and numpy imports
    ---
    Commit 9c4ce2452 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag parsing to more tests in xla/service specifically those which build
    HLO graphs. This enables, for example, dumping of the graphs with
    --xla_generate_hlo_graph. Also remove some superfluous tensorflow test_main
    dependencies.
    
    PiperOrigin-RevId: 168406746
    
    ---
    Commit d4efa695c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Relax the feed_nodes collection check, which triggers a false positive in some modes where the feed node collection is auto-generated. Keep it as a warning to help correct user-provided feed node lists.
    
    PiperOrigin-RevId: 168396408
    
    ---
    Commit cbc46a856 authored by Changming Sun<chasun@microsoft.com>
    Committed by gunan<gunan@google.com>:
    Add a missing template explicit instantiation of SetZeroFunctor (#12791)
    
    ---
    Commit 7bb08f5bf authored by Kevin Slagle<kjslag@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    fix ExponentialMovingAverage documentation so that ExponentialMovingAverage.apply is evaluated within control_dependencies (#12987)
    
    ---
    Commit e6b011763 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extend c++ gradient_checker to complex types.
    
    PiperOrigin-RevId: 168392949
    
    ---
    Commit 4086219a4 authored by Lyndon White<oxinabox@ucc.asn.au>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Correct minor typo in substr docs example (#12991)
    
    ---
    Commit f63aa7f49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate core TFGAN functions to opensource.
    
    PiperOrigin-RevId: 168391923
    
    ---
    Commit bc6b60f1b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix tuple_losses bug caused by Python bug.
    
    PiperOrigin-RevId: 168386341
    
    ---
    Commit 7a8c63da3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate `leaky_relu` to `nn_ops.py`. Will be used for TFGAN.
    
    PiperOrigin-RevId: 168386268
    
    ---
    Commit f7ba16fdf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Do not export from eval on train data steps.
    
    PiperOrigin-RevId: 168374021
    
    ---
    Commit 9b9e54b34 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding NCCL sum op, register all_sum gradient.
    Streamlining nccl test.
    
    PiperOrigin-RevId: 168347428
    
    ---
    Commit bc300318e authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update gemmlowp hash as the commit history seems to have changed in the
    repository.
    
    PiperOrigin-RevId: 168343607
    
    ---
    Commit 1e96d54d9 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Also accept non-k8 CPU types in build pip package. (#12975)
    
    * Also accept non-k8 CPU types in build pip package.
    Fixes #12735
    
    * Make the script work with `set -e`.
    
    ---
    Commit c0a4c7ffc authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix bug in ShapeUtil::ShapeIs that would lead to type inference errors.
    
    PiperOrigin-RevId: 168323589
    
    ---
    Commit 4af9be964 authored by Amy<amy@infosleuth.net>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    support passing in a source url to the mnist read_data_sets function, to make it easier to use 'fashion mnist' etc. (#12983)
    
    ---
    Commit 9f848734f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Tweak layer a bit to be eager friendly.
    
    PiperOrigin-RevId: 168312865
    
    ---
    Commit 60f15462b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change conv_input_scale and side_input_scale from attributes to inputs for improved flexibility, in fused_conv2d_bias_activation op.
    
    PiperOrigin-RevId: 168311988
    
    ---
    Commit 4b4e10f9c authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds dict support of eval metrics.
    
    PiperOrigin-RevId: 168310444
    
    ---
    Commit ab7f22de6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Move FusedConvBiasActivationShape out of common_shape_fns.cc to a lambda inside the op.
    
    PiperOrigin-RevId: 168300911
    
    ---
    Commit 3a98035fa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Augment metadata output with source-line info, as before.
    
    PiperOrigin-RevId: 168292527
    
    ---
    Commit 349188152 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enable fused batch norm, which is 15-20% faster for training and inference.
    
    PiperOrigin-RevId: 168288154
    
    ---
    Commit 08587d45b authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added back persistent memory tracking in queue op. The new tracking logic has avoided the crash in previous implementation:  the queue_ passed to CreateTypedQueue may be unreffed if the resource is already created by another resource op that shares the same resource name and type.
    
    PiperOrigin-RevId: 168284509
    
    ---
    Commit 733063d55 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Fixing awkward wording.
    
    ---
    Commit c7ad6bfef authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Removing accidental hash.
    
    ---
    Commit 53dbc761a authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Adding Windows self check script to docs.
    
    ---
    Commit ed1135994 authored by Andrew Harp<andrewharp@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add -latomic flag to benchmark_model target to fix Android x86 build.
    
    PiperOrigin-RevId: 168281337
    
    ---
    Commit c0348bb55 authored by Anna R<annarev@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update tf_export.py to take constant name as an argument instead of a constant.
    
    PiperOrigin-RevId: 168280613
    
    ---
    Commit c3d19e40a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup training_ops to reduce code redudancy.
    
    PiperOrigin-RevId: 168280069
    
    ---
    Commit 123fb01ee authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set fused=False for batch norm, because the test assumes no bessel's
    correction. Fused=True would add bessel's correction to variance.
    
    PiperOrigin-RevId: 168274392
    
    ---
    Commit f0e8c545e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch resource variables from copy-on-read to copy-on-write.
    
    RELNOTES: Change the signature of (C++) GetInputTensorFromVariable in
    training_op_helpers to support new copy-on-write semenatics of resource
    variables.
    PiperOrigin-RevId: 168273249
    
    ---
    Commit 495cc8e47 authored by Yuan (Terry) Tang<terrytangyuan@users.noreply.github.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Minor wording change in timeseries module's README (#12938)
    
    * Minor wording change in timeseries module's README
    
    * Address comments
    
    ---
    Commit f13b876ed authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Making the default build from source version 1.4.0dev. The whl files that are built will be 1.3.0devDDMMYYYY.
    
    ---
    Commit 2356c0ff4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete ScopedTFStatus to avoid leaking it for long running trainers(1+day).
    
    PiperOrigin-RevId: 168259652
    
    ---
    Commit e15f4cae2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't remove all aliases from linalg namespace.
    Get rid of redundant aliases.
    
    PiperOrigin-RevId: 168257658
    
    ---
    Commit c58082642 authored by postBG<profile2697@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    Fix minor typo in Programmers guide (#12965)
    
    * Fix minor typo in Programmers guide
    
    * change to "this"
    
    ---
    Commit 509372c2e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a lot of operations' flops calculations
    
    PiperOrigin-RevId: 168256746
    
    ---
    Commit 80ed8afc0 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Flatten to core layers.
    
    PiperOrigin-RevId: 168254118
    
    ---
    Commit a6223c01a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix locking of variables in SparseProximalGradientDescent,
    AdagradDA, SparseAdagradDA.
    
    PiperOrigin-RevId: 168252530
    
    ---
    Commit abde00830 authored by Olivia Nordquist<nolivia@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    adding InputTensor class for symmetry with OutputTensor
    
    PiperOrigin-RevId: 168250085
    
    ---
    Commit 0451032ca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix variable naming style guide violation.
    
    PiperOrigin-RevId: 168245542
    
    ---
    Commit a202a5a94 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 168245371
    
    ---
    Commit f93e354cb authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Switch backend Dataset representation to DT_VARIANT.
    
    This change introduces a new `DatasetWrapper` type that wraps a
    `DatasetBase*` and can be stored in a DT_VARIANT tensor. All Dataset
    ops now consume and produce DT_VARIANT instead of DT_RESOURCE, and the
    underlying implementation is simplified because the `DatasetWrapper`
    can be passed directly by value without using the `ResourceMgr`.
    
    PiperOrigin-RevId: 168240571
    
    ---
    Commit a4042cd2a authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces the placeholder for _TrainingExecutor, which serves the implementation of tf.estimator.train_and_evaluate.
    
    PiperOrigin-RevId: 168240151
    
    ---
    Commit 10ba148f7 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch control_flow_ops library to use Resource variants of Stack operators, instead of deprecated Ref variants.
    
    PiperOrigin-RevId: 168234822
    
    ---
    Commit ca43fe82b authored by Ali Yahya<alive@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: Improves the interfaces of tape.watch_variable() and implicit_grad().
    
    tape.watch_variable() replaces tape.watch() and now is called on ResourceVariable objects instead of their underlying handles.
    
    implicit_grad() now returns a list of (gradient, variable) pairs to be consistent with tf.Optimizer's interface.
    
    PiperOrigin-RevId: 168232055
    
    ---
    Commit b72862dfc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    internal change
    
    PiperOrigin-RevId: 168225993
    
    ---
    Commit da3280f4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable tsan for sdca_estimator_test.
    
    PiperOrigin-RevId: 168186374
    
    ---
    Commit c936c1155 authored by Yifei Feng<yifeif@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests for contrib/gan.
    - Add *_impl.py so tests can still access removed symbols.
    - Add /python directory layer to make *_impy.py and __init__.py not in the same dir.
    
    PiperOrigin-RevId: 168161722
    
    ---
    Commit ce9a2b00f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance guide update
    
    PiperOrigin-RevId: 168159289
    
    ---
    Commit 3bce4f9a0 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    TFE: expose tfe.num_gpus()
    
    PiperOrigin-RevId: 168154345
    
    ---
    Commit 67a7cbc28 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Changed the default eval throttle secs from 2 min to 10 mins.
    
    PiperOrigin-RevId: 168120323
    
    ---
    Commit 92bed178f authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce cmake log mess.
    
    * Echo off for the .bat scripts.
    * TF cmake: disable warnings in some of the patched projects (gif,jpeg,lmdb).
    
    PiperOrigin-RevId: 168119914
    
    ---
    Commit 702d59582 authored by joshkyh<joshkyh@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Corrected hyperlink for audio training tutorial (#12923)
    
    ---
    Commit 877c9deca authored by Frank Chen<frankchn@gmail.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Reverse change eb75ded6 so that internal tests will pass. (#12933)
    
    As support for int64 global steps is not ready in TPUs, I am reversing this change so that our internal performance and regression tests will pass.
    ---
    Commit 665966438 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable grpc_session_test.
    
    PiperOrigin-RevId: 168078694
    
    ---
    Commit 405def792 authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Switch CallInliner to use CallGraph::VisitNodes.
    
    PiperOrigin-RevId: 168078645
    
    ---
    Commit aba3466f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Exposes Head and factory methods in tf.contrib.estimator.
    
    PiperOrigin-RevId: 168071246
    
    ---
    Commit b76565b39 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Some profiler fixes and cleanup.
    
    PiperOrigin-RevId: 168069346
    
    ---
    Commit 32ffc5a81 authored by Jonas<sauercrowd@users.noreply.github.com>
    Committed by Yifei Feng<fengyifei2026@gmail.com>:
    Just a dot in order to be consistent (#12919)
    
    added a dot to the `7` to make clear it's a float (like every other number)
    ---
    Commit 0753b0c79 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Scope the scalar cache in the context.
    
    PiperOrigin-RevId: 168065417
    
    ---
    Commit 48deb206b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Migrate TFGAN features to third_party.
    
    PiperOrigin-RevId: 168060880
    
    ---
    Commit d2ae1311f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing an issue in the BUILD file of the LSH ops.
    
    PiperOrigin-RevId: 168056645
    
    ---
    Commit 2f440eda4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose NumpyReader for reading timeseries data.
    
    PiperOrigin-RevId: 168055838
    
    ---
    Commit be1916ce7 authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added functionality to allow `SqlDataset` to interpret a database column as various numeric types, including several integer types and `dtypes.float64`.
    
    PiperOrigin-RevId: 168055827
    
    ---
    Commit fa2000a0b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Supporting nightly windows pip packages.
    
    PiperOrigin-RevId: 168054959
    
    ---
    Commit a263ea626 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Treat eager tensors as constants during graph construction.
    
    Unless capturing is explicitly enabled.
    
    PiperOrigin-RevId: 168052675
    
    ---
    Commit 6e402d0d2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make TODO a bit more specific.
    
    PiperOrigin-RevId: 168051381
    
    ---
    Commit c779384bc authored by Daniel Grazian<dgr@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added code example to the doc string for `SqlDataset`.
    
    PiperOrigin-RevId: 168049037
    
    ---
    Commit ff6dd474a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use self._in_graph_mode consistently in ResourceVariable
    instead of sometimes getting it from the context.
    
    Also: fix formatting of a comment and use a more precise test to detect
    if initial_value is set.
    PiperOrigin-RevId: 168047258
    
    ---
    Commit f331f528b authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes "fast paths" which are not fast in eager mode.
    
    PiperOrigin-RevId: 168046278
    
    ---
    Commit 86f1713e5 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduces TrainSpec and EvalSpec.
    
    PiperOrigin-RevId: 168040435
    
    ---
    Commit c8b9e92f0 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    eager: Move "register_function" to context.py
    
    This will allow function registration from other
    modules without having to import "function.py".
    (And besides, the function really does belong on the context).
    
    PiperOrigin-RevId: 168040411
    
    ---
    Commit 74137f994 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix signed int overflow issue in tensor_id.cc
    
    When a node name has a long numeric suffix, e.g.,
    "foo/y_0/gradient_debug_09684b60f2184c67b744721915034528" (as has happened with tfdbg GradientsDebugger),
    
    the parsing algorithm in ParseTensorName() may experience signed int overflow. Replacing the types with "unsigned int" resolves the issue.
    
    PiperOrigin-RevId: 168039195
    
    ---
    Commit 450c3b562 authored by Rohan Jain<rohanj@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Using rendezvous manager to pass args / rets between devices during function remote execution. This enables CPU->GPU remote device executions now.
    
    PiperOrigin-RevId: 168038285
    
    ---
    Commit 82cc6529f authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes the wording about StopIteration.
    
    PiperOrigin-RevId: 168034451
    
    ---
    Commit fb5588002 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a statement on install/index.md on what os are supported.
    
    PiperOrigin-RevId: 168032996
    
    ---
    Commit f83f6b9ef authored by Chris Leary<leary@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Handle higher-order HLOs (e.g. While) in CallInliner and test.
    
    PiperOrigin-RevId: 168029345
    
    ---
    Commit 8988ae365 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 167916124
    
    PiperOrigin-RevId: 168916710

commit dc1eda8a6d06cff541be768a0c8e2b22b376651c
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Sep 13 09:35:09 2017 -0700

    [XLA] Fix CHECK-failure crash if a non-tuple was passed to GetTupleElement.
    
    PiperOrigin-RevId: 168550703

commit 08587d45b4013101b8c91d4b66d8d403303966ae
Author: Yuefeng Zhou <yuefengz@google.com>
Date:   Mon Sep 11 14:21:15 2017 -0700

    Added back persistent memory tracking in queue op. The new tracking logic has avoided the crash in previous implementation:  the queue_ passed to CreateTypedQueue may be unreffed if the resource is already created by another resource op that shares the same resource name and type.
    
    PiperOrigin-RevId: 168284509

commit ca0743d4a4d8b24100a6a14a858d4b859c4e35c0
Author: Mahmoud Abuzaina <mahmoud.abuzaina@intel.com>
Date:   Thu Jul 27 14:06:03 2017 -0700

    Fixed a crash in conv-grad-input with NHWC format

commit 91617d22fc5868948a361e04a0642a765a092544
Author: David Majnemer <majnemer@google.com>
Date:   Thu Aug 31 14:45:25 2017 -0700

    [XLA] Dump nested fusion nodes without crashing
    
    PiperOrigin-RevId: 167194247

commit 78da113f02668bc000565773e1e1c8e180cb2fcf
Author: Benoit Steiner <bsteiner@google.com>
Date:   Mon Aug 28 10:56:26 2017 -0700

    Don't record persistent memory usage of typed queues since the code crashes when running on GPU.
    
    PiperOrigin-RevId: 166726596

commit eb0808fb95567c1f5b7ce48d29f47edfd988aff8
Author: Benoit Steiner <bsteiner@google.com>
Date:   Wed Aug 23 14:41:56 2017 -0700

    Converted LOG(FATAL) into regular errors to prevent the process from crashing
    on error.
    
    PiperOrigin-RevId: 166257105

commit 84138ef8bbb258ba5822808e19c54865f345cbef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 23 12:31:11 2017 -0700

    Fix crashes caused by loading boosted_trees shared libraries.
    
    PiperOrigin-RevId: 166238007

commit c33e667ec25e0e8bd6b759dc1360707ab3aae30b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Aug 15 23:10:53 2017 -0700

    Give an error instead of crashing when tfcompile is fed a tensor that is not
    needed for the fetch.
    
    PiperOrigin-RevId: 165404677

commit d2d25c3bdbe074147ef9923e7c2fe46082e3a225
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 9 12:56:49 2017 -0700

    Don't run contrib/timeseries/python/timeseries:state_management_test pip test until crash has been resolved.
    
    PiperOrigin-RevId: 164759761

commit 762c0e56c8d03f7f7f2902c725ef5057e6a53b44
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Aug 9 12:56:49 2017 -0700

    Don't run contrib/timeseries/python/timeseries:state_management_test pip test until crash has been resolved.
    
    PiperOrigin-RevId: 164759761

commit 2b7840722fd3ff0f36e053e170113d56ae9d68c4
Author: Benoit Steiner <bsteiner@google.com>
Date:   Wed Aug 9 10:19:18 2017 -0700

    Deleted the code that infers shapes of restores since it crashes
    
    PiperOrigin-RevId: 164739939

commit afe603348babf6f055d635e230e1494dd138df21
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Jul 18 15:42:11 2017 -0700

    Fix crash when OOM error occurs with verbose logging enabled
    
    PiperOrigin-RevId: 162414962

commit 8905db7881d9118b0267ac948092e56a63cd680e
Author: Pete Warden <petewarden@google.com>
Date:   Mon Jul 10 15:45:40 2017 -0700

    Fixed crash in graph summarization tool
    
    PiperOrigin-RevId: 161452440

commit 4e0f4e462f80e2dc84aa38da3fbc39cb15da3482
Author: Peter Hawkins <phawkins@google.com>
Date:   Fri Jul 7 06:00:28 2017 -0700

    [TF:XLA] Fix crash in graph_to_functiondef.cc if there was a control dependency onto a _Retval node.
    
    Move graph_to_functiondef_test into its own BUILD target.
    
    PiperOrigin-RevId: 161193674

commit 87d86dbbf4eadf1f7be414d1192cd5ef72db6026
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu Jul 6 13:20:29 2017 -0700

    [XLA] Fix crash in algebraic simplifier when sinking a reshape-to-scalar after an elementwise operation.
    
    The test case in the change previously failed with:
    algebraic_simplifier.cc:1091] Check failed: user->operand(reshape_or_broadcast_operand_index) == reshape_or_broadcast
    
    PiperOrigin-RevId: 161121259

commit c0f475b03eeca19b217527f7946da837e8438e27
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu Jul 6 08:56:32 2017 -0700

    [XLA] Add support for tuple constants via a rewrite that replaces constant tuples with tuples of non-tuple constants.
    
    Fix crash in HloInstruction::ToString() for tuple constants.
    
    PiperOrigin-RevId: 161085252

commit 4eb71a7f1aa01639a57b67413e7225fc26512ead
Author: Benoit Steiner <bsteiner@google.com>
Date:   Thu Jun 29 16:30:42 2017 -0700

    Don't crash when converting ill formed graphs to graph defs: this can happen
    with legacy fed inputs whose 2 inputs may remain unconnected.
    
    PiperOrigin-RevId: 160589677

commit cf7c008ab150ac8e5edb3ed053d38b2919699796
Author: Yifei Feng <fengyifei2026@gmail.com>
Date:   Wed Jun 28 11:07:44 2017 -0700

    Branch 160346151 (#11094)
    
    * Properly handle ops that don't have a CPU kernel
    
    PiperOrigin-RevId: 159655906
    
    * Selected BUILD cleanup in tensorflow/contrib/...
    
    PiperOrigin-RevId: 159673079
    
    * Remove redundant `get` calls on smart pointers
    
    PiperOrigin-RevId: 159675809
    
    * PiperOrigin-RevId: 159698321
    
    * Migrate kernels to boosted_trees.
    
    PiperOrigin-RevId: 159698656
    
    * Fix a bug in the memory optimizer when two inputs to a node are both recomputed
    
    PiperOrigin-RevId: 159700457
    
    * Fixed memory leak that can be triggered by a failed node evaluation
    
    PiperOrigin-RevId: 159707380
    
    * Updates get_started tutorial.
    
    PiperOrigin-RevId: 159709158
    
    * [XLA] Remove unused factory in local_service
    
    PiperOrigin-RevId: 159712806
    
    * Fix typo in docstring
    
    PiperOrigin-RevId: 159714414
    
    * Migrate ops for new version of TensorForest.
    
    PiperOrigin-RevId: 159718610
    
    * Added parameterized tests to reduce window tests.
    
    PiperOrigin-RevId: 159721784
    
    * Use C API to implement Operation.device property
    
    PiperOrigin-RevId: 159723490
    
    * Several Estimator changes:
    - support configurable input_fn calling in Estimator subclasses.
    - pass params and config to the input_fn.
    - allow callables for model_fn and input_fn.
    
    PiperOrigin-RevId: 159725554
    
    * Fixed the scalar output for shard api when outputs_from_all_shards=True.
    
    PiperOrigin-RevId: 159726444
    
    * Automated g4 rollback of changelist 159718610
    
    PiperOrigin-RevId: 159728380
    
    * Adding missing deps to targets in llvm.BUILD. This was only working in non-sandboxed builds.
    
    PiperOrigin-RevId: 159729295
    
    * [XLA:HLO] Move sequence functions from hlo_ordering.h to hlo_scheduling.h.
    
    This is required for upcoming changes to convert the sequence creation functions
    (and HeapSimulator and BufferAssignment) over to using the new
    Hlo{Dataflow,Alias}Analysis.
    
    It's required because otherwise there's a dependency cycle:
    
    Hlo{Dataflow,Alias}Analysis depends on HloOrdering
    CreateMemoryMinimizingSequence will depend on Hlo{Dataflow,Alias}Analysis
    
    There's already a cycle here, if both HloOrdering and
    CreateMemoryMinimizingSequence are in the same file.  Also note that:
    
    MinimumMemoryForSequence depends on HeapSimulator
    HeapSimulator will depend on Hlo{Dataflow,Alias}Analysis
    Hlo{Dataflow,Alias}Analysis depends on HloOrdering
    
    Splitting out the sequence functions resolves the cycle.
    
    Refactoring only; no functional changes.
    
    PiperOrigin-RevId: 159731836
    
    * [XLA:HLO] Split Hlo{Value,Buffer} out of Hlo{Dataflow,Alias}Analysis.
    
    This will make dependencies cleaner for upcoming CLs that will convert
    HeapSimulator and HloOrdering to use the new analyses.
    
    No change in functionality.
    
    PiperOrigin-RevId: 159737265
    
    * Internal change
    
    PiperOrigin-RevId: 159738215
    
    * Suggest people need to do some build environment ./configur'ing.
    
    Fixes #4279
    
    PiperOrigin-RevId: 159738412
    
    * Rewrite SameDefinedShape function in ShapeRefiner
    
    PiperOrigin-RevId: 159745894
    
    * [XLA] Remove xla_cpu_*_eigen flags from CPU backends.
    
    These flags are currently de-facto unused; parallelism should be controlled
    through the cpu_parallel backend. For configuring Eigen, if needed, the options
    should be piped more directly to the code.
    
    PiperOrigin-RevId: 159746509
    
    * Updates layers tutorial and corresponding example.
    
    PiperOrigin-RevId: 159749528
    
    * Further BUILD cleanup
    
    PiperOrigin-RevId: 159749869
    
    * Use more efficient squared_difference
    
    PiperOrigin-RevId: 159751209
    
    * Add log_step_count_steps to RunConfig and allow it to flow to the MonitoredSession.
    
    PiperOrigin-RevId: 159753935
    
    * [XLA] Remove xla_hlo_test_generate_hlo_graph, which is now redundant.
    
    PiperOrigin-RevId: 159755688
    
    * Do not use SSE4.1 instructions on Android builds.
    
    PiperOrigin-RevId: 159756104
    
    * Add nonpublic helper `tf.distributions.util.tridiag` op.
    
    PiperOrigin-RevId: 159757904
    
    * [XLA] Remove dead "in-client" code.
    Remove Service::runs_in_client_process_ field and it's dead user. This was
    previously used by the "InProcess" methods which have been replaced with
    the LocalClient API.
    
    PiperOrigin-RevId: 159759455
    
    * [tf contrib seq2seq] Add monotonic attention mechanisms
    
    * Add monotonic_attention and safe_cumprod helper functions.
    * Add _BaseMonotonicAttentionMechanism base class.
    * Add BahdanauMonotonicAttention and LuongMonotonicAttention classes.
    
    These attention mechanisms are proposed in
    Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
    "Online and Linear-Time Attention by Enforcing Monotonic Alignments."
    ICML 2017.  https://arxiv.org/abs/1704.00784
    
    PiperOrigin-RevId: 159760073
    
    * Add ability for argmax to output int32 indices.  Default remains int64.
    
    Change is made in a backwards and forward compatible manner, since
    we add a new attribute with a default that remains the same, and
    simply register a few new kernels.
    
    PiperOrigin-RevId: 159761347
    
    * Automated g4 rollback of changelist 159746509
    
    PiperOrigin-RevId: 159763112
    
    * Raise ValueError if invalid dtype for random_uniform.
    
    PiperOrigin-RevId: 159764956
    
    * Internal change.
    
    PiperOrigin-RevId: 159769520
    
    * Support zero shapes for random_poisson. This matches random_uniform.
    
    PiperOrigin-RevId: 159771215
    
    * Blacklist the quantized ops since they have too many issues (incorrect shape
    functions, memory corruptions, ...)
    
    PiperOrigin-RevId: 159772801
    
    * Fixed the shape functions of the QuantizedAdd and QuantizedMul ops
    
    PiperOrigin-RevId: 159772841
    
    * Switch from assigning namedtuple.__new__.__defaults__ to overwriting __new__.
    
    Assigning __defaults__ relies on an implementation detail of CPython, confuses
    type checkers (and developers :)), and is error-prone since it doesn't make the
    relationship between parameter names and default values explicit.
    This CL switches to overloading __new__ instead.
    
    PiperOrigin-RevId: 159773922
    
    * Made sure that we can call the constant folding code twice safely.
    
    PiperOrigin-RevId: 159781607
    
    * Added batch_matmul op dependence to android_extended_ops
    
    PiperOrigin-RevId: 159787178
    
    * Fixes a TODO in head_test.
    
    PiperOrigin-RevId: 159789178
    
    * When configuring per-session thread pools, allow
    a pool to be a global pool. This allows a division
    between large and small pools, without needing to make
    new pool for each session.
    
    PiperOrigin-RevId: 159789678
    
    * Add a multi-head TensorForest estimator.
    
    PiperOrigin-RevId: 159820487
    
    * Have RestoreV2's shape fn set all outputs to unknown shape.
    
    PiperOrigin-RevId: 159835723
    
    * VectorExponential added to distributions.
    
    PiperOrigin-RevId: 159840822
    
    * Fold as many nodes as possible instead of giving up if there is any error.
    
    PiperOrigin-RevId: 159841935
    
    * Removed deprecated summary usage from estimators.
    Made name_space usage consistent.
    
    PiperOrigin-RevId: 159846928
    
    * Adding missing license notice to toolchain build files
    
    PiperOrigin-RevId: 159847551
    
    * [XLA] Remove unused flags and move debugging flag to debug options.
    
    PiperOrigin-RevId: 159849759
    
    * Fixes some docstrings in feature_column.
    
    PiperOrigin-RevId: 159850619
    
    * TpuEstimator: Replicate the input_fn to the worker CPU for each shard.
    
    The batch size is configured as follows:
    The user may specify a global batch size in their hyperparameters. If the 'batch_size' field is set, then we convert the global batch size into a per-shard batch size by dividing by num_shards before running their input_fn.
    
    PiperOrigin-RevId: 159851773
    
    * Modify beam search decoder to use symbolic shape for vocab size if the static shape is not present.
    
    PiperOrigin-RevId: 159852297
    
    * Generalize cluster initialization to span multiple mini-batches if necessary.
    
    PiperOrigin-RevId: 159852557
    
    * Use a single threaded session for SDCALinearRegressorTest to
    avoid incorrect threading test failures (tsan).
    
    PiperOrigin-RevId: 159852818
    
    * Migrate ops for new version of TensorForest.
    
    PiperOrigin-RevId: 159852889
    
    * Replaced constant inputs with variables to ensure most of the graph doesn't get
    optimized away
    
    PiperOrigin-RevId: 159853171
    
    * For candidate sampling, add facility to colocate the logit computation with the sharded embeddings.
    
    PiperOrigin-RevId: 159854706
    
    * Added a utility to create parsing spec for regressors (canned estimator)
    
    PiperOrigin-RevId: 159855254
    
    * Fix cuda_kernel_helper_test. std::numeric_limits<int32>::max() doesn't pass, so
    I didn't use that.
    
    PiperOrigin-RevId: 159869169
    
    * In tfcompile, prune nodes that are not reachable from the fetches before
    building the Graph. This allows loading a graph that contains ops not
    needed for the compiled binary.
    
    PiperOrigin-RevId: 159869692
    
    * Fix bugs related to distributions over integers.
    
    - Ensure that the max number of categories does not exceed largest integer-form float.
    - Make dtype inference consistent between Categorical and Multinomial
    distributions.
    - Improve documentation to better reflect that the Categorical
    distribution is analogous to `argmax{OneHotCategorical}` (itself being
    identical to `argmax{Multinomial(p,n=1)}` but not Multinomial.
    - Fix validation_args Heisenberg uncertainty: only validation logic should live under self.validate_args. E.g., validate_args=True would sometimes imply `x=floor(x)` which changes behavior thus making debugging impossible because enabling validation *changes* values.
    - Corrected `Geometric` swapping of validate_args` and `allow_nan_stats` default-values.
    
    Fixes #10149
    
    PiperOrigin-RevId: 159872532
    
    * Make HloModule clonable
    
    This CL makes HloModule clonable, which is necessary when we want to run the same compilation twice with the same input.
    
    PiperOrigin-RevId: 159874256
    
    * Internal change.
    
    PiperOrigin-RevId: 159876942
    
    * Implement alternative `monte_carlo.expectation_v2`. This function implements
    the reparameterization and score-gradient tricks and does not depend on
    tf.Distribution like inputs.
    
    PiperOrigin-RevId: 159877923
    
    * In SE_ASSIGN_OR_RETURN change ConsumeValueOrDie to the preferred std::move ValueOrDie.
    
    PiperOrigin-RevId: 159879754
    
    * If rank is unknown, do not add output shapes to transpose nodes.
    
    PiperOrigin-RevId: 159879840
    
    * Move sparse_fill_empty_rows to new, *significantly* faster, C++ kernel for everyone.
    
    Also fix a bug in the C++ op when the input ST has 0 elements.
    
    PiperOrigin-RevId: 159880044
    
    * Add support of label_keys to DebugClassifier
    
    PiperOrigin-RevId: 159883986
    
    * Register devices under their legacy names
    
    Because some higher level APIs continue to use the legacy name format,
    when using ClusterSpec propagation, we need to ensure that we register
    the devices under their legacy names as well as their canonical names.
    
    PiperOrigin-RevId: 159885777
    
    * [BatchNorm] Minor fixes to TF doc
    
    PiperOrigin-RevId: 159886125
    
    * Generating TBAA metadata causes the LLVM to miscompile after
    https://reviews.llvm.org/rL305938).  Disable TBAA (to stop the miscompiles)
    while we fix the root issue.
    
    PiperOrigin-RevId: 159895736
    
    * Improve score-trick to be a valid Csiszar f-Divergence yet numerically stable.
    
    PiperOrigin-RevId: 159896013
    
    * Support advisor in all places (Command line, APIs)
    Add expensive operation checker
    
    PiperOrigin-RevId: 159897279
    
    * Added canned estimators to Tensorflow library. List of added estimators:
    * DNNClassifier
    * DNNRegressor
    * LinearClassifer
    * LinearRegressor
    * DNNLinearCombinedClassifier
    * DNNLinearCombinedRegressor
    
    PiperOrigin-RevId: 159898954
    
    * Alligned how model-fns handled params among linear/dnn/combined estimators.
    
    PiperOrigin-RevId: 159899925
    
    * Fixed cmake tests.
    
    PiperOrigin-RevId: 159901417
    
    * [XLA:CPU] Add VLOGs to cpu_compiler.cc
    
    PiperOrigin-RevId: 159902919
    
    * Make occurence (op run times and op definition) selectable
    in all views to address the loop problem.
    
    When a node is in loop, its execution times are accumulated, its run times
    will increase.
    
    PiperOrigin-RevId: 159912429
    
    * [XLA] Small error message improvement in binop shape inference.
    
    PiperOrigin-RevId: 159920109
    
    * Follow upstream API change from r306058.
    
    PiperOrigin-RevId: 159938416
    
    * [TF:XLA] Update LLVM to upstream revision r306085.
    
    PiperOrigin-RevId: 159946562
    
    * [XLA] Remove unused xla_cpu flag and move another to DebugOptions.
    
    PiperOrigin-RevId: 159952124
    
    * Updates linear.md tutorial
    
    PiperOrigin-RevId: 159956867
    
    * Add TraceMe instrumentation of RunStep in GRPC distributed runtime.
    A unique ID is added to each RunStep call that allows the client and server
    events to be correlated.
    
    PiperOrigin-RevId: 159956950
    
    * [XLA] Add general F32 implementation for ReducePrecision operation.
    
    This only tests with parameter inputs (which is needed to ensure we actually test on GPUs as well as CPUs); there's no point in separately testing with constants.
    
    PiperOrigin-RevId: 159961430
    
    * Java: NativeLibrary: Fix URL in error message.
    
    And add some detail.
    Inspired by #11015
    
    PiperOrigin-RevId: 159962478
    
    * Increase rtol for util_test.
    
    PiperOrigin-RevId: 159971136
    
    * Re-enable IR dumping for the sequential CPU backend.
    
    PiperOrigin-RevId: 159974126
    
    * tfdbg: a few minor fixes and improvements
    
    * Let DumpingDebugWrapperSession and DumpingDebugHook create session_root if it doesn't exist
    * Add README.md to tensorflow/python/debug
    * Add section "Debugging Keras Models with TFDBG" in debugger.md
    
    PiperOrigin-RevId: 159976070
    
    * Add None check for save_path when restoring checkpoints as if something is wrong in tf.train.latest_checkpoint, it will often return None and it's nice to have a common sense check in restore for this. This way log.error says what has happened.
    
    PiperOrigin-RevId: 159979481
    
    * Don't crash if a metagraph fails to load.
    
    PiperOrigin-RevId: 159981628
    
    * Prepare to not include node_def.proto.h in node_def_util.h
    
    The goal is to make kernels mostly independent of proto headers, which will let
    us lock down our .so imports.  This CL makes a bunch of .cc files
    either include node_def.proto.h themselves or not need the definition of
    NodeDef; a second CL will make node_def_util.h not include node_def.proto.h.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 159982117
    
    * Add a few diagnostic flags to help narrow down issues with the LLVM
    backends.
    
    PiperOrigin-RevId: 159982441
    
    * Updated wide-n-deep tutorial code to use core version of estimators and feature-columns.
    
    PiperOrigin-RevId: 159984663
    
    * Modify ControlFlowContext to also respect import_scope in 'values_' and keys of 'external_values_'
    
    PiperOrigin-RevId: 159985290
    
    * Add item's graph to partition_graphs in virtual cluster's run method.
    Put node op name in timeline_label instead of node_name.
    
    PiperOrigin-RevId: 159986583
    
    * Use short-proto for logging purposes.
    
    A short proto will be output on a single log line, making it
    easier for certain automated tools to handle.
    
    PiperOrigin-RevId: 159994005
    
    * Sinh, ArcSinh, Cosh, LogCosh functions added to distributions/python/ops/trig.
    Care is taken to ensure a fair bit of stability.
    
    PiperOrigin-RevId: 159995514
    
    * Updates some examples in examples/learn.
    
    PiperOrigin-RevId: 159996397
    
    * Add kernel tests for boosted_trees.
    
    PiperOrigin-RevId: 160002696
    
    * Avoid doing unecessary work in the OptimizeGraph() function whenever possible
    
    PiperOrigin-RevId: 160003173
    
    * Use std::shared_ptr instead of core::RefCounted for Node::Properties
    
    Also changes Node::Properties to a struct and removes underscores from public member variables. This change should make it easier to work with Properties moving forward as the refcount will be automatically updated.
    
    PiperOrigin-RevId: 160003281
    
    * Make the CPU compiler dump optimized IR along with the unoptimized IR.
    
    PiperOrigin-RevId: 160005257
    
    * Disable flaky run_metadata_test.
    
    PiperOrigin-RevId: 160015399
    
    * BUILD cleanup in tensorflow/tools/...
    
    PiperOrigin-RevId: 160018623
    
    * SinhArcSinh bijector added.
    
    This two-parameter diffeomorphism from R --> R allows for skewness and fatter
    or thinner tails.  See docstring and also
    http://oro.open.ac.uk/22510/1/sinhasinh.pdf
    
    PiperOrigin-RevId: 160019380
    
    * Avoid hardcoded names for temporary files in tests.
    
    These tests (and examples that are run as tests) were using hardcoded names for
    temporary files.  This failed when multiple copies of these tests were run in
    parallel, or even successively by different users, where the second run could
    not overwrite files left by the first.
    
    This change uses the TEST_TMPDIR environment variable used by bazel's test
    runner to choose a temporary directory.   If that directory is not set,
    /tmp is used, as before.
    
    PiperOrigin-RevId: 160026924
    
    * Fix multinomial doc-string, input arg logits expects to log-probabilities and not log-odds.
    
    PiperOrigin-RevId: 160036709
    
    * Made TensorFlow documentation on LSTMs slightly more accurate.
    
    PiperOrigin-RevId: 160047054
    
    * Follow LLVM/ORC upstream API change in r306166.
    
    PiperOrigin-RevId: 160108102
    
    * Move resampler from sonnet to contrib.
    
    PiperOrigin-RevId: 160134565
    
    * [TPUEstimator] Make input_fn invoked properly with eval on CPU.
    
    PiperOrigin-RevId: 160151890
    
    * Deletes iris_val_based_early_stopping example, which uses deprecated ValidationMonitor.
    
    PiperOrigin-RevId: 160154863
    
    * [XLA] Move HLO dumping flags from service_flags to debug_options_flags
    
    This also removes the duplication in the xla_generate_hlo_graph flag.
    
    This CL also moves the actual dumping logic from Executable to the
    hlo_graph_dumper namespace, where it belongs; this is in preparation for
    removing the hlo_dumper callback altogether, since it isn't serving any role
    beyond what a direct call to hlo_graph_dumper would have (b/62872831 has more
    details).
    
    PiperOrigin-RevId: 160154869
    
    * Fix missing variable unref
    
    Direct leak of 56 byte(s) in 1 object(s) allocated from:
        #0 0xf5ee272 in operator new(unsigned long) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf5ee272)
        #1 0x1b51394c in tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*)::'lambda'(tensorflow::Var**)::operator()(tensorflow::Var**) const (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b51394c)
        #2 0x1b5136c0 in std::_Function_handler<tensorflow::Status (tensorflow::Var**), tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*)::'lambda'(tensorflow::Var**)>::_M_invoke(std::_Any_data const&, tensorflow::Var**) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b5136c0)
        #3 0x1b50b289 in std::function<tensorflow::Status (tensorflow::Var**)>::operator()(tensorflow::Var**) const (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50b289)
        #4 0x1b50af88 in tensorflow::Status tensorflow::ResourceMgr::LookupOrCreate<tensorflow::Var>(basic_string<char, std::char_traits<char>, std::allocator<char> > const&, basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::Var**, std::function<tensorflow::Status (tensorflow::Var**)>) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50af88)
        #5 0x1b50ac10 in tensorflow::Status tensorflow::LookupOrCreateResource<tensorflow::Var>(tensorflow::OpKernelContext*, tensorflow::ResourceHandle const&, tensorflow::Var**, std::function<tensorflow::Status (tensorflow::Var**)>) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b50ac10)
        #6 0x1b512f1e in tensorflow::AssignVariableOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1b512f1e)
        #7 0x1d1881c7 in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0x1d1881c7)
        #8 0xf96e0fe in tensorflow::KernelAndDevice::Run(std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf96e0fe)
        #9 0xf94f9c8 in TFE_Execute (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf94f9c8)
        #10 0xf94356d in TFE_Py_Execute(TFE_Context*, int, char const*, tensorflow::gtl::InlinedVector<TFE_TensorHandle*, 4>*, _object*, tensorflow::gtl::InlinedVector<TFE_TensorHandle*, 2>*, TF_Status*) (/build/cas/5d2/5d2be3b530580573ff7269adcab7cbac+0xf94356d)
    
    PiperOrigin-RevId: 160160101
    
    * Simplify strided_slice's shape handling
    
    Now that TensorShape and PartialTensorShape share memory representations, there's no need for an abstract class that makes TensorShape and TensorShapeProto look the same.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160161618
    
    * Added a tool to report the static information that can be extracted from a TF model.
    
    PiperOrigin-RevId: 160162256
    
    * Properly handle RefEnter, RefExit and RefNextIteration nodes.
    
    PiperOrigin-RevId: 160162338
    
    * Switch tfprof to use proto3
    
    PiperOrigin-RevId: 160163483
    
    * Fixes to cuda_config.h.
    
    PiperOrigin-RevId: 160168545
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160171187
    
    * Adds notes to prevent overfitting for Experiment continous_train_and_eval.
    
    PiperOrigin-RevId: 160172692
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 160172985
    
    * Merge changes from github.
    END_PUBLIC
    
    Note: this CL will break builds.  cl/159887762 to follow to fix all the breakages.
    
    ---
    Commit 2336cdf7f authored by Maxwell Paul Brickner<mbrickn@users.noreply.github.com>
    Committed by gunan<gunan@google.com>:
    Updated link to use HTTPS (#10998)
    
    Howdy!
    
    I just updated a link to use https instead of http.
    
    Thanks!
    ---
    Commit ad0892df1 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] Fixes run_metadata_test for SYCL
    
     This test is designed to test CUDA specific behavior
    
    ---
    Commit 6b37a0725 authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Update comments
    ---
    Commit 1699d904a authored by John Lawson<john@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] Fixes CUDA specific test run on SYCL (#56)
    
    The testBadParentValuesOnGPU should only be run on CUDA devices, as the
    test checks for particular CUDA behaviour. We don't actually provide a
    SYCL kernel for GatherTree and so it's not a problem that the tests
    don't target SYCL.
    ---
    Commit 3c1946230 authored by myPrecious<Moriadry@users.noreply.github.com>
    Committed by Shanqing Cai<cais@google.com>:
    Java API to get the size of specified input list of operations. (#10865)
    
    * Java API to get the size of specified input list of operations
    
    * remove unnecessary explain to avoid bring a new term to users.
    
    ---
    Commit e911c7480 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Luke Iwanski<luke@codeplay.com>:
    [OpenCL] REGISTER -> REGISTER6
    
    ---
    Commit fbf6c4cec authored by superryanguo<superryanguo@gmail.com>
    Committed by superryanguo<superryanguo@gmail.com>:
    Simplify the Quickstart section with the weblink is better
    
    ---
    Commit 72e2918cc authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Taehoon Lee<taehoonlee@snu.ac.kr>:
    Fix typos
    
    ---
    Commit 90c4406b7 authored by Rishabh Patel<patelrishabh@users.noreply.github.com>
    Committed by GitHub<noreply@github.com>:
    Correct the learning rate as per the code snippet
    ---
    Commit 03da61134 authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Update ir_array.cc
    ---
    Commit 2df6cd3ac authored by Todd Wang<toddwang@gmail.com>
    Committed by GitHub<noreply@github.com>:
    Another try
    ---
    Commit af0cbace1 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Transpose to go through Eigen (#10321)
    
    ---
    Commit fc7361081 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Registers RGBToHSV and HSVToRGB (#91) (#10848)
    
    * [OpenCL] Added RGBToHSV and HSVToRGB
    
    * Aligning '\'
    ---
    Commit 832894ef8 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Registers AdjustContrastv2 (#10949)
    
    * [OpenCL] Registers AdjustContrastv2 (#93)
    
    * [OpenCL] Extended adjust_contrast_op_benchmark_test for OpenCL (#96)
    
    * [OpenCL] Extended adjust_contrast_op_benchmark_test for OpenCL
    
    * simplified to #ifndef
    
    * Changed to "#if GOOGLE_CUDA"
    
    * Update adjust_contrast_op_benchmark_test.cc
    
    * Added comments
    
    ---
    Commit cb4c2f8d1 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Make TransferBufferToInFeed not virual so it compiles.
    
    ---
    Commit e89f04d80 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix calling Literal member functions.
    
    ---
    Commit 15a8df724 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix mac build
    clone from meheff's change:
    [XLA] Change return type of DeviceAssignment::Deserialize to fix build
    breakage on mac.
    The mac build had the following error:
    
    error: incomplete type 'xla::DeviceAssignment' used in type trait
    expression
    
    This was due to a static method returning a StatusOr<DeviceAssignment>
    inside of the definition of DeviceAssignment.
    
    ---
    Commit a54d43fa4 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Replace LiteralUtil to Literal in compiler/plugin/executor
    
    ---
    Commit 88a6bb80c authored by Guenther Schmuelling<guschmue@microsoft.com>
    Committed by Guenther Schmuelling<guschmue@microsoft.com>:
    expand inline for debug builds to limit number of symbols
    
    ---
    Commit 62fb49d31 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Fix visibility error for contrib/remote_fused_graph/pylib/BUILD.
    
    ---
    Commit 4c75252f2 authored by Mark Neumann<markn@allenai.org>
    Committed by Mark Neumann<markn@allenai.org>:
    fix initial test values to avoid numerical instability
    
    ---
    Commit b58d98353 authored by sj6077<epik03sj@gmail.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    Fixes of AutoParallel bug (#10368)
    
    * Fix the bug that auto_parallel could replicate variable snapshot name
    
    * Use NodeName in grappler:utils instead of substr, convert variables->variable_def of grappler item
    
    * remove variable_def from grappler item, exclude snapshot nodes from dont_replicate_nodes in auto_parallel
    
    ---
    Commit a286b7db8 authored by Yifei Feng<yifeif@google.com>
    Committed by Yifei Feng<yifeif@google.com>:
    Make debug_test slice integer.
    
    ---
    Commit 97fcfdfa6 authored by Toby Boyd<tobyboyd@google.com>
    Committed by GitHub<noreply@github.com>:
    Fixed path to seq2seq.py and minor formatting
    ---
    Commit 63c1befb8 authored by Anish Shah<shah.anish07@gmail.com>
    Committed by Anish Shah<shah.anish07@gmail.com>:
    Improve docs for tf.nn.depthwise_conv2d_native
    
    ---
    Commit 8d42202b2 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Yong Tang<yong.tang.github@outlook.com>:
    Fix mismatched delete in mkl_tfconv_op.cc
    
    This fix fixes mismatched new[]-delete in mkl_tfconv_op.cc
    
    (the file went through clang-format so there are some additional
    changes)
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    
    ---
    Commit 26301bd55 authored by Danny Goodman<goodman.danny@gmail.com>
    Committed by Danny Goodman<goodman.danny@gmail.com>:
    fix error format
    
    ---
    Commit b3f33ad46 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make changes to prepare for the fused option of batch norm to be set to None (None means using fused batch norm if possible).
    
    PiperOrigin-RevId: 159649743
    
    ---
    Commit a4a469832 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add tests for select ops and while loops that produce tuples that contain predicates.
    
    PiperOrigin-RevId: 159645900
    
    ---
    Commit 980d3f2be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use C API to implement Operation.name property
    
    This name property is used in many existing tests including those that
    already run with C API enabled (math_ops_test, framework_ops_test,
    session_test, session_partial_run_test, math_ops_test_gpu, etc).
    
    PiperOrigin-RevId: 159645767
    
    ---
    Commit 26239c706 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Previously we didn't have an implementation of BatchNormInference and BatchNormTraining, which gives a linker error if anyone ever tries to call that. A dummy implementation is friendlier than a linker error.
    
    PiperOrigin-RevId: 159645612
    
    ---
    Commit f671c5caa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 159570549
    
    PiperOrigin-RevId: 160182040
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160183349
    
    * Merge changes from github followup.
    
    PiperOrigin-RevId: 160183498
    
    * Automated g4 rollback of changelist 160183498
    
    PiperOrigin-RevId: 160189134
    
    * Automated g4 rollback of changelist 160182040
    
    PiperOrigin-RevId: 160190881
    
    * [XLA] Disallow fuse X into Y if there are paths from X to Y which don't fuse
    
    Just because X can fuse into all of its consumers does not mean that those
    consumers can fuse into anything. Depending on the structure of the graph, this
    can either result in no performance win at all or, in the case of recurrent
    networks, a big performance deficit.
    
    PiperOrigin-RevId: 160194058
    
    * First draft of Tensors segment of the programmer's guide.
    
    PiperOrigin-RevId: 160196550
    
    * First draft of variables unit of programmer's guide.
    
    PiperOrigin-RevId: 160196566
    
    * Make xla::Literal moveable.
    
    PiperOrigin-RevId: 160197273
    
    * Automated g4 rollback of changelist 159897279
    
    PiperOrigin-RevId: 160198598
    
    * Updates text_classification example.
    
    PiperOrigin-RevId: 160200457
    
    * Fix backward compatibility test broken by rollback.
    
    PiperOrigin-RevId: 160222187
    
    * Support advisor in all places (Command line, APIs)
    Add expensive operation checker
    
    PiperOrigin-RevId: 160222348
    
    * [XLA] Simplify the fusion heuristic
    
    We had two different aspects of the fusion heuristic:
    - Don't fuse a producer into a consumer if there exists a path from the
      producer to the consumer which cannot be fused.
    - Don't fuse a producer into a consumer if any consumer of the producer cannot
      fuse.
    
    These can be combined into one, simpler, heuristic.
    
    PiperOrigin-RevId: 160222771
    
    * Automated g4 rollback of changelist 160196566
    
    PiperOrigin-RevId: 160222930
    
    * Automated g4 rollback of changelist 160196550
    
    PiperOrigin-RevId: 160222942
    
    * Lets the HParam parser also accept True and False as inputs, since that's how python prints booleans.
    
    PiperOrigin-RevId: 160234658
    
    * Automated g4 rollback of changelist 155070869
    
    PiperOrigin-RevId: 160249526
    
    * [TF:XLA] Inline the sigmoid operation instead of mapping it elementwise.
    
    PiperOrigin-RevId: 160274436
    
    * Make sure all convolution tests are testing non-trivial cases, i.e. where not all inputs are 0, leading to an all-0 output, which masks most possible bugs.
    We do not check-fail on 0-sized dimensions as tests for these special cases
    exist.
    
    PiperOrigin-RevId: 160274593
    
    * Explicitly use "dns" URI scheme when using DNS names or literal IP
    addresses with gRPC.  This avoids problems in environments in which the
    default URI scheme is something other than "dns".
    
    PiperOrigin-RevId: 160276862
    
    * Add RWSE (root weighted squared error) to the WALS estimator.
    
    PiperOrigin-RevId: 160276937
    
    * Don't include node_def.proto.h in node_def_util.h
    
    The goal is to make kernels mostly independent of proto headers, which will let us lock down our .so imports.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160278032
    
    * [XLA] Add tuple support to Literal::CreateFromShape.
    
    PiperOrigin-RevId: 160278561
    
    * Updates some more examples in examples/learn.
    
    PiperOrigin-RevId: 160278757
    
    * Automated g4 rollback of changelist 160278032
    
    PiperOrigin-RevId: 160280961
    
    * Fixed the bug that Estimator does not make deepcopy of params in constructor
    
    PiperOrigin-RevId: 160281247
    
    * Clean out the config and params in TPUEstimator.
    
    PiperOrigin-RevId: 160281507
    
    * [XLA] Remove the "hlo dumper" parameter of xla::Compiler and its piping.
    
    This dumper is no longer necessary since the restructuring of HLO dumping and
    the addition of MaybeDumpHloModule which heeds to the right flags. The
    remaining bits didn't have additional functionality, but constituted a lot of
    boilerplate that has to be propagated throughout the backends.
    
    PiperOrigin-RevId: 160281798
    
    * [TF:XLA] Refactor the sigmoid op as a rescaled tanh.
    
    PiperOrigin-RevId: 160282472
    
    * Fix uninitialized values in TensorForest code.
    
    PiperOrigin-RevId: 160284420
    
    * [TF:XLA] Update Tensorflow LLVM release to upstream r306370.
    
    Fix broken XLA build.
    
    PiperOrigin-RevId: 160284588
    
    * tfdbg example: fix --tensor_size issue in debug_fibonacci
    
    PiperOrigin-RevId: 160290541
    
    * [SE] ThenConvolveWithAlgorithm vlogs algorithm configs.
    
    PiperOrigin-RevId: 160292762
    
    * Fix documentation of Estimator class (invalid quotes).
    
    PiperOrigin-RevId: 160292803
    
    * Shrink the test size to avoid OOM error on old GPUs.
    
    PiperOrigin-RevId: 160292834
    
    * [TF:XLA] Reject operators with resource outputs on CPU and GPU devices.
    
    We were checking for resource inputs but not resource outputs, which led to accidental fusion of some TensorArray ops on CPU and GPU.
    
    PiperOrigin-RevId: 160294302
    
    * Add a functionality of remote fused graph transformation to fuse graphs by op type
    
    PiperOrigin-RevId: 160300039
    
    * Cudnn compatible LSTMCell and LSTMBlockCell
    
    PiperOrigin-RevId: 160300668
    
    * [XLA] Remove "operand" argument from HandleReducePrecision.
    
    PiperOrigin-RevId: 160301461
    
    * Added more reduce window tests.
    
    PiperOrigin-RevId: 160301509
    
    * Updates more text classification examples in examples/learn.
    
    PiperOrigin-RevId: 160305131
    
    * Use C API to implement Operation._output_types
    
    This change first converts the _output_types member to a property and
    then implements it using C API if it is enabled.
    
    PiperOrigin-RevId: 160306227
    
    * Add more tests for BatchNormTraining.
    RELNOTES: n/a
    
    PiperOrigin-RevId: 160307959
    
    * Update path to print_selective_registration_header.py in comment
    
    PiperOrigin-RevId: 160308173
    
    * Migrate TensorForest v4 python to contrib.
    
    PiperOrigin-RevId: 160308805
    
    * Automated g4 rollback of changelist 159454657
    
    PiperOrigin-RevId: 160314706
    
    * TESTFIX:  distributions:trig_test wasn't passing in ASAN mode.
    
    PiperOrigin-RevId: 160315597
    
    * tfdbg doc: fixes and improvements
    
    PiperOrigin-RevId: 160318411
    
    * Add a time estimation to HloCostAnalysis and represent properties as a map so that adding more properties will be easier, e.g. in a sub-class.
    
    PiperOrigin-RevId: 160318494
    
    * tfdbg: revert dns:/// prefix in gRPC mode
    
    PiperOrigin-RevId: 160319348
    
    * Moves TensorCApi from c_api.cc to c_api_internal.h, where it can be used
    by other code that require access to the underlying TensorBuffers.
    
    PiperOrigin-RevId: 160323362
    
    * Readd the new tensors and variables documents, with tests passing.
    
    PiperOrigin-RevId: 160324191
    
    * Make ResourceHandle not be a proto
    
    I'm trying to make core/kernels independent of protos.  Currently the dtype ResourceHandle is itself a proto.  After this CL, ResourceHandle is a normal C++ type which gets converted to/from ResourceHandleProto at (de)serialization time.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 160329002
    
    * Minor cleanup: remove unused dependencies and inclusions
    
    PiperOrigin-RevId: 160334030
    
    * Add name_scopes to mnist_deep.py for a cleaner graph layout.
    
    PiperOrigin-RevId: 160338775
    
    * Add note about `tf.test.mock` to docs for `tf.test`
    
    PiperOrigin-RevId: 160338811
    
    * Internal change.
    
    PiperOrigin-RevId: 160339087
    
    * Fix bugs in ScatterNd and add ScatterNdNonAliasingAdd.
    
    tf.scatter_nd_non_aliasing_add acts similarly to tf.scatter_nd_add but
    works on non-ref objects (i.e., Tensors -- not Variables).  This means
    it has a gradient with respect to the primary input as well as the
    updates.  It does its best to avoid making extra copies of the input.
    
    PiperOrigin-RevId: 160339328
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160340888
    
    * Add checkpoint conversion for models that use the attention mechanism implemented in tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py.
    
    PiperOrigin-RevId: 160340994
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 160341769
    
    * Merge changes from github.
    
    PiperOrigin-RevId: 160344052
    
    * Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 160346151
    
    * Load py_test in tensorflow/contrib/boosted_trees/BUILD to fix pip test
    visibility failures.
    
    * Disable boosted_trees tests on mac while they are being debugged.

commit 0eff699d3087171cf35671d9d0bd6f8e79441ab3
Author: Benoit Steiner <bsteiner@google.com>
Date:   Fri Jun 23 12:51:19 2017 -0700

    Don't crash if a metagraph fails to load.
    
    PiperOrigin-RevId: 159981628

commit c81484b5dad8327e1158ae48c9e2cc8526a27313
Author: Shanqing Cai <cais@google.com>
Date:   Fri Jun 16 16:02:39 2017 -0700

    tfdbg: prevent curses UI from crashing during rapid resizing
    
    Under rapid resizing, pad.refresh() and addstr() sometimes throws curses.error.
    
    PiperOrigin-RevId: 159288309

commit 1b5235fd897f7ea5cffc715300f67b4dc852fa27
Author: Jonathan Hseu <jhseu@google.com>
Date:   Fri Jun 9 10:37:18 2017 -0700

    Merge changes from github.
    END_PUBLIC
    
    ---
    Commit f0e185d1f authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Better handle nodes with a variable number of outputs
    
    PiperOrigin-RevId: 158435028
    
    ---
    Commit bc3e20807 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused BUILD dependencies
    
    PiperOrigin-RevId: 158431059
    
    ---
    Commit a0c80e4d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Delete unnecessary (mistakenly duplicated) logging message.
    
    PiperOrigin-RevId: 158428506
    
    ---
    Commit b6ad1d747 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds DNN-only tests for DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158423119
    
    ---
    Commit ddbb58034 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unnecessary pylint disable
    
    PiperOrigin-RevId: 158416140
    
    ---
    Commit fcaa724e2 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans pack and unpack ops (#10336)
    
    * [OpenCL] Cleans pack op
    
    * [OpenCL] Cleans unpack op
    
    ---
    Commit 2f53cacb2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a test failure of quantization_utils_test on ASAN
    
    PiperOrigin-RevId: 158414538
    
    ---
    Commit 50b2f951c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158413455
    
    ---
    Commit 1e90b78e9 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add CacheDataset ops.
    
    Some input pipelines may pull down data from remote webservers or perform
    expensive processing. In order to avoid extraneous work, we now support
    caching the dataset (e.g. on disk).
    
    PiperOrigin-RevId: 158411901
    
    ---
    Commit e16cd2ede authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by gunan<gunan@google.com>:
    Fix typos (#10533)
    
    ---
    Commit 50d80ddf9 authored by Jonathan Hseu<jhseu@google.com>
    Committed by Jonathan Hseu<jhseu@google.com>:
    Fix fft_ops_test.py for CPU
    
    ---
    Commit d35cbbb44 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add weight-column support to the heads.
    
    PiperOrigin-RevId: 158409180
    
    ---
    Commit 7fb52cd54 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't crash when displaying XLA metrics if they happen to be negative.
    
    PiperOrigin-RevId: 158407664
    
    ---
    Commit 12a7a752a authored by Jianfei Wang<me@thinxer.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Add a tip for tf.train.LoggingTensorHook (#10237)
    
    `INFO` logs are not printed by default unless in IPython. Add a friendly tip for newcomers.
    ---
    Commit 216dcbf1e authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reduction ops (#10340)
    
    * [OpenCL] Cleans reduction_ops_max.cc
    
    * [OpenCL] Cleans reduction_ops_mean.cc
    
    * [OpenCL] Cleans reduction_ops_min.cc
    
    * [OpenCL] Cleans reduction_ops_prod.cc
    
    * [OpenCL] Cleans reduction_ops_sum.cc
    
    ---
    Commit 2b351062a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Improve docs for selective registration headers (#10351)
    
    * Improve docs for selective registration headers
    
    progressing #10299
    
    * Update print_selective_registration_header.py
    
    * Mention both flags
    
    -DSELECTIVE_REGISTRATION and -DSUPPORT_SELECTIVE_REGISTRATION
    
    ---
    Commit ee919510f authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Re-enable some python tests in Windows Bazel build (#10526)
    
    ---
    Commit b0e881457 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Declare and assign separately (#10509)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2155
    ---
    Commit 284901b08 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Remove unquoting quotes (#10506)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2027
    ---
    Commit 2a1f11556 authored by ksellesk<zhengdachuan200305@gmail.com>
    Committed by ksellesk<zhengdachuan200305@gmail.com>:
    Fix AttributeError in resnet.py
    
    There is no function tf.softmax() in Tensorflow 1.x.
    
    When running the old code, Python interpreter complains:
    
    File "resnet.py", line 152, in res_net_model
    prediction, loss = res_net(x, y)
    File "resnet.py", line 148, in res_net
    return tf.softmax(logits), loss
    AttributeError: 'module' object has no attribute 'softmax'
    
    ---
    Commit 1d68f729b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unneeded BUILD dependency
    
    PiperOrigin-RevId: 158391996
    
    ---
    Commit 08ed32dbb authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Windows: Make TensorFlow build without --cpu=x64_windows_msvc (#10466)
    
    * Windows: Make TensorFlow build without --cpu=x64_windows_msvc
    
    Since from Bazel 0.5.0, MSVC toolchain became the default toolchain on
    Windows. So --cpu=x64_windows_msvc is not required as long as we adjust
    the BUILD files in TensorFlow.
    
    --cpu=x64_windows_msvc is also supported for now, but is depracated.
    The configuration for cpu value x64_windows_msvc is a duplicate of
    x64_windows, which should be removed in the future.
    
    * Fix breakage on macOS
    
    ---
    Commit 02dbe153a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Simplify Conditional (#10503)
    
    ---
    Commit c07bc581f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Prefer read -a to split path (#10508)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2207
    ---
    Commit 0a389674d authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    [Bash] Prefer [ p ] && [ q ] over [ p -a q ] (#10507)
    
    As proposed by static analysis tool:
    https://github.com/koalaman/shellcheck/wiki/SC2166
    ---
    Commit 87a008ec3 authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by gunan<gunan@google.com>:
    Delete non-deterministic testEmpty() test (#10512)
    
    ---
    Commit 3a2971bd8 authored by Frank Chen<frankchn@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds the base for ClusterResolvers, a new way of communicating with and retrieving cluster information for running distributed TensorFlow.
    
    Implementations of this class would eventually allow users to simply point TensorFlow at a cluster management endpoint, and TensorFlow will automatically retrieve the host names/IPs and port numbers of TensorFlow workers from the cluster management service.
    
    PiperOrigin-RevId: 158358761
    
    ---
    Commit 28b4e7f04 authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by gunan<gunan@google.com>:
    Disable stage_op_test and map_stage_op_test (#10516)
    
    ---
    Commit 390e57a75 authored by Yan (Asta) Li<yanastali@users.noreply.github.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    Check EIGEN_MAX_ALIGN_BYTES to prevent mod-by-0 (#10380)
    
    * Check EIGEN_MAX_ALIGN_BYTES to prevent mod-by-0
    
    If EIGEN_MAX_ALIGN_BYTES is set to 0, alignment checks that mod by EIGEN_MAX_ALIGN_BYTES fail at runtime.
    
    * Returns true, as in tensorflow/core/framework/tensor.h
    * Update unit tests
    
    * Enable tests only if EIGEN_MAX_ALIGN_BYTES > 0
    
    ---
    Commit cd5ac40b3 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Update LLVM to upstream revision r304927.
    Add LLVM build rules for the LLVM AMDGPU backend, commented out by default. Fixes issue #10437.
    
    PiperOrigin-RevId: 158351480
    
    ---
    Commit 91cb809bd authored by David Norman<DavidNorman@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [XLA] Add ability to run the XLA unit tests against a different device (#9759)
    
    * Add ability to run the XLA unit tests against a different device
    
    * Allow for multiple extra backend devices
    
    * Correct merge error
    
    * Include options for additional tags
    
    ---
    Commit aff4d124b authored by Yuxin Wu<ppwwyyxxc@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Compare base_dtype instead of dtype in piecewise_constant (#10280)
    
    * Compare base_dtype instead of dtype in piecewise_constant
    
    Compare base_dtype instead of dtype in piecewise_constant. Fix #10086
    
    * add unit test
    
    * Small lint fix and comment
    
    ---
    Commit 845539f98 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add evaluation test for linear classifier (n==2 or n >2).
    
    PiperOrigin-RevId: 158340296
    
    ---
    Commit 7c46214ab authored by Jonathan Hseu<vomjom@vomjom.net>
    Committed by GitHub<noreply@github.com>:
    Fix numpy 1.13 incompatibilities (#10501)
    
    * Fix numpy 1.13 incompatibilities
    
    * Skip tests with numpy 1.13.0
    
    ---
    Commit 4572c41df authored by gunan<gunan@google.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    A few changes to kernel_tests. (#10502)
    
    * Disable reader_ops_test on windows.
    
    * Run buildifier on kernel_tests/BUILD
    
    * Mark map_stage_op_test as large.
    
    * Set the size of stage_op_test to large
    
    ---
    Commit 892293d98 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set a default for datasets end_of_sequence.
    
    While all datasets carefully set the end_of_sequence to true at the
    appropriate time, some datasets might forget to set it to false in the normal
    case. In order to avoid potential undefined behavior, we set the
    end_of_sequence variable to be false by default.
    
    PiperOrigin-RevId: 158337799
    
    ---
    Commit 187404eac authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Setup the env to since ops such as MatchFileOp rely on it.
    
    PiperOrigin-RevId: 158336344
    
    ---
    Commit 2741561c8 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix up vz_projector script structure
    
    We now make sure scripts and HTML imports are declared in the correct
    places. In the future, pedantically listing script tags should not be
    necessary.
    
    PiperOrigin-RevId: 158334306
    
    ---
    Commit beeaade46 authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Resubmit a reverted change. Original description:
    
    [XLA] Enable HloEvaluator for constant folding, also merged a few operations
    from hlo_constant_folding to hlo_evaluator.
    
    Additionally:
    - In ShapeUtil::ForEachIndex:
        * fix a bug where visitor is called when the shape has zero elements (e.g., F32{1,0})
        * added test case for ForEachIndex.
    
    - In HloEvaluator:
        * Instead of copying and caching a Constant instruction, return the literal directly if the instruction is constant.
        * Fix an issue where TUPLE and OPAQUE primitives are not keyed in the templated typed_visitor.
        * Use (fixed) LiteralUtil::Populate to populate resulting literal, fixes the preexisting bug in the evaluator where R0 and shape with zero size dimensions are not handled.
        * Refactor ElementWiseUnaryOp and HandleCompare to be templatized on the operand's type.
        * Refactor IsFinite to be top level since it is only applicable to floats and the return type is always boolean.
        * Change from std::remainder to std::fmod for kRemainder to be compliant with existing XLA behavior.
        * Change from std::max and std::min to std::fmax and std::fmin to handle NaNs.
        * Minor comments fix.
    
    PiperOrigin-RevId: 158330052
    
    ---
    Commit b94540e6f authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tf.layers.conv2d use_bias=True to use nn.bias_add
    
    PiperOrigin-RevId: 158326493
    
    ---
    Commit 379aa9911 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 158325855
    
    ---
    Commit 4e529f0f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158325293
    
    ---
    Commit 0a9d2dac0 authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a util function in virtual placer to return canonicalized device string, which can be used to fix the node's device field before passing them to the maxcut algorithm.
    
    PiperOrigin-RevId: 158322753
    
    ---
    Commit 2d8da1d9b authored by Daniel Ylitalo<daniel@blodan.se>
    Committed by gunan<gunan@google.com>:
    Recognize CPU core count in FreeBSD (#10490)
    
    ---
    Commit c19e6cac0 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Initial implementation of TensorArray ops.
    
    The XLA implementation of TensorArrays is more restrictive than regular TensorArrays:
    * XLA TensorArrays must have dynamic_size=False.
    * all elements in an XLA TensorArray must have the same shape.
    * writes always add their values to any existing values; neither reads nor writes ever issue errors. Out-of-bounds writes currently wrap.
    
    Refactor Variable handling in the TF/XLA bridge. Use a XlaVariable* to refer to variables inside compilation rather than a numerical ID. Allow for variables that don't correspond to variables known to the user. Also use XlaVariable to handle TensorArrays.
    
    PiperOrigin-RevId: 158322041
    
    ---
    Commit b5e8d3086 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Refactor randomized tests to allow testing of larger inputs without running out of memory.
    
    PiperOrigin-RevId: 158321431
    
    ---
    Commit 5d90bbaac authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Disable constant_folding in test base, so that intended test code paths
    would not be elided by constant_folding pass.
    
    PiperOrigin-RevId: 158317641
    
    ---
    Commit 036ce8ba6 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans dense_update_ops (#10335)
    
    * [OpenCL] Cleans dense_update_ops
    
    * Acts on feedback from: #10335#discussion_r120536460
    
    ---
    Commit 85f968125 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans cast operation (#10330)
    
    * [OpenCL] Removes not needed typedef for SYCLDevice
    
    * [OpenCL] Fixes formatting
    
    * [OpenCL] use SYCLDevice for int32 cast case
    
    ---
    Commit bff5e72da authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix typo.
    
    PiperOrigin-RevId: 158310742
    
    ---
    Commit 38249d6be authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Swap the order of NanTensorHook and custom hooks
    
    to ensure that when the training encounteres NaN's in the loss function, user-supplied hooks such as tf_debug.LocalCLIDebugHook can still be used to debug the root cause of the numeric issues.
    
    PiperOrigin-RevId: 158310249
    
    ---
    Commit 599727c65 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Propagate debug option flags to hlo_test_base.
    
    Specific HLO tests have to replace the generic test_main target with a manual
    main() that invokes RUN_ALL_TESTS.
    
    To get access to a module with debug options set up, a new convenience method
    is created on HloTestBase.
    
    Initially algebraic_simplifier_test is modified as a canary; in a followup
    we'll convert all HLO tests to this approach.
    
    PiperOrigin-RevId: 158309488
    
    ---
    Commit 0770393e9 authored by Eric Liu<ioeric@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [Tensorboard] Add a trace viewer component to TensorBoard.
    
    We make the trace viewer a separate app; otherwise, there would be dependency
    conflicts (e.g. Polymer) between the trace viewer app and the tensorboard app.
    The trace viewer app would be served by a plugin, and Tensorboard dashboard will integrate trace viewer app using iframe in the
    future.
    
    This CL also added "mominify" support for link import HTML tags in the
    tensorboard home-grown java vulnizer; otherwise, the vulcanized trace viewer code
    would crash the java vulcanizer.
    
    For open-source build, we add a denpendency on the Catapult github repository
    (https://github.com/catapult-project/catapult/tree/master/tracing). We use a bazel genrule to vulcanize a trace viewer binary which is then used in the
    tf-trace-viewer component.
    
    PiperOrigin-RevId: 158309408
    
    ---
    Commit 85e832201 authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support unknown emit shapes in tf.nn.raw_rnn.
    
    PiperOrigin-RevId: 158308002
    
    ---
    Commit edb5fed7f authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add label-vocab support to binary logistic head.
    Add assertion that binary classifier label is in range [0., 1.]
    Fixed Classifier Integration tests.
    
    PiperOrigin-RevId: 158307521
    
    ---
    Commit f8e1cf8fa authored by Justine Tunney<jart@google.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Open up visibility of tf_imports (#10500)
    
    This also fixes the definition of Clutz.
    ---
    Commit 9fd7cf054 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans relu ops (#10343)
    
    * [OpenCL] register relu ops to gpu types (no half)
    
    * [OpenCL] Removes #undef EIGEN_USE_SYCL
    
    ---
    Commit 09c1455e3 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reverse_op.cc (#10346)
    
    ---
    Commit b7892a30f authored by orome<royl@aldaron.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Clarify tf.matmul documentation (#10381)
    
    * Update math_ops.py
    
    * Fix non-ascii character
    
    ---
    Commit 9786b7062 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Cleans StridedSlice Op (#10314)
    
    * [OpenCL] Cleans StridedSlice Op
    
    * [OpenCL] Removes half from registred types
    
    ---
    Commit f105df047 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, optimize backward filter convolution for images 2 or 4 times smaller than 16x16. Also initialize in_cols from blockDim, to fix the regression caused in CL 157906773.
    
    PiperOrigin-RevId: 158296136
    
    ---
    Commit 492afc2e3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 158295169
    
    ---
    Commit abe0877ef authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add bazel version check to .configure
    
    PiperOrigin-RevId: 158294569
    
    ---
    Commit b702e7e79 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158294289
    
    ---
    Commit 94085bee7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Replace std::function object with regular function.
    
    The function is called recursively, and the std::function object had only existed to allow recursion from within a lambda expression. A regular function should be cheaper than a polymorphic function wrapper.
    
    PiperOrigin-RevId: 158292415
    
    ---
    Commit ba656b261 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use template specialization instead of overloaded methods. This is a more appropriate tool here. NFC
    
    PiperOrigin-RevId: 158292035
    
    ---
    Commit 55f987692 authored by Yutaka Leon<yleon@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
      Make tf.contrib.lookup  python functions use the kernels v2 that uses the resource tensor as handler.
    
    PiperOrigin-RevId: 158291836
    
    ---
    Commit ebae3deba authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Switch back to max_num_rows_to_load instead of reading slice by slice due to performance regression from network overhead.
    
    Add check when using initializing values to avoid seg fault
    
    PiperOrigin-RevId: 158291218
    
    ---
    Commit 7b4c01794 authored by RJ Ryan<rjryan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support numpy-style padding and slicing of tf.spectral.rfft/irfft to match the desired FFT length.
    
    Fixes incorrect RFFT/IRFFT results when fft_length does not match the input dimension.
    
    PiperOrigin-RevId: 158289991
    
    ---
    Commit fdb8e2935 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update iOS examples to use CocoaPods, and moved to tensorflow/examples/ios
    
    PiperOrigin-RevId: 158289285
    
    ---
    Commit d86167b5f authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Merging rc2 back into master.
    
    ---
    Commit dffea202a authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Clean up some code after previous CL
    
    PiperOrigin-RevId: 158282834
    
    ---
    Commit 7b5302af0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds ability to set a "family" attribute in Tensorflow summaries, which
    controls the "tab name" of the summary that is displayed.
    
    This solution keeps using name_scope to keep names unique, but then prefixes the tag with the family name if provided.
    
    PiperOrigin-RevId: 158278922
    
    ---
    Commit 611c82b5b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration test for DNNLinearCombined((Classifier)|(Regressor)).
    
    PiperOrigin-RevId: 158278512
    
    ---
    Commit cc6c91a9a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove a further unused proto header inclusion
    
    PiperOrigin-RevId: 158278026
    
    ---
    Commit 9f17c26ca authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add HloLocation to dataflow analysis.
    Add an HloLocation abstraction to dataflow analysis which indicates where (in the output of what instruction and at which index) an HloValue may appear. Previously only uses were stored with an HLO value where a use is an edge in the HLO graph (instruction, operand number and ShapeIndex).
    
    Also, change the handling of tuple-shaped kSelect instructions when ssa_form is true. Previously a phi value would be created. With this change the the value set instead contains the union of it's inputs identical to the ssa_form=false case.
    
    PiperOrigin-RevId: 158276598
    
    ---
    Commit b9d5e1441 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Start collecting flags for debug options in a single place.
    
    ClientLibraryTestBase will now parse command-line flags for debug options
    automatically, permitting subclasses to override certain options by using
    mutable_debug_options.
    
    main() still has to call AppendDebugOptionsFlags() explicitly before running
    the TF flag parser. In the mean-time, this CL leaves flag handling to the
    current "legacy" approach. However, this is part of a larger plan to move *all*
    debugging flags for XLA into the DebugOptions message and expose them as flags
    from a single place. The other flags (which are not controlling debugging
    options) will have to be propagated more explicitly.
    
    PiperOrigin-RevId: 158276294
    
    ---
    Commit 3b6fe94bb authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Properly handle shape nodes that have a preexisting control dependency
    
    PiperOrigin-RevId: 158274845
    
    ---
    Commit 1d67379d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup
    
    PiperOrigin-RevId: 158268933
    
    ---
    Commit 41997756c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Sort header inclusions; define EIGEN_USE_THREADS where headers depend on it.
    
    PiperOrigin-RevId: 158267803
    
    ---
    Commit 85355f015 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add missing header inclusion
    
    PiperOrigin-RevId: 158265934
    
    ---
    Commit 3cf88d390 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    When GPU is configured, do not require --config=cuda.
    Also fix indentation in configure.
    
    PiperOrigin-RevId: 158232959
    
    ---
    Commit f48673b50 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Removes ReductionFunctor for SYCLDevice (#10326)
    
    We are using Eigen implementation
    ---
    Commit 1b6453bec authored by Joan Puigcerver<joapuipe@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fixes issue #10258 (#10366)
    
    On CUDA versions previous to 8.0, only __shared__ variables could be declared as static in the device code.
    ---
    Commit cd56a638d authored by Beomsu Kim<123bskim@naver.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed wrong range in docstring (#10272)
    
    ---
    Commit d13ae380c authored by Micha? Jastrz?bski<michal.jastrzebski@intel.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix CMD in Dockerfile (#10444)
    
    Currently Notebook fails execution because default user for this container is root, and unless explicitly allowed, jupyter notebook will not start.
    ---
    Commit 8118ab4ec authored by Simon Perkins<simon.perkins@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Support partial gets in MapStagingArea (#10276)
    
    * Modify map staging area tests
    
    - size from `small` to `medium`
    - introduce 2 shards
    
    * Add partial get support in MapStagingArea
    
    A partial list of tensors in a (key, value) map entry can now be
    requested. Once all tensors associated with the entry are removed,
    it is removed from the map.
    
    * Correct output/indices mismatch errors
    
    * Rename IncompleteTuple to OptionalTuple
    
    * Add partial get test with indices
    
    * Add some more index checks
    
    * Improve stage test case graph creation
    
    Test sessions (and default graphs) are reused by default.
    Create explicit, finalized graphs in each test to prevent
    possible interactions between stateful Staging Areas and
    others ops created in separate tests.
    
    * Make staging area tests small and remove shards
    
    They were originally made 'medium' to ameliorate timeouts in the test
    case, but they usually run in ~1s so they should be small.
    
    * Improve imports
    
    Avoid importing base tensorflow package
    
    * Support both python 2 and python 3 range.
    
    * Set map_stage_op_test to size=large
    
    * Convert the tests to size=medium
    
    ---
    Commit 0df102b0a authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Update `configure` script sample (#10455)
    
    The `configure` script was changed regularly since the generation of the sample.
    This PR updates the sample to reflect those changes.
    ---
    Commit f6dc1ac61 authored by Earthson Lu<Earthson.Lu@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    MKL_INSTALL_PATH should not be ignore when given (#10180)
    
    * MKL_INSTALL_PATH should not be clear when given
    
    * fix overwrite by default
    
    ---
    Commit 8ad6a036e authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Java: Update Maven release to 1.2.0-rc2
    
    PiperOrigin-RevId: 158212897
    
    ---
    Commit 15eddf035 authored by Fritz Obermeyer<fritz.obermeyer@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Export C API symbols in _pywrap_tensorflow_internal.so (#10469)
    
    * Export C API symbols
    
    * Export C API symbols under config:default
    
    ---
    Commit 754e12668 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Removes half concat op registration (#10331)
    
    ---
    Commit cfdc22dee authored by Peng Yu<yupbank@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    fix the error (#10293)
    
    ---
    Commit 58747e357 authored by Joel Hestness<jthestness@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    PhiloxRandom: Fix race in GPU fill function (#10298)
    
    * PhiloxRandom: Fix race in GPU fill function
    
    The PhiloxRandom fill kernel for the GPU had race conditions that caused the
    outputs to be non-deterministic. In particular, the code previously executed
    with N GPU threads (# thread contexts per GPU), but it would only advance the
    fill addresses by N-1 stride in each step. This incorrect stride caused the
    0th and N-1st threads to write to the same memory locations, racing for which
    was last to write their common locations. Make the stride equal to the number
    of threads to eliminate the race.
    
    BONUS: By fixing this race, PhiloxRandom constant-sized GPU initializers now
    match CPU initializers.
    
    * Update random_ops_test.py to find race conditions
    
    Increasing the size of arrays in the random_ops_test.py test to manifest
    the race conditions to be resolved.
    
    ---
    Commit 2cbcda08f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed formatting in Linux install guide (#10353)
    
    Formatting issues were introduced in PR #8825, commit f30918b3694afe844990cbddc82e27e023d88856
    ---
    Commit ab5f38560 authored by Lakshay Garg<lakshayg@outlook.in>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fixed typos in documentation & READMEs (#10365)
    
    ---
    Commit 94dc1dbfa authored by Christos Nikolaou<cNikolaou@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Enable figures in the tfprof README.md (#10372)
    
    ---
    Commit 3018d4678 authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix typos (#10386)
    
    ---
    Commit c5f3c6171 authored by Daniel Rasmussen<drasmuss@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix unbatch for Datasets with multiple elements (#10401)
    
    * Fix unbatch for datasets with multiple elements
    
    * fixup! pylint (indent two spaces instead of four)
    
    ---
    Commit 8b065bc10 authored by Yong Tang<yong.tang.github@outlook.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    Fix unaligned args in api_docs/python/tf/contrib/learn/Evaluable (#10423)
    
    This commit fixes unaligned args in api_docs/python/tf/contrib/learn/Evaluable
    
    Signed-off-by: Yong Tang <yong.tang.github@outlook.com>
    ---
    Commit 8f89b654f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Profile memory usage in VirtualScheduler and report peak memory usage.
    To do so, NodeState now handles different output ports of a node (in case
    a node has multiple outputs).
    
    Also, VirtualScheduler code is cleaned up with more comments.
    
    PiperOrigin-RevId: 158209068
    
    ---
    Commit 0ea0bf5aa authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a frontend for viewing the first ops that exhibit bad values (NaN, +/- Inf).
    
    This helps the user identify problematic ops. Also moved the debugger data logic within tf-graph-info into a new tf-graph-debugger-data-card component.
    
    PiperOrigin-RevId: 158208679
    
    ---
    Commit ed47ecf2d authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Cleans variable op (#10333)
    
    * [OpenCL] Cleans variable op
    
    * Fixes formatting and float / double -> GPU_NUMBER_TYPES_NO_HALF
    
    ---
    Commit 9b2c1af63 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Improves device reporting (#10462)
    
    Prints: id, type, name, vendor and profile of the device
    ---
    Commit 7f5384dcc authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Making load() work for resource variables.
    
    PiperOrigin-RevId: 158205361
    
    ---
    Commit 05412bd36 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Simplify Shape traversal visitors.
    Simplify shape traversal visitors in ShapeUtil and ShapeTree. Add a non-Status form because most uses of the traversal methods do not use it, and remove is_leaf parameter from ShapeTree.ForEach* as it is not frequently used.
    
    PiperOrigin-RevId: 158201574
    
    ---
    Commit 69c9365b4 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extracted linear estimator testing utils to be reused by dnn-linear-combined.
    Added tests for linear part of dnn-linear-combined estimator.
    
    PiperOrigin-RevId: 158200827
    
    ---
    Commit 65ce8c723 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add arrowheads to dataflow edges.
    Make reference edges orange.
    Remove animations from tooltips in the graph documentation.
    
    Previously, arrowheads were only added to reference edges (because we assumed users knew about the convention that arrowless edges flow upwards). That decision nicely reduces clutter. However, recently, some internal and external folks have expressed confusion, and so I want to try adding arrowheads to all data flow edges. And make the reference edges starkly different.
    
    See #10428
    
    PiperOrigin-RevId: 158195388
    
    ---
    Commit bf4c3dd6b authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Revert "Fix patching issue on Windows" (#10472)
    
    This reverts commit 47e6785646a1266f01a1a570bd799f8518ee2997.
    
    ---
    Commit b49515539 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add only string constants to ASSET_FILEPATHS collection.
    
    PiperOrigin-RevId: 158192152
    
    ---
    Commit 51acad09c authored by Sergio Guadarrama<sguada@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add tests with different delta to huber_loss.
    
    PiperOrigin-RevId: 158191361
    
    ---
    Commit a4e7b7add authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes a bug in setting default optimizers for DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158190192
    
    ---
    Commit ddd67e333 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    [OpenCL] Cleans reshape.cc (#10347)
    
    * [OpenCL] Cleans reshape.cc
    
    * Removes half and complex numbers.
    
     Half is extension and complex numbers needs implementation in Eigen first
    
    ---
    Commit 3ca653304 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 158186454
    
    ---
    Commit 8cda8660e authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans sendrecv_ops.cc (#10345)
    
    ---
    Commit 6915bb919 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans Slice op (#10341)
    
    ---
    Commit 54998b45d authored by Michele Colombo<m-colombo@users.noreply.github.com>
    Committed by Jonathan Hseu<vomjom@vomjom.net>:
    BasicRNNCell comment fix (#10467)
    
    ---
    Commit df5906fb7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Mark saver/restore ops that depend on filesystem as stateful to disable them
    from being folded into a constant by graph optimizer.
    
    PiperOrigin-RevId: 158182282
    
    ---
    Commit 96cb4d182 authored by Sergio Guadarrama<sguada@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add support of scale_l1 == 0. or scale_l2 == 0 to l1_l2_regularizer.
    Added tests.
    
    PiperOrigin-RevId: 158179790
    
    ---
    Commit b65eb3f9b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Speed up atrous_convolution_test by combining evaluations.
    
    To make this test run faster (and prevent it from timing out under
    certain circumstances), this change combines all evaluations for each
    test method into a single call to Session.run, to eliminate overhead.
    
    This reduces the test time from about 40 seconds to 10 seconds.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 158175227
    
    ---
    Commit b440abce7 authored by Gao, Xiang<qasdfgtyuiop@gmail.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    add Cuda{2D,3D}LaunchConfig that maximizes occupancy (#10032)
    
    * add Cuda{2D,3D}LaunchConfig that max occupancy
    
    * remove default val, check input<=0
    
    * add max size check
    
    * fix typo
    
    * tests, docs, and related changes
    
    * build the test
    
    * buildify
    
    * cudaOccupancy... call check success, and style fix
    
    ---
    Commit 81cf61fdb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Initialize tensor in graph_properties_test, to avoid msan complaint.
    
    PiperOrigin-RevId: 158169374
    
    ---
    Commit cabc5c35c authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add xla_disable_hlo_passes to DebugOptions
    
    Also add a SetDebugOptions method to ClientLibraryTestBas; this lets us set
    debug options in tests by calling it.
    
    As an example, this CL removes the current way of passing
    xla_disable_hlo_passes programmatically in tests - it used to employ a special
    constructor parameter which is no longer required.
    
    PiperOrigin-RevId: 158169006
    
    ---
    Commit 187d23337 authored by Luke Iwanski<luke@codeplay.com>
    Committed by gunan<gunan@google.com>:
    [OpenCL] Cleans Pad op (#10339)
    
    ---
    Commit e8bc38ef6 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Fix test failures on windows. (#10470)
    
    ---
    Commit 2b3535c64 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor docstring fix for build_parsing_serving_input_receiver_fn
    
    PiperOrigin-RevId: 158163615
    
    ---
    Commit e55f2e036 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Propagates constants through switch nodes.
    
    PiperOrigin-RevId: 158163537
    
    ---
    Commit b01d4b905 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Remove outdated todo.
    
    PiperOrigin-RevId: 158161411
    
    ---
    Commit 7125733d7 authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Create a set of sample data for the audio plugin
    
    This implements a simple tone generator, with sine waves, square waves,
    and triangle waves, plus two simple combinations of sine waves. The step
    value is used to control the frequency.
    
    PiperOrigin-RevId: 158160889
    
    ---
    Commit dc81a2420 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Updates to the WALSMatrixFactorization estimator:
    - Add a completed_sweeps variable to keep track of sweeps that have been completed during training.
    - Add a StopAtSweepHook, which can request a stop after completing a specified number of sweeps.
    
    PiperOrigin-RevId: 158156347
    
    ---
    Commit 74220616c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set device cores and frequency in op_level_cost_estimator_test,
    to avoid asan error about assigning inf to int64 (this comes
    in from a divide-by-0).
    
    PiperOrigin-RevId: 158155488
    
    ---
    Commit 47e678564 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Fix patching issue on Windows (#10452)
    
    ---
    Commit 6d54f09d9 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Fix linking errors of lmdb on Windows (#10457)
    
    ---
    Commit 61c8a745b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup: Add braces around if statement arms; remove redundant "return" and "static".
    
    PiperOrigin-RevId: 158143418
    
    ---
    Commit e9a889c5e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Pass int parameter by value, not by const reference
    
    PiperOrigin-RevId: 158142102
    
    ---
    Commit 9184726ed authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid unnecessary copying of map data during visitation
    
    PiperOrigin-RevId: 158141962
    
    ---
    Commit 2e7e1d57b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Small fix for how std::move is used in constructors
    
    PiperOrigin-RevId: 158141564
    
    ---
    Commit 2a61c1652 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In cpu compiler's CompileAheadOfTime, pass ordering when compiling entry computation.
    
    PiperOrigin-RevId: 158140349
    
    ---
    Commit f3f53e8b3 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Add support for dicts and remove lists from nested structures.
    
    This changes the behavior of constructors like
    `tf.contrib.data.Dataset.from_tensors()` when passed a list. Previously, the
    `nest` utility would recurse into each element of such a list and create a
    separate Dataset component. Now the list will be converted to a tensor, allowing code like:
    
    ```python
    dataset = tf.contrib.data.Dataset.from_tensor_slices(([1, 2, 3], [4, 5, 6]))
    ```
    
    ...to define a dataset with two components (each of shape `()`).
    
    This change also adds support for dictionaries as nested structures, which
    simplifies integration with dictionary-returning ops like `tf.parse_example()`.
    
    Fixes #10151.
    
    RELNOTES: Breaking change to `tf.contrib.data.Dataset` APIs that expect a
    nested structure. Lists are now converted to tf.Tensor implicitly. You may need
    to change uses of lists to tuples in existing code. In addition, dicts are now
    supported as a nested structure.
    PiperOrigin-RevId: 158139467
    
    ---
    Commit b6a8848c1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Enabling python configuration to use a remotely generated configuration that is located inside of the org_tensorflow repo (previously it *had* to be a remote repo declared in workspace file).
    
    PiperOrigin-RevId: 158138601
    
    ---
    Commit 0fe0bfcc3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused protobuf header inclusions
    
    PiperOrigin-RevId: 158120864
    
    ---
    Commit f0c4c6c3f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW backward filter convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 158111294
    
    ---
    Commit 8dcf37b47 authored by Jon Malmaud<malmaud@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fix typo (#10379)
    
    ---
    Commit 3039d7da2 authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by gunan<gunan@google.com>:
    Remove "bazel clean" (#10318)
    
    Reverting #8880 (see #10236)
    unnecessary since bazelbuild/bazel#2759 was merged
    ---
    Commit ae1c16ae8 authored by Yifei Feng<fengyifei2026@gmail.com>
    Committed by gunan<gunan@google.com>:
    Update docker to cudnn6. (#10307)
    
    * Update docker to cudnn6.
    
    * Update Dockerfile.gpu
    
    * Add --expunge to bazel clean to make cuda_configure run again and update TF_CUDNN_VERSION.
    
    * Remove expunge and set CUDA and CUDNN version default in configure.
    
    * Update configure
    
    * Only set --action_env once
    
    * Update prints for default version.
    
    ---
    Commit 232e9d86d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tf_workspace() claims that the tf_repo_name argument is unused.
    temp_workaround_http_archive still requires it.
    This change silences the spurious message.
    
    PiperOrigin-RevId: 158089834
    
    ---
    Commit cc1a02d37 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add fp16 support to convolutional layers that support it.
    
    PiperOrigin-RevId: 158086284
    
    ---
    Commit 7d3fbba48 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extracted dnn estimator testing utils to be reused by dnn-linear-combined.
    Added tests for dnn part of dnn-linear-combined estimator.
    
    PiperOrigin-RevId: 158084898
    
    ---
    Commit 9d12c629c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor the document and some polishment
    
    PiperOrigin-RevId: 158083952
    
    ---
    Commit 134138299 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Corrected comment: import_scoped_metagraph does not return a Saver.
    
    PiperOrigin-RevId: 158082288
    
    ---
    Commit a58553e4d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add function in shape inference to try to infer output tensor content based on
    the input shapes of the op. In some cases (E.g: shape), knowing the shapes of
    the input is all that is necessary to infer the content of the output tensor.
    This improves shape inference.
    
    PiperOrigin-RevId: 158079306
    
    ---
    Commit 0cc851c08 authored by Yuefeng Zhou<yuefengz@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Call maxcut algorithm in the model_based_cost_estimator.
    
    PiperOrigin-RevId: 158078511
    
    ---
    Commit 7d76a90be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add question marks next to items in the graph legend.
    
    PiperOrigin-RevId: 158076005
    
    ---
    Commit 68fdb7628 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add DNNLinearCombinedClassifier.
    
    PiperOrigin-RevId: 158075939
    
    ---
    Commit 3d52e4cb9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix create_meta_graph to respect an empty collection_list.
    
    PiperOrigin-RevId: 158073112
    
    ---
    Commit 54ccc3e5a authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add module-scoped HLO dataflow analysis.
    This is the first step to replacing TuplePointsToAnalysis with a global, module-scoped analysis. This dataflow analysis identifies all values and their defs and uses in the XLA graph. The analysis is currently unused. Follow up CLs will add buffer alias analysis using this dataflow analysis, and incrementally switch the transformation passes (for example, CopyInsertion) to use these new module-scoped analyses.
    
    PiperOrigin-RevId: 158067910
    
    ---
    Commit 93c57c6e4 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Handle control flow logic properly:
     * Don't fold enter/exit nodes since that can interact badly with frames
     * Create proper control dependencies on switch nodes
    
    PiperOrigin-RevId: 158066691
    
    ---
    Commit 9e6899720 authored by Jingyue Wu<jingyue@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [SE] Add cudnnTransformTensor to StreamExecutor.
    
    PiperOrigin-RevId: 158062553
    
    ---
    Commit 827874c30 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW backward input convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 158061669
    
    ---
    Commit bee26215c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Speed up multinomial_op on CPU by using a vectorized Eigen expression and avoiding unnecessary casts.
    
    Benchmark with AVX+FMA enabled:
    
    Run on <redacted> (12 X 3492 MHz CPUs); 2017-06-05T12:54:07.881672447-07:00
    CPU: Intel Haswell with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:15MB
    Benchmark                          Base (ns)  New (ns) Improvement
    ------------------------------------------------------------------
    BM_Multinomial_cpu_1_10000_4          250817    172953    +31.0%
    BM_Multinomial_cpu_1_10000_128        273834    187552    +31.5%
    BM_Multinomial_cpu_1_10000_10000     1174175   1130778     +3.7%
    BM_Multinomial_cpu_1_100000_4        2040741   1276761    +37.4%
    BM_Multinomial_cpu_32_10000_4       10221765   4498666    +56.0%
    BM_Multinomial_cpu_32_10000_128     10638159   4994754    +53.0%
    BM_Multinomial_cpu_32_100000_4      100790019  44193314    +56.2%
    BM_Multinomial_cpu_128_100000_1     431269640  182506078    +57.7%
    PiperOrigin-RevId: 158061480
    
    ---
    Commit 515b3ac67 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add Clutz to TensorBoard build
    
    This is so we can get JavaScript protobufs. This CL also improves the
    web_aspect and makes some peculiar Closure Compiler errors go away
    relating to externs.
    
    PiperOrigin-RevId: 158061198
    
    ---
    Commit 0df6760fe authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added a test to make sure that graph properties for variables are properly
    reported
    
    PiperOrigin-RevId: 158053084
    
    ---
    Commit 2ccfe8e76 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added a new method to extract the graph properties from a cost graph without
    having to run the model. This will simplify the process of creating regression
    tests
    
    PiperOrigin-RevId: 158050327
    
    ---
    Commit 27f1b80c2 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes memory leak in py_func when functions return unwrapped strings.
    
    PiperOrigin-RevId: 158046530
    
    ---
    Commit cf238e1f2 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix memory leak in python caused by @tf_should_use.
    
    The issue is that python's GC has trouble collecting objects with __del__ methods.
    
    The solution is two pronged:
    * Keep track of usage state outside of the class, via a dict mapping
      id(object) => state
    * Remove __del__ (this was the source: python's GC couldn't collect wrapped
      objects), and instead use weakref.finalize to emit warnings just as the object
      is being garbage collected.
    * Added tests for garbage collection [they were failing before i fixed the issue]
    
    PiperOrigin-RevId: 158042388
    
    ---
    Commit e6f581863 authored by Bo Wang<david.b.wang@gmail.com>
    Committed by Rasmus Munk Larsen<rmlarsen@google.com>:
    New reader for LMDB databases (#9950)
    
    * Add LMDBReader op and test case
    
    * Add testcase to load LMDB from a folder
    
    * Add tensorflow/core/lib/lmdb/testdata/data.mdb
    
    * Add EOF test
    
    * Add license export
    
    * Blacklist the test data in pip_smoke_test.py
    
    * Address issues with respect to review
    
    * Add LICENSE to BUILD rules
    
    * Remove the prefx of LICENSE
    
    * Wrap key with compat.as_bytes()
    
    * Fixed a compilation flag
    
    * Improve BUILD rules
    
    * Support LMDB build in cmake
    
    * Fix BUILD file format with buildifier
    
    * Add fake unistd.h for lmdb to build on Windows
    
    * Avoid building lmdb tools which depends on unistd.h
    
    * Fix the string encoding issue in Python3
    
    * Update lmdb library name in CMakeList.txt
    
    ---
    Commit cc411f938 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    When converting the layout of Conv2DBackpropInput, we need to permute one of
    its inputs, which is a constant node. We permute a copy of this node, instead of the
    original node, because the original node may be used as input to other nodes.
    This kind of sharing of const node could arise if the graph is pre-optimized by common
    subexpression elimination, which is part of the L1 optimizations in
    TensorFlow.
    
    PiperOrigin-RevId: 158037552
    
    ---
    Commit 88bdb6fca authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove all remaining references to non-public TF modules from TensorBoard.
    
    I deleted the PluginAssetUtil tests because that code is deprecated.
    I'll later add manual testing for backcompat in the text plugin.
    
    PiperOrigin-RevId: 158037466
    
    ---
    Commit 6c531eb2f authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add file hash to Keras Boston Housing dataset to force cache update.
    
    PiperOrigin-RevId: 158036587
    
    ---
    Commit afdc38cd3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove deprecated resource handle functions in InferenceContext.
    
    PiperOrigin-RevId: 158034419
    
    ---
    Commit 9f932e6ce authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid parsing a rendezvous key for Send/Recv ops outside a loop.
    
    For such ops, the rendezvous key will be constant, because
    `ctx->frame_iter()` will always evaluate to `{0, 0}`. Benchmarking
    reveals that this can save between 1 and 2 microseconds per Send or
    Recv op execution. The optimization applies to all cross-process,
    inter-device, and intra-device (host-to/from-device memory) Send/Recv
    ops.
    
    PiperOrigin-RevId: 158032522
    
    ---
    Commit cc2dd4ac8 authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfdbg: dump debug data from different devices in separate directories
    
    Fixes: #7051
    wherein TFDBG failed to load the data dump from a Session.run() involving multiple GPUs.
    
    The root cause of the bug was that TFDBG previously assumed that node names are unique across all partition graphs. This is however not the case when multiple GPUs exist. The Send/Recv nodes in the partition graphs of the GPUs can have duplicate names. There will potentially be other cases like this in the future due to other reasons (e.g., distributed sessions and/or graph optimization).
    
    This CL relaxes this assumption, by dumping the GraphDef and tensor data from different devices into different sub-directories under the dump root directory.
    
    PiperOrigin-RevId: 158029814
    
    ---
    Commit a5909d643 authored by Toby Boyd<tobyboyd@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixed triggering create device multiple times
    
    PiperOrigin-RevId: 158025196
    
    ---
    Commit 504a307b7 authored by Martin Wicke<wicke@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make sure that Adam colocates ops with a consistent variable across workers.
    
    PiperOrigin-RevId: 158022292
    
    ---
    Commit 69ba4d3d4 authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix #10371
    
    cpuinfo.get_cpu_info() doesn't seem to include the l2_cache_size key on some
    architectures.
    
    PiperOrigin-RevId: 158021008
    
    ---
    Commit a51a9846c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Performance-related tweaks: Don't copy loop variables; remove ineffective std::move casts.
    
    PiperOrigin-RevId: 158017670
    
    ---
    Commit 009789f74 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Allow 0-sized slices in DynamicSlice and DynamicUpdateSlice; add tests.
    
    PiperOrigin-RevId: 158015870
    
    ---
    Commit 48a4853eb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Miscellaneous cleanups
    
    PiperOrigin-RevId: 158012131
    
    ---
    Commit 379ddde24 authored by Chris Song<sjhshy@gmail.com>
    Committed by Chris Song<sjhshy@gmail.com>:
    Fix misspells.
    
    ---
    Commit a0a76da97 authored by Lakshay Garg<lakshay.garg.1996@gmail.com>
    Committed by Lakshay Garg<lakshay.garg.1996@gmail.com>:
    Fixed typo in code
    
    ---
    Commit 7ffc35732 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add support for bools in matrix_diag, matrix_diag_part, matrix_set_diag, matrix_band_part.
    
    PiperOrigin-RevId: 157939272
    
    ---
    Commit edf3d5dbe authored by Darren Garvey<darren.garvey@gmail.com>
    Committed by Darren Garvey<darren.garvey@gmail.com>:
    configure: Fix default path when enabling MPI.
    
    Correct showing what the default path is when mpi is installed.
    
    ---
    Commit aad2e3daf authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast NCHW forward convolution for images smaller than 16x16.
    
    PiperOrigin-RevId: 157915637
    
    ---
    Commit 5cf08d9cb authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Drop blockDim.y for the equivalent in_cols, and slightly improve naming (use 'pixels' instead of 'size' for height*width numbers).
    
    PiperOrigin-RevId: 157906773
    
    ---
    Commit 563f05ff6 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Expand tile_batch to handle nested structures.
    
    This allows it to properly tile the initial wrapper state when using
    BeamSearchDecoder with AttentionWrapper.  Unit tests updated to show this use.
    
    PiperOrigin-RevId: 157903115
    
    ---
    Commit 1234e2dda authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix Plottable definition
    
    On Mac OS the build directory in the Node package conflicts with BUILD.
    
    PiperOrigin-RevId: 157899970
    
    ---
    Commit bb7a8d8e7 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Don't use the _output_shape attribute in the op_level_cost_estimator since
    there is no guaranty that it will be present or accurate.
    
    PiperOrigin-RevId: 157898989
    
    ---
    Commit 6f4204c3d authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix TensorBoard SHA256 in cmake
    
    PiperOrigin-RevId: 157897958
    
    ---
    Commit c9d2f432b authored by Justine Tunney<jart@google.com>
    Committed by Justine Tunney<jart@google.com>:
    Fix TensorBoard SHA256 in cmake
    
    ---
    Commit 1c70fb686 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add training test for multi classes (n>2) linear classifier.
    
    PiperOrigin-RevId: 157896002
    
    ---
    Commit 675d36be0 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add fused batch norm to tf.layers.
    
    PiperOrigin-RevId: 157893874
    
    ---
    Commit f37d0ea47 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change -- first draft docs
    
    PiperOrigin-RevId: 157891937
    
    ---
    Commit 9b8f6113b authored by Zongheng Yang<zongheng@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tensor_bundle: fix that the read path forgets to cache file handles.
    
    In a case where a reader is geographically far from the file, this change
    achieves a speedup of end-to-end checkpoint restore by 5.8x.
    
    PiperOrigin-RevId: 157889659
    
    ---
    Commit 0c92dada6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use inplace Cholesky factorization and solves to speed up and reduce memory usage in matrix_solve_ls.
    Check succes before copying outputs in cholesky_op.
    
    PiperOrigin-RevId: 157887564
    
    ---
    Commit a4caeb2ea authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extract the graphs dashboard to a plugin
    
    This completes the great plugin migration!
    
    The graphs plugin is somewhat different from the plugins considered so
    far. First, it exposes two kinds of data: graph data and run metadata.
    We elect to put both sources of data under the domain of the graphs
    plugin for now, because it's not clear that the run metadata would be
    useful for anything else. Second, the graph data really has no use for
    "tags": a run either has an associated graph or it does not. Thus, we
    expose an endpoint /data/plugin/graphs/runs that is different in format
    from the /tags routes exposed by other plugins (it returns just a list
    instead of a run-to-tag mapping).
    
    This change removes a bunch of tests from application_test.py. The tests
    cover the compresion behavior of the graph endpoint, but the graph
    endpoint doesn't have any special logic in the way of compression. Thus,
    the tests are, apparently, testing that werkzeug (or whatever is
    relevant here) provides good compression defaults. This isn't
    necessarily a bad idea, but it shouldn't be coupled to the graph tests.
    
    To get test data that includes run metadata, you can run this script:
    
        https://raw.githubusercontent.com/tensorflow/tensorflow/326942394e69074d50d5889218a24c9371eff259/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py
    
    PiperOrigin-RevId: 157884714
    
    ---
    Commit 05a6a13f7 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by gunan<gunan@google.com>:
    Make sure all writer caches are closed before deleting directories in dnn_test.
    
    ---
    Commit d0e761f8d authored by Gunhan Gulsoy<gunan@google.com>
    Committed by gunan<gunan@google.com>:
    Disable another test that uses matrix_set_diag on windows.
    
    ---
    Commit 8939b8562 authored by Derek Murray<mrry@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf.contrib.data] Re-implement IteratorGetNext as an AsyncOpKernel.
    
    This prevents the op from consuming an inter-op thread pool thread
    when blocked, and fixes a potential deadlock when many IteratorGetNext
    ops are blocked. Fixes #10369.
    
    PiperOrigin-RevId: 157878885
    
    ---
    Commit 9e25c68ad authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add loss_only_head to hold additional loss terms for multi_head setup
    
    PiperOrigin-RevId: 157875934
    
    ---
    Commit 7cdcd0cca authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Filter more op types that don't benefit from constant folding.
    
    PiperOrigin-RevId: 157875168
    
    ---
    Commit 366990d92 authored by Kay Zhu<kayzhu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Fix a subtle issue in copy_insertion due the interaction between copy
    overriding logic and RecordIndicesToColocatingBuffers:
    
    - When building instructions ShapeTree to be copy overriden, it is possible
    that we create a single kCopy for two identical instructions. An example can
    be:
    
        %tuple.19 = tuple(%constant.4, %constant.1793, %constant.1793)
    
    where it is used in a while.init operand, and constant.1793 is read-only within
    the loop and also used by another while loop. The copy overriding pass will then
    create the following (logical, not finalized) tuple:
    
        %tuple.19 = tuple(%constant.4, %copy.5, %copy.5)
    
    - In the subsequent pass RecordAmbiguousOrNonDistinctIndices, to add copies to
    ensure point_to set is distinct, the duplicate %copy.5 are ignored because they
    are not yet finalized, and these indices (1 and 2 in the example) are still
    marked as to-be copied.
    
    Therefore distinctiveness is lost.
    
    This fix applies to the override building stage, to explicitly avoid creating
    shared copies for non-distinct buffers.
    
    PiperOrigin-RevId: 157872231
    
    ---
    Commit f4b8d21b8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change function parameters to references to avoid copying, or otherwise move from function parameters when moving reduces the amount of copying.
    
    PiperOrigin-RevId: 157867333
    
    ---
    Commit 3eee61caa authored by Drew Hintz<pushespretn@gmail.com>
    Committed by GitHub<noreply@github.com>:
    fix quotes in example code from ? to "
    ---
    Commit 4905c0eae authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove TODO - the new tolerance is okay to keep.
    
    PiperOrigin-RevId: 157861020
    
    ---
    Commit 55f6b6ff1 authored by David Soergel<soergel@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add explicit SparseTensor support to SignatureDef.
    
    PiperOrigin-RevId: 157860466
    
    ---
    Commit 79099d677 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Removes default thresholds from BinaryLogisticHead and adds predict and evaluate tests for DNNClassifier.
    
    PiperOrigin-RevId: 157856471
    
    ---
    Commit 54595f0f3 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds the training test for LinearClassifier with n_classes=2.
    
    PiperOrigin-RevId: 157855473
    
    ---
    Commit cd6c02985 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add 'streaming_curve_points' metric which returns curve [ROC, PR] approximation at specified number of points.
    
    PiperOrigin-RevId: 157851535
    
    ---
    Commit 0f2db7391 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Split union-find implementation in mark_for_compilation_pass.cc into a separate library, make it more generic.
    
    PiperOrigin-RevId: 157850985
    
    ---
    Commit d5421cf58 authored by Justin Lebar<jlebar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add additional concat test.
    
    PiperOrigin-RevId: 157844113
    
    ---
    Commit f661128db authored by Geoffrey Irving<geoffreyi@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused overloads of SummarizeGraphDef and EqualGraphDef
    
    PiperOrigin-RevId: 157843404
    
    ---
    Commit a56d59a84 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set flow to a value during TensorArray creation,
    Re-enable tensor_array_ops_test in msan.
    
    PiperOrigin-RevId: 157841785
    
    ---
    Commit edcc5cc13 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add manual test runner for vz_sorting
    
    PiperOrigin-RevId: 157841098
    
    ---
    Commit 3f6404f20 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Assign a max height of 800px to images in the image dashboard.
    
    The user could always expand to actual dimensions if need be.
    
    PiperOrigin-RevId: 157838046
    
    ---
    Commit c6ea6972a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove debugging LOG(INFO) from previous change.
    
    PiperOrigin-RevId: 157837305
    
    ---
    Commit 07d39f28e authored by freedom" Koan-Sin Tan<koansin.tan@gmail.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    make gcc-5 on Ubuntu 16.04 happy (#10385)
    
    gcc-5 complains of ambiguity and refuses to go when doing something
    like 'bazel build -c opt tensorflow/...'
    ---
    Commit ac66be783 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Minor cleanup: Remove unused BUILD dependencies and unnecessary code.
    
    PiperOrigin-RevId: 157837211
    
    ---
    Commit 4161ccc8e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adjust tolerance on dirichlet_multinomial test.
    
    PiperOrigin-RevId: 157834660
    
    ---
    Commit 43c0f52f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix off-by-one error in BoolVector(begin, end) constructor.
    
    PiperOrigin-RevId: 157833086
    
    ---
    Commit 419d437ba authored by Lakshay Garg<lakshay.garg.1996@gmail.com>
    Committed by Lakshay Garg<lakshay.garg.1996@gmail.com>:
    Fixed typo in code comment
    
    ---
    Commit 07710014d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix device colocation for KMeans in case of multiple parameter servers.
    
    PiperOrigin-RevId: 157795360
    
    ---
    Commit b659bc39f authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Simplify TensorBoard build
    
    - Remove tensorboard_typescript_genrule
    - Remove tensorboard_typescript_bundle
    - Introduce ts_web_library Skylark rule which supports seamless
      TypeScript compilation.
    - Use Closure Compiler in semi-advanced mode to compile JavaScript.
      This is done in a way that preserves <script> tag placement, which
      causes pages to load faster and avoid FOUC, thereby making it a
      better solution than the existing vulcanize.
    
    PiperOrigin-RevId: 157794795
    
    ---
    Commit 0503ce09c authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Wipe out previous shape inference result when importing a grappler item
    Run graph optimizations last: since they can be expensive it's best to filter invalid items first.
    
    PiperOrigin-RevId: 157792834
    
    ---
    Commit 9ae941c4a authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Turn reductions along an empty set of dimensions into identity nodes.
    
    PiperOrigin-RevId: 157792209
    
    ---
    Commit 69075f354 authored by Yangzihao Wang<yangzihao@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add functional support for cudnnConvolutionBiasActivationForward().
    
    PiperOrigin-RevId: 157788425
    
    ---
    Commit 7d7a40309 authored by William Chargin<wchargin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Extract the distributions dashboard to a plugin
    
    This continues the great plugin migration. The distributions plugin was
    similar to the histograms plugin, but it also purported to allow CSV
    download like the scalars plugin. However, the existing implementation
    of this was flawed, and would always yield a 500 on current prod [1]
    (unless there were actually no data). This indicates that no one is
    actually using it---probably because there isn't a relevant button on
    the frontend, anyway!---so I just removed it.
    
    This also changes most frontend occurrences of "compressedHistograms"
    to "distributions" while we're at it.
    
    [1]: Due to the reference `value.rank_in_bps` in the handler
    `_serve_compressed_histograms`; this field does not exist and throws an
    `AttributeError`.
    
    PiperOrigin-RevId: 157787156
    
    ---
    Commit 23cdf96b8 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Re-enable session_test.py
    
    A number of CL's have split up session_test.py to be a bit smaller. As a
    result, this CL will re-enable the session_test to see if it remains flaky.
    
    PiperOrigin-RevId: 157786407
    
    ---
    Commit d741d81c5 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expose tf.test.StubOutForTesting in the tf testing api
    
    Also redirect TensorBoard usage to use that endpoint.
    
    This is part of my ongoing effort to have TensorBoard only
    depend on TensorFlow via its public api, so that it can
    be split into a project with a fast external build.
    
    PiperOrigin-RevId: 157784552
    
    ---
    Commit 40411cd5c authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor projector plugin to only use tf public methods.
    
    Remove all reference to the PluginAsset system, which is deprecated.
    
    Part of an ongoing effort to have TensorBoard only consume the public
    TensorFlow api.
    
    PiperOrigin-RevId: 157784016
    
    ---
    Commit a65a70ea5 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix pip tests under contrib/text
    
    PiperOrigin-RevId: 157783952
    
    ---
    Commit fb4bc806a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix flakiness in GpuMultiSessionMemoryTest.
    
    PiperOrigin-RevId: 157781368
    
    ---
    Commit f7de292df authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update placeholder nodes' shapes in the GraphDef to reflect manually specified values for incomplete placeholder shapes. Previously, these overrides were only specified in the feed nodes, which improves estimates when using dynamic shapes but not when using static shapes. With this change, static shapes also benefit.
    
    PiperOrigin-RevId: 157780800
    
    ---
    Commit eebd44123 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a frontend method for retrieving numeric alerts from the debugger plugin.
    
    This route responds with a list of alerts (occurrences of bad values) in ascending timestamp order.
    
    PiperOrigin-RevId: 157780270
    
    ---
    Commit 5bc685d7f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] If an op has a single "large" operand, we want to fuse this op into some of its consumers, even if we can't fuse into all of them.
    
    PiperOrigin-RevId: 157779106
    
    ---
    Commit 2ee09b873 authored by Mark Heffernan<meheff@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Various improvements to ShapeTree.
    Add support for holding non-copyable types, operator==, and a
    CopySubtreeFrom method for copying a subtree from one ShapeTree to
    another.
    
    PiperOrigin-RevId: 157777636
    
    ---
    Commit 4f3ae7699 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add beam_search kernels used by BeamSearchDecoder to tensorflow.contrib.
    
    PiperOrigin-RevId: 157775011
    
    ---
    Commit 6b16c33b3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make audio-related logic use the audio plugin.
    
    Previously, fetching audio and related data from TensorBoard used handlers within application.py. We now remove those handlers in favor of routes offered by the audio plugin. ML Dash is updated as well.
    
    PiperOrigin-RevId: 157774953
    
    ---
    Commit 8032e1f75 authored by Geoffrey Irving<geoffreyi@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make function instantiation use std::vector<NodeDef> instead of GraphDef
    
    It's about to turn into std::vector<NodeInfoPtr>; this change gets us partway there.
    
    RELNOTES: n/a
    PiperOrigin-RevId: 157771141
    
    ---
    Commit 2e44be35d authored by Vinu Rajashekhar<vinuraja@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds a protected DeleteResourceMgr(...) method in Device.
    
    PiperOrigin-RevId: 157770378
    
    ---
    Commit cc346e690 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Strip the :x suffix when generating control inputs from input names
    
    PiperOrigin-RevId: 157770257
    
    ---
    Commit d6fe47af5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use tensorflow::StringPiece in literal_util.
    Use template for RepeatedField assignment.
    
    PiperOrigin-RevId: 157765477
    
    ---
    Commit 7866fa01b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    This change significantly reduces time and resources used to load large TensorFlow graphs.
    
    For a real-world large graph (13k nodes, 20k edges), this change:
    
    * reduces all heap allocations by 19%
    * reduces retained (final) heap allocations by 2.2%
    * reduces CPU time by 11.2%
    
    In most TF graphs, the set of unique values set to Node::assigned_device_name() is quite small.  This change adds an interning table to the Graph object, which contains all of the unique values used for Node::set_assigned_device_name(), as well as a look-up table.  This is the main source of the reduction in retained heap memory; nearly all nodes are assigned to just one or two unique devices.
    
    This change removes the "string assigned_device_name_" field from the Node class, and replaces it with "int assigned_device_name_index_".  However, because you need both the index and the name table to get the actual value, the Node::assigned_device_name() accessor needs access to the parent Graph.  This requires adding a "Graph* graph_" field to the Node class.
    
    In the future, if all users of this property are converted to use Graph::assigned_device_name(Node*), then the Node::graph_ field can be deleted, and the space reclaimed.  However, doing so is out of the scope of this CL, and even with this new pointer field, the Node class is smaller than it was before, so this is still a net win.
    
    The placement algorithm in simple_placer.cc is one of the main accessors of the Node::assigned_device_name property.  This CL contains significant changes to simple_placer.cc, which directly take advantage of the fact that the property is an index into a name table, rather than treating it simply as a string.  Many temporary allocations are also removed, which is the main source of the reduction in total heap allocations.
    
    This CL also contains a few changes that remove short-lived allocations in unrelated code, such as the changes in op.cc/h, costmodel.cc, etc.  It is extremely easy in C++ to accidentally allocate memory, especially when implicit conversions and copy constructors allocate memory.
    
    All of the changes in this CL were motivated by empirical measurement, using CPU profiling and heap profiling.
    
    PiperOrigin-RevId: 157762909
    
    ---
    Commit fdffafbc1 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add QueueDequeueUpTo to the list of dequeue ops
    
    PiperOrigin-RevId: 157760201
    
    ---
    Commit 7ad0d0698 authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add type error to start_queue_runners if given session is not a `tf.Session`. Due to semver, we suppress the error if a MonitoredSession is provided.
    
    PiperOrigin-RevId: 157748375
    
    ---
    Commit 7106f9fac authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Implemented an initial version of virtual scheduler unit test.
    
    PiperOrigin-RevId: 157746305
    
    ---
    Commit b020db0c6 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    revert public visibility
    
    ---
    Commit 5b05728c2 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround 3
    
    ---
    Commit 15a740ebb authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update and Move DNNLinearCombinedRegressor to estimator/canned.
    
    PiperOrigin-RevId: 157744087
    
    ---
    Commit d29bbeca3 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix outdated code ref in TensorBoard README, add link to SO question.
    
    PiperOrigin-RevId: 157743374
    
    ---
    Commit 9fc164225 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix index_table_from_file to allow vocabulary_file be a Tensor
    
    PiperOrigin-RevId: 157740677
    
    ---
    Commit 0aa3e0194 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Internal change
    
    PiperOrigin-RevId: 157740660
    
    ---
    Commit 02ac85399 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduce new class Literal to replace protobuf Literal.
    
    This renames the existing Literal message to LiteralProto and introduces a new
    C++ class named Literal to replace it.
    
    The LiteralProto is only used at RPC boundaries, or when protobuf-specific
    functionality is required.  The Literal class offers a 'ToProto' function to
    generate a new LiteralProto message when necessary.
    
    Currently, all the static functions in class LiteralUtil, just forward to their
    counterparts in class Literal.  This will change in a future CL.
    
    Class Literal implements all the buffers as std::vectors.  The only exception
    is preds(), which given the std::vector<bool> representation, makes it unusable
    for the semantics we require (it's not possible to get the address of the
    underlying vector, for instance).
    
    The CL adds a BoolVector class to work around that issue.
    
    In future CLs, the std::vector representation may be changed to something more
    efficient, if needed.
    
    PiperOrigin-RevId: 157739125
    
    ---
    Commit 207203253 authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Python 3.6 support on windows. (#10356)
    
    * Python 3.6 support on windows.
    
    * Fix typo in README.md
    
    * Make environment configurable for windows gpu build.
    
    ---
    Commit 2b75a9a6e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157734029
    
    ---
    Commit f60b6bdcb authored by Mustafa Ispir<ispir@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a warning to documentation of MonitoredSession.
    
    PiperOrigin-RevId: 157728225
    
    ---
    Commit eb10a4c49 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Preallocate vector storage when the ultimate vector size is known in advance
    
    PiperOrigin-RevId: 157724431
    
    ---
    Commit ce32228c4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add release notes for Intel MKL integration.
    
    PiperOrigin-RevId: 157722003
    
    ---
    Commit a23255bc0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds missing group OP to benchmark
    
    PiperOrigin-RevId: 157716500
    
    ---
    Commit d3e840a6c authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Disable writing of compressed checkpoints.
    
    Snappy compression (and decompression) was enabled after the
    1.1 release (in commit 63b2f999d3f22cfe915b89103faa1b0a1b1b7617).
    This means that checkpoints produced by the 1.2.0 release candidates
    will cause TensorFlow 1.1 (and prior) binaries to crash as they
    CHECK fail when trying to load snappy-compressed tables.
    
    To ease transition, disable writing of compressed checkpoints in
    1.2.0 for now.
    
    Reconsider this in the next release.
    
    PiperOrigin-RevId: 157675189
    
    ---
    Commit 6db400bbc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactoring Python op code generation.
    
    PiperOrigin-RevId: 157675126
    
    ---
    Commit d9620cab8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add flag to determine whether to do L1 optimizations and inline functions. Default is to do them. In tf_optimizer don't inline or do l1 optimizations.
    
    PiperOrigin-RevId: 157673614
    
    ---
    Commit 25bb504cc authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make a plugin that serves data for the audio dashboard.
    
    Subsequent changes will make TensorBoard use this audio plugin instead of the previous handlers for audio-related data.
    
    PiperOrigin-RevId: 157673132
    
    ---
    Commit 24623653b authored by James Qin<jamesqin@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix graph text format serialization
    
    PiperOrigin-RevId: 157669530
    
    ---
    Commit 3aed1735c authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround 2
    
    ---
    Commit fea90f89d authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    visibility workaround
    
    ---
    Commit 732a6b1ae authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Upgrade TypeScript to v2.3.4
    
    PiperOrigin-RevId: 157667511
    
    ---
    Commit 95d90ab2e authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Fixes Split op (#10322)
    
    * [OpenCL] Fixes Split op
    
      Split should alway go through SYCL device
    
    * [OpenCL] Removes half from registred types
    
    ---
    Commit 963441400 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Extends softmax op to cover double (#10323)
    
    ---
    Commit a702863e8 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Extends tile ops to int16 and int32 (#10328)
    
    * [OpenCL] Extends tile ops to int16 and int32
    
    * [OpenCL] Extends tile_ops to cover bool, uint8, int16, int64
    
    ---
    Commit 75385814f authored by cxx<cxxgtxy@gmail.com>
    Committed by cxx<cxxgtxy@gmail.com>:
    Fix comments error in mnist_replica.py where only one ps is used with two works by default.
    
    ---
    Commit 23364e2c6 authored by Andrew Harp<andrewharp@google.com>
    Committed by Andrew Harp<andrewharp@google.com>:
    buildifier fix
    
    ---
    Commit e5088cb82 authored by Yao Zhang<yaozhang@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix discrepancy between measured and analytical cost graph. Use tf_cuda_library for utils.
    
    PiperOrigin-RevId: 157660745
    
    ---
    Commit 787381ca5 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_clusterspec_prop_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157658981
    
    ---
    Commit b09932d74 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Added PlaceholderWithDefault to the list of known placeholder types
    Use PartialTensorShape instead of TensorShapes to better handle partially known
    shapes
    
    PiperOrigin-RevId: 157657664
    
    ---
    Commit 0462416f6 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add make_ndarray, tensor_proto, and MetaGraphDef to tf api.
    
    Since TensorProtos are part of the TensorFlow API, it makes sense
    to also include the methods that generate and parse them.
    
    Similarly, we write out MetaGraphDef protos in the summary writer,
    so we should provide the proto as well.
    
    This is part of an ongoing effort to have TensorBoard only consume
    TensorFlow methods through the public api.
    
    PiperOrigin-RevId: 157657564
    
    ---
    Commit 458f94c12 authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Open-source skip-gram ops
    
    PiperOrigin-RevId: 157655970
    
    ---
    Commit faac0331c authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Introduce tensorboard_zip_file build rule
    
    This rule can depend on web_library or tensorboard_html_binary. In
    both cases it will create a .zip file containing all the transitive
    web server paths. This can be used to deploy static assets to web
    servers.
    
    A small change was also made to Vulcanize to support path overriding.
    
    PiperOrigin-RevId: 157655047
    
    ---
    Commit 7ed44f4c9 authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_partial_run_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157651813
    
    ---
    Commit 3c7ac46ae authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Teach Executable to do its own profiling (patch 4/4).
    
    This CL removes the xla::Service stub for ExecuteOnStreamWrapper so the users call the xla::Executable version directly, and simplifies the function API to simply accept "arguments" as a parameter (with a templated type) rather than requiring the user to capture it into a lambda around the relevant Executable::ExecuteOnStream method.
    
    PiperOrigin-RevId: 157651740
    
    ---
    Commit 626f95ab9 authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] Don't enforce that all nodes in an encapsulated subgraph are on the same device.
    Use the assigned device rather than the user-requested device when converting a Graph to a FunctionDef.
    
    PiperOrigin-RevId: 157648977
    
    ---
    Commit 414470329 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Guard stream pool with mutex.
    
    A data race can occur while populating the map.
    
    PiperOrigin-RevId: 157647183
    
    ---
    Commit ccdb30763 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Additional colocation options and bugfixes for TensorArray
    
    * colocate_with is now set properly when a TensorArray is passed through a
      while_loop
    * added a new argument, "colocate_with_first_write" (default: True; this is
      the current behavior).  If False, the TensorArray is simply placed on the
      device from the context it's constructed in, and no colocation constraints
      are added.
    
    PiperOrigin-RevId: 157643133
    
    ---
    Commit 03fc7022b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157642677
    
    ---
    Commit 41b87d6ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add a new attribute narrow_range to FakeQuant* operations.  It quantizes into range [1; 255] instead of [0; 255].
    
    PiperOrigin-RevId: 157641054
    
    ---
    Commit c048e2938 authored by Alexandre Passos<apassos@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds support to non-placeholder inputs in _graph_to_function_def.
    
    Specifically, supports input ops with more than one output tensor.
    
    PiperOrigin-RevId: 157640908
    
    ---
    Commit d310de4fa authored by Brennan Saeta<saeta@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Split up session_test.py -> session_list_devices_test.py
    
    session_test.py has gotten very large. Additionally, recently it has become
    flaky. In order to both (1) improve overall code health, and (2) to facilitate
    root-causing the test flakiness, this CL begins to split apart session_test
    into focused subsets.
    
    I've suffixed the scoping of the session_test in order to preserve filesystem
    sort-order grouping.
    
    PiperOrigin-RevId: 157640788
    
    ---
    Commit 8e868cf6a authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused arguments to call_cpp_shape_fn.
    
    PiperOrigin-RevId: 157640125
    
    ---
    Commit 9ddbf31fe authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use unnamed namespace to effect internal linkage, replace string constructors with array-deducing helper function
    
    PiperOrigin-RevId: 157636308
    
    ---
    Commit 88ffe6276 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Increase cholesky_op_test to medium, bump shard_count 1 more.
    
    PiperOrigin-RevId: 157635774
    
    ---
    Commit bef563dc8 authored by Benjamin Kramer<kramerb@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Don't add constraints for computations we're not currently looking at.
    
    TuplePointsToAnalysis is computed globally per module, so we add all
    unconstrained buffers in that module, even if it's outside of the computation
    we're currently running on. Then we proceed to propagate default layouts to all
    those buffers and then throw the constraints away because they don't affect any
    instruction in the current computation.
    
    PiperOrigin-RevId: 157635564
    
    ---
    Commit a980aead8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use test_adjusted_name when making the mangled_test_name in
    run_and_gather_logs_lib.py, to avoid duplicate file names when the same test is
    run on multiple GPUs.
    
    PiperOrigin-RevId: 157630193
    
    ---
    Commit 0a84cfd58 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157629497
    
    ---
    Commit 6882effb8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make single-parameter constructors explicit
    
    PiperOrigin-RevId: 157628970
    
    ---
    Commit 0b8070253 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Support negative axis for Split op
    
    PiperOrigin-RevId: 157628162
    
    ---
    Commit 289e7bf5b authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Fixes and improvements to cmake windows build. (#10354)
    
    * Disable linalg ops tests on windows.
    
    * Do not print the full source code path for logs on windows.
    
    ---
    Commit bc236cfc3 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Passes classification head to LinearClassifier.
    
    PiperOrigin-RevId: 157624020
    
    ---
    Commit cebd7e246 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Shanqing Cai<cais@google.com>:
    [OpenCL] Cleans debug ops (#10334)
    
    * [OpenCL] Cleans debug ops
    
    * Acts on feedback from #10334#discussion_r119452513
    
    * Acts on #10334#discussion_r119459463
    
    ---
    Commit fd6c3c4f1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixes flaky test in dnn_linear_combined_test.
    
    PiperOrigin-RevId: 157622951
    
    ---
    Commit c9cc388dc authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Avoid CHECKs in BundleReader, propagate errors instead.
    
    Motivation:
    We'd like to evolve the checkpoint format over time (e.g., enable
    different types of compression). Without this change, a TensorFlow
    version that encounters a format that it doesn't understand would CHECK fail
    with an unhelpful error message.
    
    With this, it propagates a clearer error message up, giving the user some
    hints about what could be wrong.
    
    I don't have a unittest for this - I thought about writing a bundle and
    then strategically corrupting the bytes on disk before reading it back,
    but that seems a bit much. The intention of this change is to enable
    graceful reporting of forward compatibility breakages. Ideas for an
    appropriate unittest are appreciated.
    
    PiperOrigin-RevId: 157620358
    
    ---
    Commit ee05b8b69 authored by Wei Ho<weiho@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix to remove TF op usage outside of the initializer fn (due to deferred execution of initializer fn, this prevent issues with graph mismatch).
    
    PiperOrigin-RevId: 157620177
    
    ---
    Commit e8d17ea8c authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Materialize shapes that are known at graph construction time into constants
    that can be folded
    
    PiperOrigin-RevId: 157619380
    
    ---
    Commit dc0427d48 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Directly depend on the used libraries
    
    Do not rely on transitive dependencies.
    
    PiperOrigin-RevId: 157618184
    
    ---
    Commit 964d1a509 authored by Yuan Yu<yuanbyu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix a bug that an erroneous control edge can be introduced when loops are nested in control dependency context.
    
    PiperOrigin-RevId: 157616919
    
    ---
    Commit 2de94bbb8 authored by Eli Bendersky<eliben@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Add an option to set the "generate HLO graph" regex without a flag.
    
    Pipes the option through xla.proto ExecutionOptions, to HloModuleConfig, which
    can then be accessed throughout the compiler.
    
    PiperOrigin-RevId: 157615458
    
    ---
    Commit d3c0482e6 authored by My name is<raviqqe@gmail.com>
    Committed by gunan<gunan@google.com>:
    Fix a typo in export_output.py (#9975)
    
    ---
    Commit 0c75d9f52 authored by ddurham2<ddurham@davyandbeth.com>
    Committed by gunan<gunan@google.com>:
    Adding lost documentation to tf.abs from the old tf.complex_abs when it learned how to work on complex data. (#9954)
    
    ---
    Commit 84661fa73 authored by Benoit Steiner<bsteiner@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Propagate control dependencies during constant folding
    
    PiperOrigin-RevId: 157610040
    
    ---
    Commit a3520340e authored by gunan<gunan@google.com>
    Committed by GitHub<noreply@github.com>:
    Improve windows bazel python test suite. (#10305)
    
    * Improve windows bazel python test suite.
    
    - Create new tags, no_windows and no_windows_gpu
    - Instead of a separate maintained list, use bazel tags to exclude tests.
    - Tag all the python tests that are known to have issues in windows.
    
    * Also blacklist neon_depthwise_conv_ops_test in windows.
    
    * Only build tests in CPU windows tests.
    
    * Only build tests in GPU windows tests.
    
    * Also disable session_test on windows.
    
    * Only run py tests on windows, and only build tests that are not
    disabled.
    
    ---
    Commit a6f284ca4 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration tests for LinearRegressor.
    
    PiperOrigin-RevId: 157604107
    
    ---
    Commit d21bf7d75 authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Backport changes from Github master.
    
    PiperOrigin-RevId: 157603238
    
    ---
    Commit 43bfc138c authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix OSS compilation error in tfprof_main.cc
    
    PiperOrigin-RevId: 157602449
    
    ---
    Commit 904a3d075 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fixing issue with cuda compilation related to missing include (exception is only thrown when running with sandboxing on)
    
    PiperOrigin-RevId: 157602401
    
    ---
    Commit f59203c98 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Shard cholesky_op_test.
    
    PiperOrigin-RevId: 157601172
    
    ---
    Commit 3fdbb5579 authored by Amit Patankar<amitpatankar@google.com>
    Committed by Amit Patankar<amitpatankar@google.com>:
    Merging rc1 back into master.
    
    ---
    Commit be5d98a8b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adds integration tests for DNNClassifier.
    
    PiperOrigin-RevId: 157592010
    
    ---
    Commit a05de6cd2 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Change reporting feature importances in RandomForestEstimator to run at the end of training, instead of part of the inference graph.
    
    PiperOrigin-RevId: 157591575
    
    ---
    Commit e96f1142f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unnecessary casts
    
    PiperOrigin-RevId: 157591439
    
    ---
    Commit 5f8571a6b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix missing namespace comments
    
    PiperOrigin-RevId: 157591364
    
    ---
    Commit eeb0b4067 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157573997
    
    ---
    Commit 7f9674217 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157573723
    
    ---
    Commit 473a590c9 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Allow complex valued input for Cholesky decomposition.
    
    PiperOrigin-RevId: 157572536
    
    ---
    Commit 2d1860859 authored by Blake Hechtman<blakehechtman@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix test name in array_elementwise_ops_test.
    
    PiperOrigin-RevId: 157552402
    
    ---
    Commit a7fff05e0 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfprof multi-step profiling.
    
    This allows users to fill in RunMetadata across different steps.
    1. It is useful for RL model which runs a subset of graph each step.
    2. It also gets averages of multi-step stats.
    
    PiperOrigin-RevId: 157552388
    
    ---
    Commit fe589d9e7 authored by Luke Iwanski<luke@codeplay.com>
    Committed by Benoit Steiner<benoitsteiner@users.noreply.github.com>:
    [OpenCL] Implementation improvements (#9117)
    
    * OpenCL Improvements
    
    * Registers Scatter and ScatterNd Ops for SYCL
    
    * Registers Stack op for SYCL
    
    * Fixes No sycl buffer found error for debug ops
    
    * Registers MatMul and Transpose Ops to SYCL device for double
    
    * Extends analyzer_cli_test.py test to cover SYCL
    
    * Fixes Transpose Op for double when on SYCL
    
    * Bumps Eigen version to fix double precision issue on SYCL
    
    * Extends SessionDebugTestBase to cover SYCL
    
    * Register SYCL implementations for random ops
    
    * Avoid functions that might not be defined on SYCL device (#51)
    
    * Avoid functions that might not be defined on SYCL device
    
    * Simplify by using Eigen math functions
    
    * OpenCL improvements
    
     - Bumps Eigen Version
     - Refactors Ops registration
     - Introduces workaround for Const Op related to the difference between
       CUDA which uses pointers and OpenCL that uses buffers/accessors
     - Extends memory types to cover DEVICE_SYCL as well
     - Introduces  GetSYCLDevice() method that returns list of supported devices
       with GPU device having the highest priority ( doesn't include blacklisted devices )
     - ::internal::Transpose -> tensorflow::internal::Transpose in order to
       avoid compilation reported error
     - re-introduces fix for bugged string replacement causing a lot of compilation
       warnings -c -> --include
     - Adds sycl_runtime to bazels ARRAY_DEPS
     - Replicates TF_CALL_GPU_PROXY_TYPES for SYCL
    
    * [OpenCL] Fixes an issue caused by switch to aligned allocator for sycl buffer (#53)
    
    * [Build] Use gcc/g++ as a host compiler to avoid #8394 (#54)
    
    * [OpenCL] Fixes Scatter Op
    
    * Fix testSimple and testConst in stack_op_test (#3)
    
    * Fix testSimple and testConst in stack_op_test
    
    * Create a specialisation of DoParallelConcatUpdate for SyclDevice and
    register it
    
    * Guard all code in TENSORFLOW_USE_SYCL
    
    * Do not use sycl device for int32
    
    * Registration of the Sycl version is now looking like the one for the GPU
    
    * Remove added empty line
    
    * Register batch normalization kernels for OpenCL (#61)
    
    * [OpenCL] RandomGamma has no GPU friendly implementation (#57)
    
    * [OpenCL] Compatibility fixes for TensorFlow 1.1.0-rc1
    
    * [OpenCL] Implements BatchMatmul Op for SYCL
    
    * Lowercase the device name when GPU or SYCL returned
    
    * [OpenCL] kernel_estimator_test.py assertEqual-> assertAlmostEqual due to floating point representation on the device
    
    * [Eigen] Version bump
    
    * GPU device name string manipulation is not needed anymore
    
    * [OpenCL] Adds SYCL to device backwards compatibility
    
    * [OpenCL] Extends core_rnn_test.py to run for SYCL device
    
    * [OpenCL] Minor optimizations for build script
    
    * [OpenCL] Enables skip folder list in build script
    
    * [OpenCL] Fixes ApplyAdamOp for Sycl device
    
    * [OpenCL] SYCL device improvements
    
    * [OpenCL] Fixes debug_ops's SEGFAULT for SYCL device
    
    * [Build] Adds hexagon to skipped folders list
    
    * [OpenCL] Removes EnterLameDuckMode from SYCL device and allocator
    
    * [OpenCL] Registers Unique Op for SYCL device
    
    * [OpenCL][Temporary] Disables tests for SYCL target due to features not being implemented yet
    
      Tests affected:
        - tensorflow/contrib/memory_stats/python/kernel_tests/memory_stats_ops_test.py
        - tensorflow/contrib/rnn/python/kernel_tests/core_rnn_test.py
        - tensorflow/python/kernel_tests/conv_ops_test.py
        - tensorflow/python/kernel_tests/depthwise_conv_op_test.py
        - tensorflow/python/kernel_tests/pooling_ops_3d_test.py
        - tensorflow/python/kernel_tests/pooling_ops_test.py
        - tensorflow/python/kernel_tests/scatter_nd_ops_test.py
        - tensorflow/python/training/adam_test.py
        - tensorflow/python/training/localhost_cluster_performance_test.py
        - tensorflow/python/training/training_ops_test.py
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Tests affected:
        - tensorflow/python/debug/cli/analyzer_cli_test.py
        - tensorflow/python/debug/lib/session_debug_testlib.py
        - tensorflow/python/debug/lib/stepper_test.py
        - tensorflow/python/kernel_tests/unstack_op_test.py
        - tensorflow/python/ops/image_ops_test.py
    
    * [OpenCL] Take options.config.device_count() into consideration
    
    * [OpenCL] Fixes compilation warning
    
    * [OpenCL] device:SYCL:0 -> sycl:0
    
    * [OpenCL] Removes unwanted flags in building script
    
    Removes flags given to computecpp that enable SIMD instructions
    Removes duplicate flags
    
    * bool -> const bool
    
    * [OpenCL] sycl in test_util.gpu_device_name() -> is_sycl_enabled()
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Test affected:
        - tensorflow/contrib/stateless/python/kernel_tests/stateless_random_ops_test.py
    
    * Imports test_util from tensorflow.python.framework
    
    * [OpenCL] Fixes formatting in Python code
    
    * [OpenCL] Extends session_test.py to cover SYCL device
    
    * [OpenCL] Cleans singleton class
    
    * [OpenCL] Keeping CUDA happy
    
    * [OpenCL][Temporary] Disables failing tests for SYCL in order to establish regression baseline
    
      Test affected:
       - tensorflow/contrib/rnn/python/kernel_tests/core_rnn_cell_test.py
       - tensorflow/contrib/seq2seq/python/kernel_tests/beam_search_ops_test.py
    
    * Added support for building with SYCL on ARM.
    
    * Acts on the review feedback from:
     - #9117#discussion_r113608975
     - #9117#discussion_r113609173
    
    * [OpenCL] Fixes scatter_nd_op_test
    
    * Fixes auto-merge mistake
    
    * [OpenCL] struct SyclDevice -> class SyclDevice
    
    * Revert "[OpenCL] struct SyclDevice -> class SyclDevice"
    
    This reverts commit addd43348c374a5379f67bb1e5ad084715722fc2.
    
    * [OpenCL] Reverting refactoring commit.
    
      As requested in the review #9117#issuecomment-298454466
      This change set will be re-introduced in smaller chunks.
    
    * Revert "[OpenCL] device:SYCL:0 -> sycl:0"
    
    This reverts commit cf16e60340b62d16c3764d71b716fe03d35f87a9.
    
    * Revert "[OpenCL] Adds SYCL to device backwards compatibility"
    
    This reverts commit b8401b5164199b7a169be1c1d8dea5001195c390.
    
    * Acts on the feedback from #9117#discussion_r115036905
    
    * control_flow_ops_py_test.py expects device name to be lower cased
    
    * Acts on the feedback from #9117#discussion_r115037222
    
    * Removes debug print
    
    * Removes not needed partial specialisation
    
    * [OpenCL] Registers ScatterNdFunctor for SYCL device
    
    * [OpenCL] Make it compile
    
    * [OpenCL] Follow gpu_device changes
    
    * [OpenCL] Adds cxx_builtin_include_directory for python lib
    
      Fixes bazels missing undeclared inclusions that appeared after
      merge with TensorFlow upstream
    
    * [OpenCL] Fixes Constant Op
    
    * [OpenCL] gXX-4.8 -> gXX
    
    * [OpenCL] Removes -D_GLIBCXX_USE_CXX11_ABI=0 as it breaks default compiler setup for Ubuntu 16.04
    
    * Revert "[OpenCL] kernel_estimator_test.py assertEqual-> assertAlmostEqual due to floating point representation on the device"
    
    This reverts commit 06c50c0a485f40c30a436f02c3fa7794e370c49d.
    
    * [OpenCL] CPU allocator is a singleton we should not delete it
    
    ---
    Commit 7aac2395c authored by Blake Hechtman<blakehechtman@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Merge a copies of copies.
    
    PiperOrigin-RevId: 157549434
    
    ---
    Commit 37d9d5f0e authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add some routines for managing summaries to slim.
    
    PiperOrigin-RevId: 157541902
    
    ---
    Commit d58cd2962 authored by Justine Tunney<jart@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix weblas license mirror URL
    
    PiperOrigin-RevId: 157537115
    
    ---
    Commit 5c13ee13b authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Make images-related logic use the images plugin.
    
    Previously, fetching images and related data from TensorBoard used handlers within application.py. We now remove those handlers in favor of routes offered by the images plugin. ML Dash is updated as well.
    
    PiperOrigin-RevId: 157536471
    
    ---
    Commit 60394a3d1 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Reduce size of the no-winograd tests, but still large enough that
    ShouldIncludeWinogradNonfusedAlgo returns true.
    
    PiperOrigin-RevId: 157535386
    
    ---
    Commit 9501c4104 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Replace protobuf CopyFrom with assignment
    
    PiperOrigin-RevId: 157534272
    
    ---
    Commit 96698f7fd authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Improve BeamSearchDecoder's ability to handle unknown shapes.
    
    Updated unit tests to contain inputs of unknown shape (at graph build time).
    Found an issue in the gather helper that stops it from properly propagating
    the batch size of the output shape.  This caused problems with tf.while_loop.
    Fixed.
    
    PiperOrigin-RevId: 157533937
    
    ---
    Commit 5c73d0102 authored by Neal Wu<wun@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Batch norm docs fix applied to _fused_batch_norm as well
    
    PiperOrigin-RevId: 157530527
    
    ---
    Commit abd4aa49a authored by Jonathan Hseu<jhseu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix docs for tf.abs() and tf.pow().
    
    PiperOrigin-RevId: 157528475
    
    ---
    Commit dd5ad6917 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Declarations of operators to support batch norm in xla
    
    PiperOrigin-RevId: 157527596
    
    ---
    Commit bbeaa1307 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the expand_dim for label and weight for classifier heads.
    
    PiperOrigin-RevId: 157524909
    
    ---
    Commit 346021ab4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Cleanup: Use C++ casts, remove redundant casts, use CHECK_OK
    
    PiperOrigin-RevId: 157522142
    
    ---
    Commit e405b0f6b authored by Francois Chollet<fchollet@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactoring of layer name autogeneration, to remove a graph serialization warning.
    
    PiperOrigin-RevId: 157520123
    
    ---
    Commit 5784e1e35 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add HasOutputProperties to check for pruned ops; Return
    device name instead of casting it to a short name (GPU:0/CPU:0); VLOG(2) when printing op device placement since it is a lot of output.
    
    PiperOrigin-RevId: 157519077
    
    ---
    Commit 2994444bf authored by Peter Hawkins<phawkins@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Issue a more user-friendly error message if a variable's initializer is from inside a control-flow scope, such as tf.cond() or tf.while_loop().
    
    Fixes #8604.
    
    PiperOrigin-RevId: 157516279
    
    ---
    Commit da2daf068 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused using declarations
    
    PiperOrigin-RevId: 157513772
    
    ---
    Commit 8b2e8b566 authored by Derek Murray<derek.murray@gmail.com>
    Committed by gunan<gunan@google.com>:
    Exclude Python test files from CMake PIP package. (#10302)
    
    * Exclude *_test.py files from the CMake-built PIP package.
    
    * Add stray _test.py file to the PIP package.
    
    * Nit. Convert tabs to spaces in tf_python.cmake
    
    ---
    Commit 2249a4ea8 authored by Dan Ringwalt<ringwalt@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix control reaching the end of ProjectiveGenerator.
    
    PiperOrigin-RevId: 157510013
    
    ---
    Commit 040e2e20f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unneeded check for has properties in grappler.
    
    PiperOrigin-RevId: 157507665
    
    ---
    Commit 684006955 authored by Yun Peng<pcloudy@google.com>
    Committed by gunan<gunan@google.com>:
    Windows: Remove session_test from bazel_test_lib.sh (#10274)
    
    It was disabled in 49b17146d2e4f04192d16ed67574142de167f3a1
    ---
    Commit 890a0a407 authored by Gunhan Gulsoy<gunan@google.com>
    Committed by Gunhan Gulsoy<gunan@google.com>:
    Upgrade TF ci build and docker files to use bazel 0.5.0
    
    ---
    Commit 46db634e5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Only run the no-winograd tests once each.
    Only run the no-winograd tests on GPU; this also fixes
    timeouts in asan and msan.
    
    PiperOrigin-RevId: 157505317
    
    ---
    Commit a6cd4e735 authored by Dandelion Man?<dandelion@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove all TB build references that circumvent TF's public API.
    
    This doesn't actually remove all the code references, lots of code references continue to work despite the BUILD references being removed. I think this is because depending on the public api transitively makes all of TensorFlow's guts available too.
    
    PiperOrigin-RevId: 157502987
    
    ---
    Commit dcc3cdce8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove redundant get() calls and string conversions
    
    PiperOrigin-RevId: 157497932
    
    ---
    Commit af2b9d875 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the trace inputs functionality of the graph explorer.
    
    After migrating to d3 v4, the graph can no longer directly index into d3.Selections to obtain elements. Instead, we must use the nodes method of d3.Selection to generate an array of selected elements.
    
    PiperOrigin-RevId: 157493509
    
    ---
    Commit 5cf484584 authored by Jacques Pienaar<jpienaar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Small test that performs A*B+A and A*B+B.
    
    PiperOrigin-RevId: 157492992
    
    ---
    Commit b2355913b authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    remove some invalid entries (#10294)
    
    I noticed that some entries don't exist (anymore).
    This seems to be some kind of a consistency issue.
    
    More specifically:
    `tensorflow/contrib/ios_examples/camera/data`
    `tensorflow/contrib/session_bundle/testdata/saved_model_half_plus_two`
    `tensorflow/contrib/session_bundle/testdata/saved_model_half_plus_two/variables`
    
    This is the continuation of PR #10264
    ---
    Commit 367ec84f8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add SampleEmbeddingHelper to do sampling at inference time
    
    PiperOrigin-RevId: 157487623
    
    ---
    Commit a3ba225d5 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add BatchMatMul execution cost prediction
    
    PiperOrigin-RevId: 157487507
    
    ---
    Commit 34a29fc3b authored by Eric Liu<ioeric@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [TF:XLA] preserve metadata when replacing HLO instructions.
    
    The motivation is to add metadata for HLO instructions that are created to replace existing HLO instructions during optimizations. The assumption is that the old instruction and the new instruction would perform the same function, and that they would be correlated to the same TF op. This might not always be correct since HLO optimizations can cross TF op boundaries. But still this seems to be better than nothing.
    
    Note that this still doesn't fully resolve missing OpMetadata after HLO optimizations; new instructions might be added without using ReplaceInstruction.
    
    PiperOrigin-RevId: 157484394
    
    ---
    Commit 092a7b6e6 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Disable keras lstm test in tsan.
    
    PiperOrigin-RevId: 157484268
    
    ---
    Commit 7280dafca authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use "empty" member function to test for emptiness
    
    PiperOrigin-RevId: 157483181
    
    ---
    Commit 6c3b15915 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Expands integration tests in dnn_test.
    
    PiperOrigin-RevId: 157476608
    
    ---
    Commit 727193b1f authored by Androbin<robin.richtsfeld@gmail.com>
    Committed by drpngx<drpngx@users.noreply.github.com>:
    add missing import for `signal` package (#10264)
    
    * add missing import for `signal` package
    
    * add missing dependency for `signal` package
    
    * Update tf_python.cmake
    
    ---
    Commit 21461213d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused BUILD dependencies
    
    PiperOrigin-RevId: 157473460
    
    ---
    Commit 4788ca2be authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix handling of Infinity/NaN in line chart domain
    
    Test Plan:
      - Use the script listed below to generate data that has enough
        infinities for these values to not be treated as outliers.
      - Load the data into TensorBoard (`--logdir /tmp/infbug`) and look at
        the scalars plot; also look at the console.
      - Before this change, the chart is completely blank, and there is a
        console warning: "QuantitativeScales cannot take NaN or Infinity as
        a domain value. Ignoring."
      - After this change, there is no console output, and the chart appears
        as intended: a reasonable domain is shown, and the infinities just
        shoot off the chart.
    
    Generating script:
    ```py
    import tensorflow as tf
    
    LOGDIR = '/tmp/infbug'
    STEPS = 134
    
    def main():
      x = tf.Variable(3.1415)
      y = x.assign_add(x)
      tf.summary.scalar('y', y)
      summ = tf.summary.merge_all()
    
      sess = tf.Session()
      writer = tf.summary.FileWriter(LOGDIR)
      writer.add_graph(sess.graph)
      sess.run(tf.global_variables_initializer())
      for step in xrange(STEPS):
        writer.add_summary(sess.run(summ), step)
      writer.close()
    
    if __name__ == '__main__':
      main()
    ```
    
    PiperOrigin-RevId: 157472340
    
    ---
    Commit 49476a62c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Remove unused namespace aliases
    
    PiperOrigin-RevId: 157468609
    
    ---
    Commit d83074847 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Use "nullptr" for null pointer values
    
    PiperOrigin-RevId: 157468186
    
    ---
    Commit b73fea6e2 authored by Tim Harley<tharley@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Refactor `tf.Operation.traceback` implementation in to methods of tf.Graph.
    
    Adds an `_extract_frame_info` method to allow derived classes to extend the
    information available in each op traceback, if desired. The default result of
    `tf.Operation.traceback` is unchanged.
    
    Also fixes a poorly scoped `pylint disable=line-too-long`, so adds the necessary
    enable/disable blocks to silence pylint for the offending docstrings.
    
    PiperOrigin-RevId: 157466174
    
    ---
    Commit f7ca8db7d authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [XLA] Improve shape inference error messages for DynamicSlice/DynamicUpdateSlice.
    
    PiperOrigin-RevId: 157461335
    
    ---
    Commit 8c2a079ec authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Adding a slot / accumulator warmstart initializer that overrides the provided partitioner at call time with one passed at construction time.  This is intended to be used for slot Variables (such as accumulators) associated with Optimizers, since these Variables are created in a fashion that relies on replicating the exact shape of the associated primary variables (see slot_creator).
    
    PiperOrigin-RevId: 157453498
    
    ---
    Commit 73d10599f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Default CUDNN_HOME to CUDA_TOOLKIT_TARGET_DIR. The cuDNN distro is most naturally installed in the same directory as the CUDA SDK, so try to find it there if the user doesn't specify any other directory.
    
    PiperOrigin-RevId: 157436253
    
    ---
    Commit eb7cf9331 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157429266
    
    ---
    Commit 346dcc0a4 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157429078
    
    ---
    Commit 3d5ede131 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update documentation for sparse_matmul op to reflect gradient calculation.
    
    PiperOrigin-RevId: 157428135
    
    ---
    Commit 822d64f0c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix embedding_lookup() bug where normalization did not work with ids of rank != 1.
    
    PiperOrigin-RevId: 157422220
    
    ---
    Commit 8cad6b824 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Improve the error message for live set memory check.
    
    PiperOrigin-RevId: 157415647
    
    ---
    Commit 34dcd5b49 authored by Eugene Brevdo<ebrevdo@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    [tf contrib seq2seq] Bugfixes to BeamSearchDecoder
    
    Implementation by Cinjon Resnick.  He can't push this since he's traveling.
    I just copied the fix and added some small syntax tweaks to make the unit
    tests pass.  More comprehensive unit tests will come in the near future.
    
    Fixes at least part of #9904.
    
    BeamSearchDecoder:
    1. Fix the bug where we don't pass the next cell state through.
    2. Gather the cell state (and attention if that's a part of the model
       as an AttentionWrapper on the cell) according to the next_beam_ids.
    PiperOrigin-RevId: 157415564
    
    ---
    Commit f7ae1461c authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix oversampling in the GPU version of multinomial due to an error in generating
    gumbel noise.  -log(-log(U)) gives infinity if U draws a hard 0.  Adds a tiny
    offset to U (2e-30) to avoid log(U) = -inf.
    
    The CPU sampling algorithm depends on the order of the logits which is
    undesirable and can also oversample the first logit if it is smaller than the
    smallest random float larger than 0 (~1e-7).  Switching to double precision
    internally mitigates these problems, although it doesn't fix them.  Slowdown
    is ~35% in the worst case.
    
    Also adds various tests that we would like the sampling to pass.
    
    CPU Benchmark before:
    
    32 10000 1 0.060 0.069 0.87
    32 10000 4 0.229 0.074 3.10
    32 10000 32 2.180 0.059 37.09
    32 100000 1 0.430 0.480 0.90
    32 100000 4 2.322 0.449 5.17
    32 100000 32 31.508 0.471 66.96
    128 10000 1 0.168 0.235 0.71
    128 10000 4 0.965 0.246 3.93
    128 10000 32 7.989 0.225 35.51
    128 100000 1 1.681 1.539 1.09
    128 100000 4 9.012 1.57 35.73
    128 100000 32 126.222 1.626 77.60
    
    CPU Benchmark after:
    
    32 10000 1 0.054 0.112 0.48
    32 10000 4 0.206 0.093 2.21
    32 10000 32 1.826 0.091 20.12
    32 100000 1 0.292 0.636 0.46
    32 100000 4 2.086 0.606 3.44
    32 100000 32 28.496 0.633 45.03
    128 10000 1 0.125 0.266 0.47
    128 10000 4 0.759 0.258 2.94
    128 10000 32 7.362 0.254 29.03
    128 100000 1 1.550 2.18 10.71
    128 100000 4 8.712 2.22 23.92
    128 100000 32 122.585 2.213 55.39
    
    PiperOrigin-RevId: 157414849
    
    ---
    Commit 62cf561f1 authored by Jianwei Xie<xiejw@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add numpy_input_fn integration for LinearRegressor and fix the expand_dim for label and weight.
    
    PiperOrigin-RevId: 157405237
    
    ---
    Commit 40c7e0dd7 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Go: Update generated wrapper functions for TensorFlow ops.
    
    PiperOrigin-RevId: 157402364
    
    ---
    Commit 2726c00ce authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157402063
    
    ---
    Commit e9d2fba8f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix comment describing ignore_longer_outputs_than_inputs.
    
    PiperOrigin-RevId: 157400110
    
    ---
    Commit 5f097217f authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    An initial step of eliminating all implicit broadcast at the HLO level.
    Guard the shape inference for binary ops behind a flag.
    
    PiperOrigin-RevId: 157373647
    
    ---
    Commit e78e5ec8a authored by Yangzihao Wang<yangzihao@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Set winograd nofused flag to be true by default.
    
    Disable winograd nonfused conv for certain input params to avoid a known bug in cuDNNv5 and cuDNNv6.
    
    PiperOrigin-RevId: 157352847
    
    ---
    Commit 3f9b69a50 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    In the CUDA path of depthwise_conv2d, add a fast variant for forward convolution when the input images are smaller than 16x16.
    
    PiperOrigin-RevId: 157347823
    
    ---
    Commit 848123e61 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix incorrect condition to instantiate depthwise_ops introduced in commit 15d9f00fa. The change should have excluded depthwise_conv2d for doubles on windows debug builds, but it excluded it for all windows and all debug builds.
    
    PiperOrigin-RevId: 157345929
    
    ---
    Commit 060d67b34 authored by Taehoon Lee<taehoonlee@snu.ac.kr>
    Committed by Taehoon Lee<taehoonlee@snu.ac.kr>:
    Fix typos
    
    ---
    Commit 409419bcc authored by Mark Daoust<markdaoust@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    add closing code quotes
    
    PiperOrigin-RevId: 157339360
    
    ---
    Commit d20d0a623 authored by Jonathan Hseu<jhseu@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Fix the contrib estimator_test by updating the global step in all the appropriate spots.
    
    PiperOrigin-RevId: 157328239
    
    ---
    Commit d1144d3a9 authored by Juang, Yi-Lin<b02901026@ntu.edu.tw>
    Committed by Juang, Yi-Lin<b02901026@ntu.edu.tw>:
    Fix typos
    
    ---
    Commit fa8bb43b1 authored by lanhin<lanhin1@gmail.com>
    Committed by lanhin<lanhin1@gmail.com>:
    Fixed a comment typo in GraphView:InitializeNode(), executor.cc.
    
    ---
    Commit 9f13ae93f authored by Asim Shankar<ashankar@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Java: Update Maven release to 1.2.0-rc1
    
    PiperOrigin-RevId: 157294719
    
    ---
    Commit c8256769c authored by Gunhan Gulsoy<gunan@google.com>
    Committed by Gunhan Gulsoy<gunan@google.com>:
    Address comments and sanity check failures.
    
    ---
    Commit 344225a60 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Update ops-related pbtxt files.
    
    PiperOrigin-RevId: 157292254
    
    ---
    Commit eb2f6d041 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    VLOG(2) instead of VLOG(1) for detailed op printouts.
    
    PiperOrigin-RevId: 157291238
    
    ---
    Commit b4466279a authored by Shanqing Cai<cais@google.com>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    tfdbg: add runtime shape and dtype info to DebugNumericSummary
    
    PiperOrigin-RevId: 157291215
    
    ---
    Commit 4fb2425f8 authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    Add GraphOptimizer to Grappler item builder to do L1 optimizations and
    inlining.
    
    Op Counts Comparison (BNMT)
    Counts: Profile vs Grappler
    Op: Add, 968 vs 965
    Op: AddN, 2228 vs 2228
    Op: ApplyGradientDescent, 84 vs 84
    Op: BatchMatMul, 998 vs 998
    Op: Identity, 142 vs 105
    Op: MatMul, 63 vs 63
    Op: Mul, 10318 vs 10306
    Op: OneHot, 1 vs 1
    Op: Reshape, 8421 vs 8422
    Op: Select, 488 vs 488
    Op: Shape, 8132 vs 8131
    Op: Sigmoid, 942 vs 942
    Op: Softmax, 19 vs 19
    Op: StridedSlice, 58 vs 74
    Op: Sub, 1398 vs 1394
    Op: Tanh, 333 vs 333
    Op: Tile, 21 vs 21
    Op: Transpose, 39 vs 39
    PiperOrigin-RevId: 157288420
    
    ---
    Commit 8918fa9ef authored by A. Unique TensorFlower<gardener@tensorflow.org>
    Committed by TensorFlower Gardener<gardener@tensorflow.org>:
    BEGIN_PUBLIC
    Automated g4 rollback of changelist 157272843
    
    PiperOrigin-RevId: 158534336

commit 7fb52cd54cb4eef3566671af5e4d9fbb451e19d7
Author: Justin Lebar <jlebar@google.com>
Date:   Thu Jun 8 10:03:19 2017 -0700

    Don't crash when displaying XLA metrics if they happen to be negative.
    
    PiperOrigin-RevId: 158407664

commit 0770393e95e689b6f89fb8e3a195381796766d4c
Author: Eric Liu <ioeric@google.com>
Date:   Wed Jun 7 13:30:51 2017 -0700

    [Tensorboard] Add a trace viewer component to TensorBoard.
    
    We make the trace viewer a separate app; otherwise, there would be dependency
    conflicts (e.g. Polymer) between the trace viewer app and the tensorboard app.
    The trace viewer app would be served by a plugin, and Tensorboard dashboard will integrate trace viewer app using iframe in the
    future.
    
    This CL also added "mominify" support for link import HTML tags in the
    tensorboard home-grown java vulnizer; otherwise, the vulcanized trace viewer code
    would crash the java vulcanizer.
    
    For open-source build, we add a denpendency on the Catapult github repository
    (https://github.com/catapult-project/catapult/tree/master/tracing). We use a bazel genrule to vulcanize a trace viewer binary which is then used in the
    tf-trace-viewer component.
    
    PiperOrigin-RevId: 158309408

commit fd1c3d3ead966aedcf957da0ab41449cef0fd31f
Author: Asim Shankar <ashankar@google.com>
Date:   Wed May 31 21:56:30 2017 -0700

    Disable writing of compressed checkpoints.
    
    Snappy compression (and decompression) was enabled after the
    1.1 release (in commit 63b2f999d3f22cfe915b89103faa1b0a1b1b7617).
    This means that checkpoints produced by the 1.2.0 release candidates
    will cause TensorFlow 1.1 (and prior) binaries to crash as they
    CHECK fail when trying to load snappy-compressed tables.
    
    To ease transition, disable writing of compressed checkpoints in
    1.2.0 for now.
    
    Reconsider this in the next release.
    
    PiperOrigin-RevId: 157675189

commit d3e840a6c1d26c59fe7b01963e0a2a1dc0067496
Author: Asim Shankar <ashankar@google.com>
Date:   Wed May 31 21:56:30 2017 -0700

    Disable writing of compressed checkpoints.
    
    Snappy compression (and decompression) was enabled after the
    1.1 release (in commit 63b2f999d3f22cfe915b89103faa1b0a1b1b7617).
    This means that checkpoints produced by the 1.2.0 release candidates
    will cause TensorFlow 1.1 (and prior) binaries to crash as they
    CHECK fail when trying to load snappy-compressed tables.
    
    To ease transition, disable writing of compressed checkpoints in
    1.2.0 for now.
    
    Reconsider this in the next release.
    
    PiperOrigin-RevId: 157675189

commit 04891087aa887ac744c5ec2d991314b5b3c4f78e
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Fri May 12 11:14:24 2017 -0700

    Make all the image decode ops handle all formats
    
    Too many users try to decode pngs as jpegs.  Now, if you pass a png to
    decode_jpeg, or a gif to decode_png, it silently does what the user was
    expecting.
    
    Unfortunately, tf.image.decode_image still exists as a separate thing in
    Python, since decode_gif returns 4-D shapes incompatible with the other ops.  A
    future CL could clean that up, but it's hard to do in a backwards compatible
    way.  As is, decode_png and decode_jpeg will bail if you try to decode an
    animated gif, and produce 3-D images for nonanimated gifs.
    
    Also fix some crash-on-error bugs and memory leak bugs in gif_io.cc.
    
    RELNOTES: Make decode_jpeg/decode_png/decode_gif handle all formats, since users frequently try to decode an image as the wrong type.
    
    Fixes #9786.
    
    PiperOrigin-RevId: 155888493

commit fa8381593d0cbe354cb54d691e0a8c42bf4b69d0
Author: Christopher Olston <olston@google.com>
Date:   Thu Apr 27 13:32:09 2017 -0800

    Move Batch op input validation before enqueueing to the batch scheduler, because earlier error detection is better (and also so batch->size() doesn't crash if #dims==0 :).
    Change: 154470659

commit c58d0d7aa97eae4b63c3ce4149aae30be223111d
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 18 19:24:01 2017 -0800

    Speed up non-eigen codepath for SparseTensorDenseMatmul by using FastBoundsCheck instead of CHECK_LT.
    
    Return an error for an out-of-bounds sparse index in SparseTensorDenseMatmul,
    instead of crashing (for CPU kernel only).
    Change: 153546369

commit 8cabc326b0081fb9015f6d70f30512f20aa0fba5
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Apr 18 12:08:20 2017 -0800

    * Properly compute Hermitian matrices in self_adjoint_eig tests.
    * Disable self_adjoint_eig tests for complex types until we fix crash in Numpy code when compiling with nvcc or cudaclang.
    Change: 153500103

commit 24a95ae389e1c76e771ac33d66e0ec40a236260f
Author: Vijay Vasudevan <vrv@google.com>
Date:   Mon Apr 10 15:29:15 2017 -0800

    Change Placeholder to support partial shapes and enforce scalar shapes.
    
    Adds tests; testScalar failed before with the original placeholder because
    it treated [] as "?" instead of scalar.  Now you can actually specify
    [] and it means 'scalar'.
    
    Added a backwards compatibility test using a graph_def generated
    from a previous tf version.
    
    RELNOTES: tf.placeholder can represent scalar shapes and partially known
    shapes accurately. Note, this change can break already buggy programs because
    it makes placeholder shape handling more consistent across graph serializations.
    
    Note: There are some buggy cases where this change can break a buggy pipeline: namely those that serialize a graph using an unknown shape (e.g., [None, 10] in a tf.placeholder, but then reload the graph using import_graph_def and feed it a different shape.  Prior to this change, serializing the graph_def loses the [None, 10] shape requirement, so you can feed anything you want. This change makes it so that you serialize the graph with [None, 10], and so when you reload it, it would fail if you fed it a different shape.  In these cases, the fix is to correct the original placeholder shape to match what you feed it, which is not a bug in TF but in the user's program.
    
    Note 2: A python user that did tf.placeholder(shape=[]) would get scalar checking
    in the same process due to python shape inference code.  However, a C++ user that did Placeholder(shape=[]) would not have gotten
    scalar shape checking; a C++ program that passed Placeholder(shape=[]) that expects
    to interpret this as "UnknownShape" would break -- however, that user could have
    already used an {unknown_shape: true} proto, and should not have expected the legacy behavior.
    
    Backwards compatibility: Old graphs that have shape = {} in the proto will also have a
    graph_def_version <= 21, so the default value of shape prior to this change will be interpreted by new binaries as "UnknownShape" just as before.
    
    Forwards compatibility: new graphs will produce, by default, shape={ unknown rank: true}; old binaries will use PartialTensorShape's parsing code to parse that proto
    into an object whose shape.dims() <= 0, and so these binaries will continue to interpret
    the default shape as "unknown shape" without crashing and without producing new errors.
    
    Fixes #9103
    Change: 152751019

commit 9e7bf403817a3acd4e8d865b041f37609564076e
Author: drpngx <drpngx@users.noreply.github.com>
Date:   Mon Apr 10 13:55:56 2017 -0700

    Branch 152703253 (#9112)
    
    * Improve py_func error handling.
    
    Automatically translate some python errors into corresponding TF errors at runtime.
    Change: 152156821
    
    * Update interaction with libpng so that we use the public API instead of
    knowledge of the internal libpng data structures.
    Change: 152167754
    
    * TensorBoard plugins now contain their own name/route prefix.
    Change: 152167807
    
    * Passes trainable flag to separable_conv2d biases.
    Change: 152170239
    
    * Saving resource variables with a caching device.
    Change: 152171539
    
    * Drop loss from estimator_spec.eval_metric_ops, as required by core Estimator.
    Change: 152179924
    
    * sample_stats.percentile DOCFIX.
    Change: 152182295
    
    * Added a memory optimizer to grappler.
    Change: 152184170
    
    * Change default behavior of the tf runs selector:
    
    - If there are fewer than 41 runs, enable them all by default
    - If there are 41 runs or more, disable them all by default
    
    This is in response to user complaints that having it enable only the first ten runs by default was confusing, because it was not obvious to users that some runs had been disabled.
    However, it still solves the initial user complaint that having very many runs simultaneously enabled would lag the UI.
    
    I also changed the "toggle all runs" button to try to turn everything off before turning everything on.
    Also, I improved the logic for detecting when the runs selection is back in the default state, so that we can avoid generating long URI strings wherever possible.
    Change: 152188948
    
    * Autogenerated Change: Change TensorBoard TAG to 52
    Change: 152189000
    
    * Remove warning that only happening with config cuda.
    Change: 152189205
    
    * Make resource variable shared name consistent with non-resource variables.
    
    Remove colocation constraint from resource variable cached value with the
    variable itself.
    Change: 152192203
    
    * Add a way to specify the optimization order; refactor and add constant folding to meta optimizer.
    Change: 152193646
    
    * Backport fixes and improvements from external Keras.
    Change: 152198296
    
    * Merge changes from github.
    Change: 152200430
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    Change: 152200754
    
    * Update ops-related pbtxt files.
    Change: 152203174
    
    * Make ImportGraphDef() work with functions.
    
    In addition to modify graph_constructor.cc, this patch adds some other
    functionality to enable importing fucntions:
    * Ability to add FunctionDefLibraries to Graphs and
      FunctionLibraryDefinitions (in addition to existing functions)
    * FunctionDefsEqual() utility function
    Change: 152205258
    
    * Expand contrib test to more than just test targets.
    Change: 152206822
    
    * Preserve graph version during optimization
    Change: 152213262
    
    * Exclude enter and exit nodes from shape refiner's constant folding.
    Change: 152213637
    
    * Allow reshape_mover and algebraic_simplifier to make multiple mutations, by avoiding the short-circuit
    std::any_of.
    Change: 152232810
    
    * Fix dynamic_rnn transpose bug (can input/output non-3d tensors).
    
    Also a few cleanups to RNN code.
    Change: 152267628
    
    * Fix flaky tests
    Change: 152272801
    
    * Add an auto parallelization grappler optimization pass.
    Change: 152276787
    
    * Change json.decode.JSONDecodeError to ValueError.  JSONDecodeError seems to be
    the exception used in the simplejson module, not the json module.
    Change: 152278012
    
    * Internal change.
    Change: 152281471
    
    * [XLA] Force buffer sharing of separate while instructions.
    Change: 152288540
    
    * replica_device_setter should work for resource variables
    Change: 152289915
    
    * Fix ./configure script
    1. Add %workspace% in .bazelrc file when using import statement
    2. Write action_env into bazelrc file for required environment variables for OpenCL support
    Change: 152290700
    
    * Pointing a number of Tensorboard graph visualization-related help links to the new locations for the correspondent API documentation.
    Change: 152293459
    
    * Restore most of pull request #8606
    
    Pull request #8606 added str(Label(...)) for most dependencies in
    tensorflow.bzl, allowing most functions to be used from repositories which
    include TensorFlow as a submodule.  Unfortunately, it broke when pulled into
    Google and was removed in cl/152200430.  This CL restores the change, except
    for two Android-only functions; these were the only problematic bits.
    Change: 152297413
    
    * Removed dead code in Estimator.
    Change: 152297597
    
    * Assert rank is at least equal to new_rank for `_sparse_inner_flatten`.
    Change: 152303319
    
    * Extend quantization ranges to include 0.0f.
    Change: 152304380
    
    * Remove Keras config file saving.
    Change: 152306552
    
    * API backwards compatibility tests.
    Change: 152310869
    
    * [TF:XLA] Add a test for an R3 -> R4 broadcast.
    Change: 152313967
    
    * Fix the problem that no enough placeholders for persistent tensor
    batch delete
    
    The deleter_key is always a device_name, hence there is only one
    of it. Hence, we cannot delete >1 handles at one time.
    
    In the fix, it creates delete placeholder on demand, the max
    number of placeholders is _DEAD_HANDLES_THRESHOLD.
    Change: 152322770
    
    * [XLA] Add several reduction tests.
    Change: 152323510
    
    * Added the memory optimizer to the meta optimizer.
    Change: 152323689
    
    * Started a set of utilities to categorize op types
    Change: 152329057
    
    * Add AudioSpectrogram op to TensorFlow for audio feature generation
    Change: 152332221
    
    * Update ops-related pbtxt files.
    Change: 152332812
    
    * Automated rollback of change 152332221
    Change: 152333917
    
    * Call Py_CLEAR on dead fields during TF_RESOURCE-to-ndarray conversion
    Change: 152338333
    
    * [TF contrib seq2seq] Initial, incomplete implementation of beam search decoder.
    
    **DOES NOT WORK, pushed for collaboration only**
    Change: 152343927
    
    * [XLA] Change HloPassPipeline to disallow Add* calls after Run.
    Change: 152345578
    
    * Automated rollback of change 152332812
    Change: 152349057
    
    * Remove all 64/32 bit compiler warnings from core/ops.
    Change: 152353506
    
    * libtensorflow.so: Don't export private symbols.
    
    With this change, libtensorflow.so will only export
    functions defined in c_api.h. This also results in
    a decreased binary size of libtensorflow.so.
    
    On Linux the decrease was from roughly 150MB to 67MB.
    On OS X it was from roughly 101MB to 82MB.
    
    Also fixes #8923
    Change: 152366053
    
    * Add Elu ops in XLA.
    Change: 152383201
    
    * Fixed test. ('broadcast_dims' has size 1)
    Change: 152383633
    
    * Add more detailed error message for rank assertion in _sparse_inner_flatten.
    Change: 152397909
    
    * tensor_bundle: propagrates errors related to directory creation.
    Change: 152401909
    
    * matrix_adjoint added to contrib/linalg/linear_operator_util
    Change: 152404828
    
    * Add an is_active method to plugins
    
    This method determines whether a plugin is active. A plugin may be inactive if say it lacks data. This new is_active method allows us to add a route to TensorBoard noting which plugins are active. The frontend could then avoid querying routes of inactive plugins.
    Change: 152406232
    
    * Replace a gather op for shapes by a stack op so dilated convolutions can be
    placed on GPU even with strict placing (before the gather went to CPU).
    Change: 152411159
    
    * [TF:XLA] Implement BatchToSpace, BatchToSpaceND, SpaceToBatch, SpaceToBatchND.
    Fix crashes in core implementations of the same operators for zero-sized blocks.
    Change: 152416903
    
    * Estimator saves relative paths in checkpoint.
    Change: 152420211
    
    * Fix layers_test exception regex matching.
    Change: 152422855
    
    * Unhide bijectors. Correct TransformedDistribution docstring.
    Change: 152424418
    
    * Choosing a saner default for min_eval_frequency in the constructor for Experiment for the GCS file system, because the default of 1 causes performance problems.
    Change: 152439984
    
    * Inherit use_resource from scope for partitioned variables.
    Change: 152442103
    
    * Support quantized reshape in hexagon runtime
    Change: 152445539
    
    * tfdbg CLI: add command list_source (ls) + UI fixes and improvements
    
    The new list_source (shorthand: ls) command lists Python source files responsible for constructing the nodes and tensors encountered in the run() call.
    
    It divides the source files into two categories and list them separately.
    1) files that are not part of the TensorFlow Python library, and
    2) files that are a part of it.
    
    The list contains information about how many nodes, tensors and dumps of tensors the files is responsible for. The file paths contain clickable links to the existing print_source/ps command.
    
    The list_source/ls command supports filtering by file-path and node-name regex patterns.
    
    UI fixes:
    * Fixed inconsistent black vs. transparent background color that made the layout look messy on some terminal types. Now using the transparent color for default font color consistently.
    * In the print_source command output, add clickable links to expand source lines and graph elements.
    Change: 152446002
    
    * tfcompile: Be a little more verbose about missing required flags.
    
    Fixes #9014
    Change: 152446338
    
    * Disable failing test cases in pooling_ops_test.
    Change: 152447322
    
    * Register more types for tf.image_crop_and_resize(). Resolves #9020.
    Change: 152448160
    
    * Automated rollback of change 152439984
    Change: 152450929
    
    * Add a route to TensorBoard for fetching plugin names
    
    Specifically, we add a /data/plugins_listing route to the TensorBoard application. This route responds with an object mapping the name of each initialized plugin to whether it is active.
    
    This route could help the frontend avoid issuing requests to inactive plugins.
    
    Ordered the listing of routes within application.py so there is a little more organization.
    
    Refactored the test for application to use a fake plugin.
    Change: 152451390
    
    * Added the ability to retrieve the amount of usable gpu memory
    Change: 152453470
    
    * Allow to set session ConfigProto in RunConfig and use it in Estimator.
    Change: 152454548
    
    * Colocate ResourceVariable reads with their handles.
    Change: 152455939
    
    * tfdbg: update doc for new command list_source/ls
    Change: 152456128
    
    * Make rnn directions slightly easier to follow.
    Change: 152456296
    
    * Internal change
    Change: 152458104
    
    * Adds batch renormalization.
    
    NOTE: if you use renormalization, you might want to use faster moving average updates, i.e. lower `decay` values.
    Change: 152458872
    
    * When using ImportGraphDef with a passed in ShapeRefiner, use the
    producer version of the GraphDef when importing; the ShapeRefiner
    may be initialized with a different graph_def_version, so we need
    to be able to override it.
    
    The test failed without the change to graph_constructor and passes with it.
    The test uses a legacy graph that is supported (reduction shape).
    Change: 152459169
    
    * Allow any iterable for `export_strategies` arg.
    Change: 152461826
    
    * Log steps/sec every 100 steps in MonitoredSession, as before.
    Change: 152465320
    
    * Fixes documentation to note that the in case of ties the identity of the return value of ArgMin and ArgMaxis not guaranteed .
    Change: 152465346
    
    * Automated rollback of change 152465346
    Change: 152465844
    
    * Fix shape inference fn on _ParallelConcatStart.
    Change: 152466076
    
    * Fix getting started guide
    
    Explain numerical differences in loss
    fix one example to print
    Change: 152466119
    
    * Remove superfluous mode argument.
    Change: 152467334
    
    * Add a tool that converts HLO computations to tensorflow GraphDef which can be visualized on Tensorboard.
    
    This CL defines basic tensorflow::OpDef for each HLO instruction/node. More attributes (e.g. shapes, colors) will be added in the future.
    Change: 152477918
    
    * [TF:XLA] Increase shard count of //third_party/tensorflow/compiler/tests:spacetobatch_test to reduce flakiness when built under ASAN.
    Change: 152496244
    
    * Make projector plugin backend read assets saved via the PluginAssets API.
    
    At the same time, keep backwards compatibility with the old way of looking up assets.
    Change: 152504793
    
    * Move MNIST pointers to mirror hosted by the CVDF on Google Cloud.
    Fixes: #9031
    Change: 152504901
    
    * Merge changes from github.
    Change: 152508170
    
    * Update API after changing default step couter frequency before.
    Change: 152517535
    
    * Move a few random op helper functions to header files
    
    1. shape_inference::RandomShape
    2. OpKernel::MakeShape(Tensor, TensorShape*)
    Change: 152522156
    
    * addresses the divide by zero bug
    Change: 152522488
    
    * Clarify doc on tf.assign.
    Change: 152523909
    
    * Sparse adam for resource variables.
    Change: 152525327
    
    * Automated rollback of change 152310869
    Change: 152528732
    
    * Add an env_var tf_sync_on_finish_bool that block until device has finished all queued operations in a step if true.
    Change: 152533676
    
    * Add more node attributes for HloInstruction on Tensorboard e.g. shape and layout etc.
    Change: 152534472
    
    * Add tf.complex64 GPU support to tf.gather.
    
    Also add ldg specializations for std::complex.
    Change: 152537848
    
    * Formatting changes
    Change: 152544842
    
    * Upgrade TensorBoard TypeScript to 2.2.1
    
    See also: #8326
    Change: 152545950
    
    * TEST:  Getting reasonable test sizes on linalg library, removing need for
    sharding.
    Change: 152546409
    
    * Disabling _testSourceUtilModuleReturnsTrue as its causing opensource issues.
    Change: 152548721
    
    * Fix race due to unsafe buffer forwarding in maxpooling second order gradients added in #6664.
    Re-enable previously flaky tests.
    Clean up a few minor things in maxpooling_op_gpu.cu.cc
    Change: 152550050
    
    * LinearOperator:  adjoint_arg kwarg added to all operators.  Now,
    operator.apply(x, adjoint_arg=True) means that the adjoint of 'x' is taken
    before application of operator.  Sometimes this is done more efficiently than
    simply taking adjoint.
    Change: 152560471
    
    * Adds weighted_average_loss metric key.
    Change: 152560999
    
    * Documentation: Fix bug in manual device placement example
    Change: 152563392
    
    * Change for internal compatibility.
    
    * Use std::vector for storage instead of map.
    Do the sorting inplace and return the same vector to avoid any copies.
    On larger streams it is about 50% faster.
    Change: 152576112
    
    * Add tf.add_n GPU support for complex64/complex128.
    
    Also adds a unit test for tf.add_n.
    Change: 152577190
    
    * - Adds support for nested types in tf.case and tf.cond.
    - Adds a "strict" mode which disables silent unpacking of singleton lists.
    - Adds shape inference to tf.case.
    - Adds a lot of unit tests.
    Change: 152581097
    
    * [XLA] Add support for folding transpose into convolution
    Change: 152581336
    
    * Add a smoke test to ensure that the doc generator runs.
    Change: 152592164
    
    * Add tensorboard to the _do_not_descend_map of the PublicAPIVisitor.
    Change: 152592268
    
    * Add auto parallelization to meta optimizer. Enable MetaOptimizer if any one of the optimizers is on.
    Change: 152598517
    
    * Update ops-related pbtxt files.
    Change: 152629248
    
    * Prevent the renorm_weight from being updated too early.
    Change: 152631776
    
    * Automated rollback of change 152528732
    Change: 152652473
    
    * Construct TensorBoard dashboards in a JS list
    
    Previously, adding a dashboard to TensorBoard involved changing logic in several places.
    
    As part of this effort, added constructors to dashboards. Tweaked logic in various dashboards to preserve original behavior. For instance, the graph dashboard can only perform fitting after the dashboard is attached to the DOM.
    Change: 152658532
    
    * Make CheckpointSaverListener visible next to CheckpointSaverHook.
    Change: 152662945
    
    * tfdbg CLI: minor bug fixes
    
    1: The calculation of the scroll command in the scroll bar didn't take into account that the y-coordinate of the scroll block is in the ScrollBar coordinate system, while the mouse click y-coordinate is in the screen coordinate system.
    
    2: The y position of the ScrollBar was off by one.
    
    3: The command box is not re-created after mouse-triggered commands, leading to strange-looking cursor position.
    Change: 152684294
    
    * Remove obsolete use of validate_indices from embedding_ops.py
    
    validate_indices is ignored, so it shouldn't appear in new code.
    Change: 152691948
    
    * Preparation of using GMock matchers in XLA tests.
    Change: 152691970
    
    * Replace RuntimeException by RuntimeError in coordinator documentation.
    Change: 152697758
    
    * Move the TensorBoard debugger plugin to be internal.
    
    This feature is currently not open-source anyway.
    Change: 152700267
    
    * Add a single-machine tf.learn Estimator implementation for the WALS solver.
    Change: 152700915
    
    * Add tf.contrib.training.python_input -- making it easy to feed data into
    TensorFlow from python coroutines.
    Change: 152701623
    
    * Show that QuantizeToFloat consistently introduces a small error. The
    error is equal to
      range_min - round(range_min / range_scale) * range_scale
    Change: 152702015
    
    * Internal Changes
    Change: 152703253
    
    * Remove tensorflow/tensorboard/plugins/debugger, as part of merge resolution.

commit 52dcb2590bb9274262656c958c105cb5e5cc1300
Author: Rohan Jain <rohan100jain@gmail.com>
Date:   Fri Apr 7 18:04:26 2017 -0700

    Branch 152550050 (#9059)
    
    * Improve py_func error handling.
    
    Automatically translate some python errors into corresponding TF errors at runtime.
    Change: 152156821
    
    * Update interaction with libpng so that we use the public API instead of
    knowledge of the internal libpng data structures.
    Change: 152167754
    
    * TensorBoard plugins now contain their own name/route prefix.
    Change: 152167807
    
    * Passes trainable flag to separable_conv2d biases.
    Change: 152170239
    
    * Saving resource variables with a caching device.
    Change: 152171539
    
    * Drop loss from estimator_spec.eval_metric_ops, as required by core Estimator.
    Change: 152179924
    
    * sample_stats.percentile DOCFIX.
    Change: 152182295
    
    * Added a memory optimizer to grappler.
    Change: 152184170
    
    * Change default behavior of the tf runs selector:
    
    - If there are fewer than 41 runs, enable them all by default
    - If there are 41 runs or more, disable them all by default
    
    This is in response to user complaints that having it enable only the first ten runs by default was confusing, because it was not obvious to users that some runs had been disabled.
    However, it still solves the initial user complaint that having very many runs simultaneously enabled would lag the UI.
    
    I also changed the "toggle all runs" button to try to turn everything off before turning everything on.
    Also, I improved the logic for detecting when the runs selection is back in the default state, so that we can avoid generating long URI strings wherever possible.
    Change: 152188948
    
    * Autogenerated Change: Change TensorBoard TAG to 52
    Change: 152189000
    
    * Remove warning that only happening with config cuda.
    Change: 152189205
    
    * Make resource variable shared name consistent with non-resource variables.
    
    Remove colocation constraint from resource variable cached value with the
    variable itself.
    Change: 152192203
    
    * Add a way to specify the optimization order; refactor and add constant folding to meta optimizer.
    Change: 152193646
    
    * Backport fixes and improvements from external Keras.
    Change: 152198296
    
    * Merge changes from github.
    Change: 152200430
    
    * Go: Update generated wrapper functions for TensorFlow ops.
    Change: 152200754
    
    * Update ops-related pbtxt files.
    Change: 152203174
    
    * Make ImportGraphDef() work with functions.
    
    In addition to modify graph_constructor.cc, this patch adds some other
    functionality to enable importing fucntions:
    * Ability to add FunctionDefLibraries to Graphs and
      FunctionLibraryDefinitions (in addition to existing functions)
    * FunctionDefsEqual() utility function
    Change: 152205258
    
    * Expand contrib test to more than just test targets.
    Change: 152206822
    
    * Preserve graph version during optimization
    Change: 152213262
    
    * Exclude enter and exit nodes from shape refiner's constant folding.
    Change: 152213637
    
    * Allow reshape_mover and algebraic_simplifier to make multiple mutations, by avoiding the short-circuit
    std::any_of.
    Change: 152232810
    
    * Fix dynamic_rnn transpose bug (can input/output non-3d tensors).
    
    Also a few cleanups to RNN code.
    Change: 152267628
    
    * Fix flaky tests
    Change: 152272801
    
    * Add an auto parallelization grappler optimization pass.
    Change: 152276787
    
    * Change json.decode.JSONDecodeError to ValueError.  JSONDecodeError seems to be
    the exception used in the simplejson module, not the json module.
    Change: 152278012
    
    * Internal change.
    Change: 152281471
    
    * [XLA] Force buffer sharing of separate while instructions.
    Change: 152288540
    
    * replica_device_setter should work for resource variables
    Change: 152289915
    
    * Fix ./configure script
    1. Add %workspace% in .bazelrc file when using import statement
    2. Write action_env into bazelrc file for required environment variables for OpenCL support
    Change: 152290700
    
    * Pointing a number of Tensorboard graph visualization-related help links to the new locations for the correspondent API documentation.
    Change: 152293459
    
    * Restore most of pull request #8606
    
    Pull request #8606 added str(Label(...)) for most dependencies in
    tensorflow.bzl, allowing most functions to be used from repositories which
    include TensorFlow as a submodule.  Unfortunately, it broke when pulled into
    Google and was removed in cl/152200430.  This CL restores the change, except
    for two Android-only functions; these were the only problematic bits.
    Change: 152297413
    
    * Removed dead code in Estimator.
    Change: 152297597
    
    * Assert rank is at least equal to new_rank for `_sparse_inner_flatten`.
    Change: 152303319
    
    * Extend quantization ranges to include 0.0f.
    Change: 152304380
    
    * Remove Keras config file saving.
    Change: 152306552
    
    * API backwards compatibility tests.
    Change: 152310869
    
    * [TF:XLA] Add a test for an R3 -> R4 broadcast.
    Change: 152313967
    
    * Fix the problem that no enough placeholders for persistent tensor
    batch delete
    
    The deleter_key is always a device_name, hence there is only one
    of it. Hence, we cannot delete >1 handles at one time.
    
    In the fix, it creates delete placeholder on demand, the max
    number of placeholders is _DEAD_HANDLES_THRESHOLD.
    Change: 152322770
    
    * [XLA] Add several reduction tests.
    Change: 152323510
    
    * Added the memory optimizer to the meta optimizer.
    Change: 152323689
    
    * Started a set of utilities to categorize op types
    Change: 152329057
    
    * Add AudioSpectrogram op to TensorFlow for audio feature generation
    Change: 152332221
    
    * Update ops-related pbtxt files.
    Change: 152332812
    
    * Automated rollback of change 152332221
    Change: 152333917
    
    * Call Py_CLEAR on dead fields during TF_RESOURCE-to-ndarray conversion
    Change: 152338333
    
    * [TF contrib seq2seq] Initial, incomplete implementation of beam search decoder.
    
    **DOES NOT WORK, pushed for collaboration only**
    Change: 152343927
    
    * [XLA] Change HloPassPipeline to disallow Add* calls after Run.
    Change: 152345578
    
    * Automated rollback of change 152332812
    Change: 152349057
    
    * Remove all 64/32 bit compiler warnings from core/ops.
    Change: 152353506
    
    * libtensorflow.so: Don't export private symbols.
    
    With this change, libtensorflow.so will only export
    functions defined in c_api.h. This also results in
    a decreased binary size of libtensorflow.so.
    
    On Linux the decrease was from roughly 150MB to 67MB.
    On OS X it was from roughly 101MB to 82MB.
    
    Also fixes #8923
    Change: 152366053
    
    * Add Elu ops in XLA.
    Change: 152383201
    
    * Fixed test. ('broadcast_dims' has size 1)
    Change: 152383633
    
    * Add more detailed error message for rank assertion in _sparse_inner_flatten.
    Change: 152397909
    
    * tensor_bundle: propagrates errors related to directory creation.
    Change: 152401909
    
    * matrix_adjoint added to contrib/linalg/linear_operator_util
    Change: 152404828
    
    * Add an is_active method to plugins
    
    This method determines whether a plugin is active. A plugin may be inactive if say it lacks data. This new is_active method allows us to add a route to TensorBoard noting which plugins are active. The frontend could then avoid querying routes of inactive plugins.
    Change: 152406232
    
    * Replace a gather op for shapes by a stack op so dilated convolutions can be
    placed on GPU even with strict placing (before the gather went to CPU).
    Change: 152411159
    
    * [TF:XLA] Implement BatchToSpace, BatchToSpaceND, SpaceToBatch, SpaceToBatchND.
    Fix crashes in core implementations of the same operators for zero-sized blocks.
    Change: 152416903
    
    * Estimator saves relative paths in checkpoint.
    Change: 152420211
    
    * Fix layers_test exception regex matching.
    Change: 152422855
    
    * Unhide bijectors. Correct TransformedDistribution docstring.
    Change: 152424418
    
    * Choosing a saner default for min_eval_frequency in the constructor for Experiment for the GCS file system, because the default of 1 causes performance problems.
    Change: 152439984
    
    * Inherit use_resource from scope for partitioned variables.
    Change: 152442103
    
    * Support quantized reshape in hexagon runtime
    Change: 152445539
    
    * tfdbg CLI: add command list_source (ls) + UI fixes and improvements
    
    The new list_source (shorthand: ls) command lists Python source files responsible for constructing the nodes and tensors encountered in the run() call.
    
    It divides the source files into two categories and list them separately.
    1) files that are not part of the TensorFlow Python library, and
    2) files that are a part of it.
    
    The list contains information about how many nodes, tensors and dumps of tensors the files is responsible for. The file paths contain clickable links to the existing print_source/ps command.
    
    The list_source/ls command supports filtering by file-path and node-name regex patterns.
    
    UI fixes:
    * Fixed inconsistent black vs. transparent background color that made the layout look messy on some terminal types. Now using the transparent color for default font color consistently.
    * In the print_source command output, add clickable links to expand source lines and graph elements.
    Change: 152446002
    
    * tfcompile: Be a little more verbose about missing required flags.
    
    Fixes #9014
    Change: 152446338
    
    * Disable failing test cases in pooling_ops_test.
    Change: 152447322
    
    * Register more types for tf.image_crop_and_resize(). Resolves #9020.
    Change: 152448160
    
    * Automated rollback of change 152439984
    Change: 152450929
    
    * Add a route to TensorBoard for fetching plugin names
    
    Specifically, we add a /data/plugins_listing route to the TensorBoard application. This route responds with an object mapping the name of each initialized plugin to whether it is active.
    
    This route could help the frontend avoid issuing requests to inactive plugins.
    
    Ordered the listing of routes within application.py so there is a little more organization.
    
    Refactored the test for application to use a fake plugin.
    Change: 152451390
    
    * Added the ability to retrieve the amount of usable gpu memory
    Change: 152453470
    
    * Allow to set session ConfigProto in RunConfig and use it in Estimator.
    Change: 152454548
    
    * Colocate ResourceVariable reads with their handles.
    Change: 152455939
    
    * tfdbg: update doc for new command list_source/ls
    Change: 152456128
    
    * Make rnn directions slightly easier to follow.
    Change: 152456296
    
    * Internal change
    Change: 152458104
    
    * Adds batch renormalization.
    
    NOTE: if you use renormalization, you might want to use faster moving average updates, i.e. lower `decay` values.
    Change: 152458872
    
    * When using ImportGraphDef with a passed in ShapeRefiner, use the
    producer version of the GraphDef when importing; the ShapeRefiner
    may be initialized with a different graph_def_version, so we need
    to be able to override it.
    
    The test failed without the change to graph_constructor and passes with it.
    The test uses a legacy graph that is supported (reduction shape).
    Change: 152459169
    
    * Allow any iterable for `export_strategies` arg.
    Change: 152461826
    
    * Log steps/sec every 100 steps in MonitoredSession, as before.
    Change: 152465320
    
    * Fixes documentation to note that the in case of ties the identity of the return value of ArgMin and ArgMaxis not guaranteed .
    Change: 152465346
    
    * Automated rollback of change 152465346
    Change: 152465844
    
    * Fix shape inference fn on _ParallelConcatStart.
    Change: 152466076
    
    * Fix getting started guide
    
    Explain numerical differences in loss
    fix one example to print
    Change: 152466119
    
    * Remove superfluous mode argument.
    Change: 152467334
    
    * Add a tool that converts HLO computations to tensorflow GraphDef which can be visualized on Tensorboard.
    
    This CL defines basic tensorflow::OpDef for each HLO instruction/node. More attributes (e.g. shapes, colors) will be added in the future.
    Change: 152477918
    
    * [TF:XLA] Increase shard count of //third_party/tensorflow/compiler/tests:spacetobatch_test to reduce flakiness when built under ASAN.
    Change: 152496244
    
    * Make projector plugin backend read assets saved via the PluginAssets API.
    
    At the same time, keep backwards compatibility with the old way of looking up assets.
    Change: 152504793
    
    * Move MNIST pointers to mirror hosted by the CVDF on Google Cloud.
    Fixes: #9031
    Change: 152504901
    
    * Merge changes from github.
    Change: 152508170
    
    * Update API after changing default step couter frequency before.
    Change: 152517535
    
    * Move a few random op helper functions to header files
    
    1. shape_inference::RandomShape
    2. OpKernel::MakeShape(Tensor, TensorShape*)
    Change: 152522156
    
    * addresses the divide by zero bug
    Change: 152522488
    
    * Clarify doc on tf.assign.
    Change: 152523909
    
    * Sparse adam for resource variables.
    Change: 152525327
    
    * Automated rollback of change 152310869
    Change: 152528732
    
    * Add an env_var tf_sync_on_finish_bool that block until device has finished all queued operations in a step if true.
    Change: 152533676
    
    * Add more node attributes for HloInstruction on Tensorboard e.g. shape and layout etc.
    Change: 152534472
    
    * Add tf.complex64 GPU support to tf.gather.
    
    Also add ldg specializations for std::complex.
    Change: 152537848
    
    * Formatting changes
    Change: 152544842
    
    * Upgrade TensorBoard TypeScript to 2.2.1
    
    See also: #8326
    Change: 152545950
    
    * TEST:  Getting reasonable test sizes on linalg library, removing need for
    sharding.
    Change: 152546409
    
    * Disabling _testSourceUtilModuleReturnsTrue as its causing opensource issues.
    Change: 152548721
    
    * Fix race due to unsafe buffer forwarding in maxpooling second order gradients added in #6664.
    Re-enable previously flaky tests.
    Clean up a few minor things in maxpooling_op_gpu.cu.cc
    Change: 152550050

commit 96bc32eab3b21192bfd065a5944c12269fe3f5a4
Author: Peter Hawkins <phawkins@google.com>
Date:   Thu Apr 6 12:02:29 2017 -0800

    [TF:XLA] Implement BatchToSpace, BatchToSpaceND, SpaceToBatch, SpaceToBatchND.
    Fix crashes in core implementations of the same operators for zero-sized blocks.
    Change: 152416903

commit afe9e404e973a00f713a6f2d59fe1774c98f772b
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Mar 31 12:59:52 2017 -0800

    [XLA] Don't crash when analyzing ops with no layout contained in a fused op.
    Change: 151864663

commit e8ee5286a686c6fc3057ba7cf9ba9ef7003789a6
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Thu Mar 30 17:34:30 2017 -0800

    Remove 2**40 size limit on TensorShape and harden to overflow
    
    The limit was preventing valid uses of TensorShape as the dense shape of very
    large sparse tensors.  There's no security advantage to the limit, since a
    memory allocation of 2**40 bytes is already far beyond a reasonable machine
    size.  The new limit is std::numeric_limits<int64>::max().
    
    In addition, the previous TensorShape code did not check for overflow when
    multiplying, which meant an operation as simple as
    
        tf.gather(tf.zeros([2**5, 2**60 + 1]), 7).eval()
    
    would appear as valid during TensorShape construction and then crash.
    A new MultiplyWithoutOverflow function does the correct overflow checking.
    
    Fixes #8494.
    Change: 151778176

commit 1626c7bb6473f759218752d128aad2e7da64af4f
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Mar 15 12:27:58 2017 -0800

    [XLA] Fix crash when loading a serialized computation with dependencies between embedded computations.
    Change: 150233783

commit 830cde8776d9adb6bdbb2e0b3173d16780d52df7
Author: Christopher Olston <olston@google.com>
Date:   Tue Mar 14 17:52:36 2017 -0800

    Eliminate crashy Concat()/Split() overloads.
    Change: 150143909

commit 6f05489ff932547cb9a80232a2ad81a817846e16
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Mar 14 13:40:07 2017 -0800

    Change the moving average update logic for LazyAdam to prevent numeric instabilities.
    
    The original implementation was modeled after TensorFlow's existing ApplyAdamNonCuda and ExponentialMovingAverage classes, which are designed for concurrent lockless updates. However, my model training jobs kept failing with NaN errors when I ran them with more than 20 workers. Upon closer investigation, I discovered that the moving average implementation had two problems:
    
    1) In some cases, the moving average of a sequence of positive numbers can actually be negative. If we take the square root of the moving average, we end up with NaN errors. This happened to me with the moving average variable 'v' in the Adam algorithm.
    
    2) When the moving average decay rates \beta_1 and \beta_2 are significantly less than one and the number of workers is large, the moving averages can become unstable, receiving huge updates from each worker. These instabilities become larger and larger until they cause the model training jobs to crash with NaN errors.
    Change: 150115814

commit c07f591c830ba97f4a17049ea114514d2f4ef9e3
Author: Alec-DeSouza <alec.desouza@uoit.net>
Date:   Mon Mar 13 18:42:35 2017 -0400

    Fixed TF Stylize crash after reaching the end (#8366)

commit 3af39a00d151bd55b69c8b045a6e67284c22c9f5
Author: Christopher Olston <olston@google.com>
Date:   Fri Mar 10 07:21:40 2017 -0800

    Rename the new TryConcat()/TrySplit() to Concat()/Split() and mark the existing Concat()/Split() as deprecated.
    
    This is the first change in a sequence that will remove the crashy Concat()/Split().
    Change: 149755537

commit b59b9043afd453d952dc6ae829fa05f68408e3b6
Author: Christopher Olston <olston@google.com>
Date:   Tue Mar 7 12:57:39 2017 -0800

    Create non-crashy versions of Concat() and Split(), to use in serving code.
    Change: 149454449

commit 4be70b915350adf4a3fb96a5d0ca4c8b2a736169
Author: Asim Shankar <ashankar@google.com>
Date:   Tue Mar 7 01:21:00 2017 -0800

    Go: Handle nil values for list-valued attributes gracefully.
    
    Without this change, setting a list-valued attribute to 'nil' would
    result in a crash (&list[0] is malformed).

commit 19dd9342e7bc55c877367b7474caf41e819e38c3
Author: Peter Hawkins <phawkins@google.com>
Date:   Mon Mar 6 12:21:14 2017 -0800

    [TF:XLA] Add support for 3D convolution to XLA bridge.
    
    Generalize common backward convolution dimension computation code to support > 2 dimensions.
    
    Fix crash for zero-element Tensors passed to Conv3DBackpropFilter on CPU.
    Change: 149329330

commit f424ca38712a87aeaf614af454d96b5d155592ca
Author: Peter Hawkins <phawkins@google.com>
Date:   Wed Mar 1 06:15:30 2017 -0800

    [TF:XLA] Add implementation of tf.one_hot to the XLA bridge.
    
    Fix crash in normal OneHot kernel for depth < 0.
    Change: 148881102

commit 8b44423d25f55ef0e83c1613c0d21bd3b4b3037a
Author: Pete Warden <petewarden@google.com>
Date:   Thu Feb 23 11:44:45 2017 -0800

    Add text proto support to summarize_graph, and fix crash on variables
    Change: 148370696

commit 02703f9525696f4788496745f6756585c1c546a3
Author: Yuefeng Zhou <yuefengz@google.com>
Date:   Tue Feb 14 22:39:15 2017 -0800

    Fix crash in range sampler by adding a range check in the sampler op.
    Change: 147562709

commit b9db1ff1bf3552cbdb18c6b0c7735a297525adcc
Author: Yuefeng Zhou <yuefengz@google.com>
Date:   Tue Feb 14 16:53:24 2017 -0800

    Make range sampler non-crashing when input arg to FixedUnigramSampler::Probability is too large.
    Change: 147539715

commit 63ad7054ad3fc223f94bbb5d7a203b6d08eceb07
Author: Manjunath Kudlur <keveman@google.com>
Date:   Fri Feb 10 17:47:06 2017 -0800

    Replace dependency on entire proto library with just the headers for contrib.
    
    - Linking a version of the entire proto library with every .so is wasteful.
    - Causes duplicate destruction of the static initialized objects causing
    non-deterministic crashes.
    Change: 147220106

commit 0eb6d8ff445922e8eb585534e3fb1deb927e011e
Author: Andrew Harp <andrewharp@google.com>
Date:   Wed Feb 1 11:34:02 2017 -0800

    Android: fix issue where mismatch between Inception output size and inception num classes could cause demo app to crash (due to recent CHECK added in inference interface).
    Change: 146268764

commit 781ccc8e4b9f2dc4fd676e05933d57f5735d0b57
Author: Illia Polosukhin <ipolosukhin@google.com>
Date:   Tue Jan 17 17:28:29 2017 -0800

    Actually use eval hooks in Experiment across all usages.
    Fix bug with not copying hooks in est.evaluate (leads to updated eval_hooks in Experiment and crash second time).
    Change: 144777878

commit bfa0fa079de45a9ce3dc54c0074680f02434cedb
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Jan 9 16:08:04 2017 -0800

    Removes potential crash from GraphMgr.
    Change: 144020788

commit 9f360c9ae4822b1082580f396b53637ce7ade3a0
Author: Shanqing Cai <cais@google.com>
Date:   Fri Dec 30 17:22:07 2016 -0800

    tfdbg CLI: fix bugs related to terminal size
    
    * Bug fix 1: Previously, if a wrapped line has a mouse-clickable link, the wrapped link in the first line will disappear. This CL fixes that.
    * Bug fix 2: Previously, the open-source version will crash on mouse-wheel scrolls, because it is an unsupported mouse event type in the external version of curses. This CL catches such exceptions (curses.error).
    * Bug fix 3: Previously, on terimnal resizing, a sufficiently long main menu bar on the top can cause the CLI to crash. This CL fixes that.
    Change: 143271319

commit c262d2e627d9bf2224f5a72a0879d597e1cc2954
Author: Pete Warden <petewarden@google.com>
Date:   Wed Dec 7 11:10:00 2016 -0800

    Compile with SSE4.1 by default on x86 platforms
    SSE4.1 is widely available, and enabling this helps overall CPU performance. It does mean that unsupported machines will crash with an illegal instruction error.
    Change: 141331377

commit b2393de6045ccf7bead52d1db5e4832854a0d281
Author: Pete Warden <petewarden@google.com>
Date:   Tue Dec 6 13:27:22 2016 -0800

    Compile with SSE4.1 by default on x86 platforms
    SSE4.1 is widely available, and enabling this helps overall CPU performance. It does mean that unsupported machines will crash with an illegal instruction error.
    Change: 141217999

commit a1f2e1ebe0b371714e164addd79e651b1786c5cd
Author: David G. Andersen <dga@google.com>
Date:   Thu Dec 1 08:56:02 2016 -0800

    Fixing null-pointer dereference on parsing of invalid TensorProto.
    (If the number of entries in the proto was zero, but we asked for
    more, the code incorrectly dereferenced a pointer to the data before
    the check to see if it was empty, resulting in a crash.)
    
    Bug spotted by libFuzzer.
    Change: 140736570

commit ec067dae3dc361661728cc086e1bdbc49f5472ef
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Nov 28 03:03:35 2016 -0800

    Honor mode in _dynamic_rnn_model_fn(): no training_op if not TRAIN,
    no loss and eval_metrics if INFER. Without this, .export() crashes.
    Change: 140337700

commit 096ab75275862f973b2fd1a369a9fd25952a6c37
Author: Mikalai Drabovich <drabovich@gmail.com>
Date:   Thu Nov 17 19:32:47 2016 -0800

    Fix integer overflow error
    
    This sample crashes if used on big text files (>2B words).
    Changing corpus_size_ to 64-bit int solves the problem.

commit f250389872ac7d282268fa69dda5f5b2e6268063
Author: Shanqing Cai <cais@google.com>
Date:   Fri Oct 28 08:16:31 2016 -0800

    tfdbg: improvements and fixes to tensor display in CLI
    
    1) Enable scrolling to next regex match with command "/" following "/regex".
    2) Enable scrolling to tensor indices with command such as "@[1, 2]" and "@100,30,0".
    3) Display tensor indices at the top and bottom of the screen, and in scroll status info bar.
    4) Handle invalid regex search commands, e.g., "/[", without crashing.
    
    Doc updated accordingly.
    Change: 137518091

commit 53fa64259c790b763a6ac9b29f186bdebcb1ada8
Author: Rohan Jain <rohanj@google.com>
Date:   Wed Nov 9 21:49:25 2016 -0800

    Making the cancel op for shared queue a no-op so that we can recover from PS crashes / restarts without crashing all workers.
    Change: 138722939

commit 38aec869681e0ac964e33bf44aef57016c5960c5
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Wed Nov 9 16:38:08 2016 -0800

    Fix metagemm crash, make sure scratch memory is aligned to 32 bytes.
    Change: 138701878

commit 443fea9b7360c7be93a56bb1f8eb2a6f7fc68051
Author: guschmue <guschmue@microsoft.com>
Date:   Mon Oct 31 10:43:51 2016 -0700

    fixes a memory corruption on windows/gpu (#5288)
    
    * use port::aligned_free() to free allocations from port::aligned_alloc().
    This was resulting in memory corruptions on windows.
    
    * windows doesn't use LD_LIBRARY_PATH so don't print it.
    it was actually crashing instead of printing the error message since getenv() returns null.

commit 82a034e8a5c0927804f4688acbcc7127da23b7eb
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Oct 28 08:38:11 2016 -0800

    Fixes for TestSessionInterOpThreadsImpl:
    - Force to run on CPU, since running on GPU fails.
    - Crash if session->Run fails. Otherwise, the test hangs if session->Run fails.
    Change: 137519956

commit a304f0a1e430be84fcbe4ffc6bd80e26fcf08393
Author: Shanqing Cai <cais@google.com>
Date:   Fri Oct 28 08:16:31 2016 -0800

    tfdbg: improvements and fixes to tensor display in CLI
    
    1) Enable scrolling to next regex match with command "/" following "/regex".
    2) Enable scrolling to tensor indices with command such as "@[1, 2]" and "@100,30,0".
    3) Display tensor indices at the top and bottom of the screen, and in scroll status info bar.
    4) Handle invalid regex search commands, e.g., "/[", without crashing.
    
    Doc updated accordingly.
    Change: 137518091

commit b09ab769296f361435aa1401db14f302937b6fec
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Oct 20 14:28:51 2016 -0800

    Fix crash in _make_metrics_ops in estimator.py when using a MetricSpec metric and targets are defined as a dict with a single key.
    Change: 136768627

commit 8ff0f0b97d7ab62a949ab24726610ba54d0f3c42
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Tue Oct 11 12:26:27 2016 -0800

    Avoid crashing if sequence_length is a Tensor.
    Change: 135833298

commit 032b35922d2d0335cfebc8e9c99c78a3898d0961
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Sep 30 10:44:23 2016 -0800

    There was an issue with the batch_sequences_with_states function which was
    causing the sqss to crash while it was reaching to the end of a sstable.
    Change: 134808335

commit ffc4dcb12cb64b14a8319ec8015ac74fbaa7ebc9
Author: Nathan Silberman <nsilberman@google.com>
Date:   Tue Sep 27 12:56:59 2016 -0800

    Fixing issue in which allow_small_batch=True in batching crashes loss functions.
    Tests added that fail without the fix and pass with the fix.
    Change: 134450477

commit c49ca80e708539f1336a6ebedf46815a68332fbc
Author: Noah Fiedel <nfiedel@google.com>
Date:   Mon Sep 26 21:46:29 2016 -0800

    Fix to resource leak caused by not explicitly calling Close on
    sessions upon SessionBundle destruction.
    
    The included test crashed on my workstation after 1145 iterations,
    and after the fix ran to 2000.
    Change: 134366492

commit dffe0fa45bcca5ecd2e0513193921deb5fb5eedf
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Sep 22 12:33:06 2016 -0800

    This fixes a crash when CUDATimer::Init() fails for any reason.
    Change: 133992867

commit 5c8bff0cba88de0fec99ae3a8c69606d7992e0f9
Author: Shanqing Cai <cais@google.com>
Date:   Tue Sep 6 12:48:18 2016 -0800

    tfdbg: Allow debug ops to watch uninitialized tensors
    
    This prevents the debugger from crashing when the debug ops receive uninitialized tensors, and hence allows it to debug session.run() calls such as tf.initialize_all_tensors(), which is quite common.
    
    To make this possible, a related small change is made in the TF core (rendezvous_mgr.cc): Allow RecvOps to receive uninitialzied tensors, by checking IsInitialized() and treating uninitialized tensors specially in IntraProcessRendezvous::RecvAsync().
    
    Add C++ and Python unit tests.
    Change: 132357188

commit cb324446acbdf0d3d2129904361cf0bcbe53e852
Author: Pete Warden <petewarden@google.com>
Date:   Fri Sep 2 12:00:41 2016 -0800

    Fuse resize and mirror padding ops into convolutions
    Spatial transformations like padding and bilinear resizing can be merged into the im2col stage of conv2d. This reduces the memory usage considerably (from 338MB to 224MB) and latency (by 15%) on some models, and helps us avoid OOM crashes on iOS. This PR has all the changes needed to fuse these particular ops, including the kernels themselves and integration into the optimize_for_inference script.
    Change: 132094335

commit d75eab5a381a9cf1c4269b2cc205e262a6568573
Author: Daniel W Mane <danmane@gmail.com>
Date:   Wed Aug 31 19:42:43 2016 -0700

    Fix bug where TensorBoard will crash if it can't determine host ip address (#4141)
    
    * Fix bug where TensorBoard may crash if it cannot resolve host ip address
    
    * Remove redundant code.

commit 19f20da191800a34260d65ae266da6b5a5e6bd1a
Author: Daniel Man <danmane@gmail.com>
Date:   Wed Aug 31 17:33:02 2016 -0700

    Fix bug where TensorBoard may crash if it cannot resolve host ip address

commit 0beb7716f0ef28284bf4e6dfebb791c3f057f0de
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Aug 19 12:48:00 2016 -0800

    Fix crash bug in debug printout.
    Change: 130787386

commit d0789e85a24af6f608a7bcc2c7928028cc0ff8a6
Author: Vijay Vasudevan <vrv@google.com>
Date:   Wed Aug 10 15:28:46 2016 -0800

    Change GPU initialization to avoid crashing on errors (as much as possible).
    Change: 129926913

commit 2d0d126749d6d0cf82fb86691362c923a1bfbfe4
Author: Vijay Vasudevan <vrv@google.com>
Date:   Mon Aug 8 14:06:20 2016 -0800

    Change DeviceFactory functions that create devices to propagate
    Statuses, so that failures to initialize devices don't crash
    the program.
    
    Changes swig for device_lib to be a lot simpler, thanks to mrry@
    and keveman@'s help.
    
    Change allocation of eigen scratch memory to go through the allocator.
    
    Re-enable test for local devices now that python3 issue is fixed.
    Change: 129678132

commit 542de2bed1d591398b5f24b3adef6f5b10794ff2
Author: Pteris Paikens <PeterisP@gmail.com>
Date:   Thu Aug 4 18:22:19 2016 +0300

    Added libcupti path to Linux GPU support documentation
    
    Added path to libcupti in the documentation for enabling Linux GPU support.
    Without this library being in LD path certain tutorials (e.g. https://www.tensorflow.org/versions/master/how_tos/graph_viz/index.html) crash with message "tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcupti.so. "

commit fcc9a6ed272d6599d38ae59ae215cff786ad1bea
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jul 28 14:15:05 2016 -0800

    Making the third_party ffmpeg decode_audio op resilient to small numbers of
    decoding failures. Instead of crashing the TF pipeline it will now return an
    empty tensor. Note that pipelines that want to take advantage of this will have
    to be modified to handle empty tensors.
    Change: 128747076

commit 3758878728710801f681afba39e145df4ddb8bf1
Author: Zongheng Yang <zongheng@google.com>
Date:   Fri Jul 22 08:57:34 2016 -0800

    Fix a read/write race in Saver.
    
    For the checkpoint state proto ("checkpoint"), we now write it to a tmp file
    first, then atomically rename it.
    
    This prevents real training crashes.
    Change: 128183442

commit 2298c99c13007541dd3eebb9bf8d66ae1fd4f0fa
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Tue Jul 12 10:41:27 2016 -0800

    Fix tf.multinomial to not crash on empty input
    
    On the GPU, tf.multinomial uses Eigen.  On empty input, this triggers a bug in
    Eigen causing a crash.  Fix this by not executing the kernel in the empty
    output case.
    
    Also fix shape validation assertions to handle more corner cases (hopefully all
    of them).
    Change: 127223716

commit 17edafebb8bf58d516b71ede3ebce138fa591522
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Jul 8 14:28:24 2016 -0800

    Handles errors.AbortedError properly so trainer task does not have to restart/block indefinitely. Without this, currently trainers gets stuck indefinitely on a single ps shard crash.
    Change: 126954343

commit e05ff5ea7b076b951d4e179596835dc6232702a5
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Wed Jul 6 14:34:07 2016 -0800

    Fix degenerate reductions
    
    Eigen crashes on tf.reduce_sum(tf.zeros((0, 9938)), [0]), so we need to handle
    the case of degenerate reductions ourselves (by manually filling the output
    with identity elements).
    Change: 126745490

commit 605aa53d2bb65a8a38dc72725e28ebe75a949d5a
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Thu Jun 30 14:21:08 2016 -0800

    Add C++ shape inference for Pack, Unpack, and Const.
    Add GetAttr to shape_inference::InferenceContext.
    Allow setting NodeDef in shape_inference_testutil INFER calls (with new
    INFER*_WITH_DEF macro).  Fix a bug that caused a crash when an INFER..ERROR
    macro called a shape inference function that did not return an error.
    Change: 126350221

commit b184d46e23064b33f5aa351c476b97b2d2167021
Author: Ernest Grzybowski <ErnestG@users.noreply.github.com>
Date:   Fri Jun 10 13:28:08 2016 -0400

    Android permission check (#2658)
    
    * Added a simple permission check and request to prevent crashing on api 23+
    
    * Removed dependency on support lib.
    
    * Refactored getPermission() to requestPermission()
    
    * Simplified hasPermission()
    
    * Update codestyle
    
    * Update targetSdkVersion to 23

commit 7233ae61b0e6deb896dd432764e9c0efae340791
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Mon May 2 12:06:47 2016 -0800

    Make reduction gradients safe on empty tensors
    
    The current gradient routines die with division by zero exceptions (hard
    crashes at the moment) when run on empty tensors.  The mathematical gradients
    are perfectly well defined in this case, so now we do the right think.
    Specific fix courtesy of Josh: instead of x // y we now do x // max(y, 1).
    
    Fixes part of #2163.
    Change: 121301471

commit cb78f99de569c13dcc0fc66c555cd77c8884f79d
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Wed Apr 27 13:58:59 2016 -0800

    Fix argmax / argmin to not crash on empty input
    
    Instead, they now throw errors.
    Change: 120957905

commit ad65566f8d3582fd259749f1bcb498ec3f9be20a
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Mon Apr 25 16:20:46 2016 -0800

    Don't crash in tensorflow/contrib/distributions/python/kernel_tests/mvn_test.py if scipy is not present. Just log a warning and skip the parts of tests that depend on it.
    Change: 120765924

commit f4e8318c736ef9f2efb6442660ae6b6a46894538
Author: Benoit Steiner <benoit.steiner.goog@gmail.com>
Date:   Thu Apr 21 17:02:43 2016 -0800

    Prevent TensorFlow from crashing when attempting to reduce an empty tensor on GPU
    Change: 120505517

commit ea632fc4063d36091a254b6c61325b64ab2a699b
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Fri Apr 15 15:25:28 2016 -0800

    Fix crash in BFC allocator when failing to allocate memory from an allocator that has zero memory in its heap.
    Change: 120002729

commit ff3ed0e58141a02c2be39cbdf15892ad7caeedba
Merge: 4fd4ac6e741 91e6443a063
Author: Vijay Vasudevan <vrv@google.com>
Date:   Thu Mar 17 23:02:14 2016 -0700

    Merge pull request #1496 from ybbaigo/translate_fix
    
    fix crash for empty dev_set bucket

commit 7ec8e0d5ecc7949da0c49613ec4b6116b2f47d3b
Author: Yuwen Yan <ybbaigo@gmail.com>
Date:   Mon Mar 14 15:43:14 2016 +0000

    fix crash for empty dev_set bucket

commit ca908c4bd1feaddb9a10d365a52d350f96b26131
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Sat Mar 12 13:08:31 2016 -0800

    Fix crash in BFC allocator rendering. Without this, gpf_bfc_allocator_test crashes when run with --v=4 because the region rendering code overflows the rendering buffer.
    Change: 117057531

commit fc2ed7dfcc654303a593988cedc05d7ec2b57049
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Wed Mar 9 13:05:34 2016 -0800

    Fix the crash when applying SparseFtrl update where inner_dimension > 0
    Has verified this fix by real job.
    Change: 116794658

commit 694ab1d7bf1a451b3e5d2533224444b06dbbfe70
Author: Vijay Vasudevan <vrv@google.com>
Date:   Mon Mar 7 12:20:12 2016 -0800

    TensorFlow: Return an error on racy inputs to listdiff_op that would otherwise
    cause a crash.
    Change: 116574701

commit 223794ee783244977e865a3724904a39a35720ed
Author: Benoit Steiner <benoit.steiner.goog@gmail.com>
Date:   Wed Feb 24 15:26:13 2016 -0800

    Avoid using initialization lists since the version of nvcc shipped with Tegra
    X1 crashes when attempting to compile them
    Change: 115500414

commit 26078dfaf20f20a5c5d8a30503fbf387d7d30d53
Author: Geoffrey Irving <geoffreyi@google.com>
Date:   Wed Feb 24 10:30:04 2016 -0800

    Fix safety bug in gather and scatter
    
    Both gather and scatter now unconditionally validate indices in the inner loop,
    which prevents crashes if indices are changed asynchronously while the ops are
    running.
    
    For gather when validate_indices = true, the new code is within the noise of the
    old code speedwise or possibly slightly faster (unsurprising since the new code
    fuses two loops).  Specifically, the geometric mean of int32 gather benchmarks
    goes from 4.05GB/s to 4.04-4.07GB/s.
    
    For gather when validate_indices = false, the old code and a version of the old
    code that supported validate_indices = false both get 1.5% slower.  Xiaoqiang
    and I deem this difference insufficient to preserve the unsafe code path, so
    poof: it's gone.
    
    For scatter (which always validates), the new code is slightly faster than the
    old code: the geometric mean goes from 546-559M items/s to 573M items/s.
    Change: 115467091

commit 5919a8330fd1b7c7ac673b293b007e0e339905f7
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Tue Feb 2 18:02:35 2016 -0800

    Updated Tensorboard logic for determining what data should be thrown out after a Tensorflow crash and restart to use SessionLog.START proto, which should be less finicky than the previous out-of-order event.step heuristic.
    Change: 113698523

commit b10a672837f74094379b0cc2ae9ccf703e09e50e
Author: A. Unique TensorFlower <nobody@tensorflow.org>
Date:   Wed Jan 27 07:57:57 2016 -0800

    Updated TensorBoard logic for discarding events after crashes to discard out of order events only within a particular tag. This was changed because race conditions in supervisor was causing many events to be unintentionally discarded.
    Change: 113161277

commit e4029435aefcc6c406c9a485bcb7a0893a95f28e
Author: Vijay Vasudevan <vrv@google.com>
Date:   Wed Jan 20 19:08:00 2016 -0800

    Rollback of "Updated TensorBoard logic for discarding events after crashes to discard out of order events only within a particular tag. This was changed because race conditions in supervisor was causing many events to be unintentionally discarded."
    Change: 112644077

commit 38f54b55cdc66e12a2f6ce9d6724440e9738ac6f
Author: Benoit Steiner <benoit.steiner.goog@gmail.com>
Date:   Mon Jan 11 13:03:29 2016 -0800

    Upgraded to the latest version of Eigen, which fixes a compilation error as
    well the crash reported in https://github.com/tensorflow/tensorflow/issues/713.
    Change: 111874622

commit d9cfc64a2ddf05c0b093c8fb6704c67452ee3ea0
Author: Vijay Vasudevan <vrv@google.com>
Date:   Thu Dec 10 16:42:22 2015 -0800

    TensorFlow: merge changes from internal
    
    Change 109945903
            Make unsorted_segment_sum detect negative indices
    
            Previously it crashed.  This fixes #466.
    
            Also improve the error message to say which index is problematic.
    Change 109942557
            Fix the conv_grad_input with stride 2.
            + We always call the Cudnn implementation even if we have an incompatible
            padding.
    
    Base CL: 109948577

commit 5de908567355337fdebd997fb5c60993cbe9ba2e
Author: Vijay Vasudevan <vrv@google.com>
Date:   Tue Dec 8 16:11:23 2015 -0800

    TensorFlow: Upstream changes to git.
    
    Change 109738410
            Don't crash if an attribute contains an invalid shape
    
            Using GetAttr to retrieve a TensorShape caused a process crash if the shape
            contained negative entries or was too large.  Instead, produce useful error
            messages (and Python exceptions).
    
            Fixes https://github.com/tensorflow/tensorflow/issues/449.
    Change 109737915
            TensorFlow: fix build failures and some warnings when built with clang
            on OS X.
    Change 109737559
            Fix bad paragraphing
    Change 109735757
            Fix OSX installation instructions.
    Change 109733797
            Adds buttons to toggle the display of all runs.
    
    Base CL: 109739474

